[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantitative Methoden",
    "section": "",
    "text": "Diese Website dient als Sammlung meiner Vorlesungsnotizen und Übungen für die Vorlesung “Quantitative Methoden” im Herbstsemester 2024.\nDiese Sammlung ist aktuell noch am Entstehen.\n\n\n\n\n\n\nHinweis\n\n\n\nDie Inhalte dieser Website können Lücken und Fehler enthalten. Die Inhalte werden laufend ergänzt und verbessert.\nFehler und Vorschläge können auf jeder Seite direkt über Problem melden auf Github gemeldet werden. Bitte das entsprechende Issue-Template verwenden.\nFalls bereits Erfahrung mit Github und quarto besteht, kann auch jeweils direkt die Seite bearbeitet werden. Anschliessend kann ein Pull-Request erstellt werden.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Übersicht</span>"
    ]
  },
  {
    "objectID": "grundlagen_R.html",
    "href": "grundlagen_R.html",
    "title": "2  Grundlagen R",
    "section": "",
    "text": "3 Grundlagen R",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen R</span>"
    ]
  },
  {
    "objectID": "grundlagen_R.html#grundsätzliches-zu-r",
    "href": "grundlagen_R.html#grundsätzliches-zu-r",
    "title": "2  Grundlagen R",
    "section": "3.1 Grundsätzliches zu R",
    "text": "3.1 Grundsätzliches zu R\n\n3.1.1 Zuweisungsoperator\nIn R werden Werte Variablen mit dem &lt;- Operator zugewiesen.\n\n# Variablen erstellen und Wert zuweisen\na &lt;- 5\n\n# Die Zuweisung kann auch umgekehrt erfolgen\n5 -&gt; b\n\n# Das gleiche funktioniert grundsätzlich aber auch mit dem = Operator\n# Allerdings wird der &lt;- Operator bevorzugt\nc = 10\n\n\n\n3.1.2 Kommentare\nKommentare in R werden mit einem # eingeleitet. Sie können entweder in einer eigenen Zeile stehen oder am Ende einer Codezeile.\n\n# Das ist ein Kommentar\na &lt;- 5 # Das ist auch ein Kommentar\n\n\n\n3.1.3 Ausgabe\nIn R können Werte entweder mit der print() Funktion oder einfach durch Eingabe des Variablennamens ausgegeben werden.\n\n# Ausgabe von Variablen\nprint(a)\n\n[1] 5\n\nb\n\n[1] 5",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen R</span>"
    ]
  },
  {
    "objectID": "grundlagen_R.html#datentypen",
    "href": "grundlagen_R.html#datentypen",
    "title": "2  Grundlagen R",
    "section": "3.2 Datentypen",
    "text": "3.2 Datentypen\nIn R gibt es verschiedene Datentypen. Die wichtigsten sind:\n\nNumerische Werte (z.B. 5, 3.14)\nZeichenketten (Strings) (z.B. \"Hallo Welt\")\nLogische Werte (TRUE, FALSE)\nVektoren (in Python Listen) (z.B. c(1, 2, 3))1\nData Frames (ähnlich wie Tabellen, Mischen von Datentypen möglich)\nMatrizen (ähnlich wie in der Mathematik, keine Mischung von Datentypen möglich)\n\n\n3.2.1 Vektoren\nDa Vektoren eine der grundlegenden Datenstrukturen in R sind, werden wir uns diese genauer ansehen.\nSie können mit der c() Funktion erstellt werden. Vektoren sind grundsätzlich ähnlich wie Objekte vom Typ list in Python. Vektoren können sämtliche Datentypen enthalten, jedoch nur einen Datentyp pro Vektor.\nAuf Vektoren können verschiedene Operationen durchgeführt werden, wie z.B. Addition, Subtraktion, Multiplikation, Division, etc.\n\n# Vektor erstellen\nvectorA &lt;- c(1, 2, 3, 4, 5)\n\n# Länge des Vektors\nlength(vectorA)\n\n[1] 5\n\n# Logischer Vergleich\nvectorA &gt;= 3\n\n[1] FALSE FALSE  TRUE  TRUE  TRUE\n\n# Arithmetische Operationen\nvectorA + 5\n\n[1]  6  7  8  9 10\n\n\nWenn wir nun den Vektor vectorA erneut ausgeben, beobachten wir, dass die Operationen nicht den ursprünglichen Vektor verändert haben.\n\nvectorA\n\n[1] 1 2 3 4 5\n\n\nUm den Vektor zu verändern, müssen wir den veränderten Vektor entweder einer neuen Variablen zuweisen oder den Vektor direkt überschreiben.\n\n# Vektor einer neuen Variablen zuweisen\nvectorB &lt;- vectorA + 5\n\n# Vektor ausgeben\nvectorB\n\n[1]  6  7  8  9 10\n\n# Wir können den Vektor auch direkt überschreiben\nvectorA &lt;- vectorA + 5\n\n# Vektor ausgeben\nvectorA\n\n[1]  6  7  8  9 10\n\n\n\n3.2.1.1 Indizierung\nVektoren können indiziert werden, um auf bestimmte Elemente zuzugreifen.\nDie Indizierung beginnt in R bei 1.\n\n# Erstes Element des Vektors\nvectorA[1]\n\n[1] 6\n\n\nWir können auch auf mehrere Elemente gleichzeitig zugreifen. Wenn wir z.B. auf das zweite bis vierte Element des Vektors zugreifen wollen, können wir dies mit dem : Operator tun.\n\n# Zweites bis viertes Element des Vektors\nvectorA[2:4]\n\n[1] 7 8 9\n\n# Alternativ können wir auch einzelne Elemente überspringen\nvectorA[c(1, 3, 5)]\n\n[1]  6  8 10\n\n\n\n\n3.2.1.2 Vektoren konkatenieren\nVektoren können auch konkateniert werden.\n\n# Vektoren erstellen\nvectorA &lt;- c(1, 2, 3, 4, 5)\n\n# Vektoren konkatenieren\nvectorC &lt;- c(vectorA, vectorB)\n\n# Vektor ausgeben\nvectorC\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n\n\n3.2.1.3 Vektoren addieren\nVektoren können auch addiert werden. Hierbei werden die Vektoren elementweise addiert.2\n\n# Vektoren addieren\nvectorA + vectorB\n\n[1]  7  9 11 13 15\n\n\n\n\n3.2.1.4 Wichtige Funktionen für Vektoren\n\n\n\n\n\n\n\n\n\nFunktion\nBeschreibung\nBeispiel\nAusgabe\n\n\n\n\nlength()\nLänge des Vektors\nlength(vectorA)\n5\n\n\nsum()\nSumme der Elemente des Vektors\nsum(vectorA)\n15\n\n\nmean()\nDurchschnitt der Elemente des Vektors\nmean(vectorA)\n3\n\n\nvar()\nVarianz der Elemente des Vektors\nvar(vectorA)\n2.5\n\n\nsd()\nStandardabweichung der Elemente des Vektors\nsd(vectorA)\n1.5811388\n\n\nmin()\nMinimum des Vektors\nmin(vectorA)\n1\n\n\nmax()\nMaximum des Vektors\nmax(vectorA)\n5\n\n\nrange()\nBereich des Vektors\nrange(vectorA)\n1, 5\n\n\n\n\n\n\n3.2.2 Data Frames\nIn Data Frames können Vektoren unterschiedlicher Datentypen kombiniert werden. Sie sind ähnlich wie Tabellen in relationalen Datenbanken.\nData Frames können mit der data.frame() Funktion direkt erstellt werden.\n\n# Data Frame erstellen\ndataFrameA &lt;- data.frame(\n  name = c(\"Alice\", \"Bob\", \"Charlie\", \"David\"),\n  age = c(25, 30, 35, 40),\n  married = c(TRUE, FALSE, TRUE, TRUE)\n)\n\n# Data Frame ausgeben\ndataFrameA\n\n     name age married\n1   Alice  25    TRUE\n2     Bob  30   FALSE\n3 Charlie  35    TRUE\n4   David  40    TRUE\n\n\nWichtig ist, dass die Vektoren, die im Data Frame kombiniert werden sollen, die gleiche Länge haben müssen und dass die Vektoren nur einen Datentyp pro Vektor enthalten dürfen.\nWir beobachten auch hier, dass die Vektoren in der Initialisierung des Data Frames wieder mit der c() Funktion erstellt werden.\n\n3.2.2.1 Indizierung\nData Frames können indiziert werden, um auf bestimmte Elemente zuzugreifen.\nDie Indizierung erfolgt ähnlich wie bei Vektoren, jedoch mit dem Unterschied, dass wir zusätzlich auch die gewünschte Spalte angeben müssen. Dies erfolgt durch die Angabe der Zeilen- und Spaltennummer in eckigen Klammern.\nWenn wir eine ganze Zeile ausgeben wollen, geben wir nur die Zeilennummer an und lassen die Spaltennummer weg.\n\n# Erste Zeile des Data Frames\ndataFrameA[1, ]\n\n   name age married\n1 Alice  25    TRUE\n\n# Zweite Zeile und dritte Spalte des Data Frames\ndataFrameA[2, 3]\n\n[1] FALSE\n\n\nWir können mit dem $ Operator auch direkter auf bestimmte Spalten zugreifen.\n\n# Spalte \"name\" des Data Frames\ndataFrameA$name\n\n[1] \"Alice\"   \"Bob\"     \"Charlie\" \"David\"  \n\n\n\n\n3.2.2.2 Auswahl aus Data Frames wieder als Data Frame\nWir können subsetting verwenden, um einen Teil des Data Frames auszuwählen und diesen wieder als Data Frame zu speichern.\n\n# Auswahl der Spalten \"name\" und \"age\" als Data Frame\ndataFrameB &lt;- dataFrameA[, c(\"name\", \"age\")]\n\n# Data Frame ausgeben\ndataFrameB\n\n     name age\n1   Alice  25\n2     Bob  30\n3 Charlie  35\n4   David  40\n\n\n\n\n3.2.2.3 Wichtige Funktionen für Data Frames\n\n\n\n\n\n\n\n\n\nFunktion\nBeschreibung\nBeispiel\nAusgabe\n\n\n\n\nnrow()\nAnzahl der Zeilen des Data Frames\nnrow(dataFrameA)\n4\n\n\nncol()\nAnzahl der Spalten des Data Frames\nncol(dataFrameA)\n3\n\n\ncolnames()\nSpaltennamen des Data Frames\ncolnames(dataFrameA)\nname, age, married\n\n\nrownames()\nZeilennamen des Data Frames\nrownames(dataFrameA)\n1, 2, 3, 4\n\n\nsummary()\nZusammenfassung des Data Frames\nsummary(dataFrameA)\nLength:4 , Class :character , Mode :character , NA, NA, NA, Min. :25.00 , 1st Qu.:28.75 , Median :32.50 , Mean :32.50 , 3rd Qu.:36.25 , Max. :40.00 , Mode :logical , FALSE:1 , TRUE :3 , NA, NA, NA",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen R</span>"
    ]
  },
  {
    "objectID": "grundlagen_R.html#daten-importieren-und-exportieren",
    "href": "grundlagen_R.html#daten-importieren-und-exportieren",
    "title": "2  Grundlagen R",
    "section": "3.3 Daten importieren und exportieren",
    "text": "3.3 Daten importieren und exportieren\nIn R können Daten aus verschiedenen Dateiformaten importiert und exportiert werden. Dazu gehören z.B. CSV-Dateien, Excel-Dateien, JSON-Dateien, etc.\n\n3.3.1 CSV-Dateien\nCSV-Dateien können mit der read.csv() Funktion in R eingelesen werden.\n\n# CSV-Datei einlesen\nmeteodaten &lt;- read.csv('Data/meteodaten_saison.csv', sep = ',', header = TRUE)\n\nIn diesem Beispiel wird die CSV-Datei meteodaten_saison.csv eingelesen. Der Parameter sep = ',' gibt an, dass die Werte in der CSV-Datei durch Kommas getrennt sind. Der Parameter header = TRUE gibt an, dass die erste Zeile der CSV-Datei die Spaltennamen enthält.\n\n\n\n\n\n\nAchtung\n\n\n\nDer Pfad zur Datei muss entweder absolut (Bsp.: C:/Users/username/Documents/data.csv) oder relativ zum aktuellen Arbeitsverzeichnis (Bsp.: Data/data.csv) angegeben werden.\nIn aller Regel ist es sinnvoll, den Pfad relativ zum aktuellen Arbeitsverzeichnis anzugeben. Das aktuelle Arbeitsverzeichnis kann in der Terminalkonsole mit dem Befehl getwd() abgefragt werden, und mit dem Befehl setwd() kann das Arbeitsverzeichnis geändert werden.\nEine gängige (und hier angewandte) Praxis ist es, ein Unterverzeichnis Data im Projektverzeichnis anzulegen und dort alle Daten abzulegen.\nDer einfachste Weg ist es im Explorer einen Ordner anzulegen in welchem alle Skripte gespeichert werden. In diesem Ordner kann dann ein Unterordner Data erstellt werden, in welchem die Daten abgelegt werden.\nIn RStudio kann das Arbeitsverzeichnis über das Menü Session -&gt; Set Working Directory -&gt; Choose Directory... gesetzt werden.\n\n\n\n3.3.1.1 Wichtige Funktionen für Datenimport\n\n\nstr(): Zeigt die Struktur des Data Frames an.\n\n\nstr(meteodaten)\n\n'data.frame':   492 obs. of  6 variables:\n $ Jahr                           : int  1901 1901 1901 1901 1902 1902 1902 1902 1903 1903 ...\n $ Saison                         : chr  \"Fruehling(MAM)\" \"Herbst(SON)\" \"Sommer(JJA)\" \"Winter(DJF)\" ...\n $ Bern_Mitteltemperatur          : num  7.73 7.4 16.8 -2.73 7.53 ...\n $ Bern_Niederschlagssumme        : num  278 245 381 112 323 ...\n $ GrStBernhard_Mitteltemperatur  : num  -4 -0.8 6.3 -10.6 -3.63 ...\n $ GrStBernhard_Niederschlagssumme: num  495 521 285 356 448 ...\n\n\n\n\n\nhead(): Zeigt die ersten Zeilen des Data Frames an.\n\n\nhead(meteodaten)\n\n  Jahr         Saison Bern_Mitteltemperatur Bern_Niederschlagssumme\n1 1901 Fruehling(MAM)              7.733333                   277.8\n2 1901    Herbst(SON)              7.400000                   244.9\n3 1901    Sommer(JJA)             16.800000                   381.1\n4 1901    Winter(DJF)             -2.733333                   112.4\n5 1902 Fruehling(MAM)              7.533333                   323.2\n6 1902    Herbst(SON)              7.466667                   231.7\n  GrStBernhard_Mitteltemperatur GrStBernhard_Niederschlagssumme\n1                     -4.000000                           494.7\n2                     -0.800000                           520.8\n3                      6.300000                           285.2\n4                    -10.600000                           356.2\n5                     -3.633333                           448.1\n6                     -1.000000                           335.6\n\n\n\n\n\ntail(): Zeigt die letzten Zeilen des Data Frames an.\n\n\ntail(meteodaten)\n\n    Jahr         Saison Bern_Mitteltemperatur Bern_Niederschlagssumme\n487 2022    Sommer(JJA)             20.000000                   238.3\n488 2022    Winter(DJF)              2.233333                   184.7\n489 2023 Fruehling(MAM)              9.533333                   272.5\n490 2023    Herbst(SON)             11.966667                   371.2\n491 2023    Sommer(JJA)             20.000000                   203.1\n492 2023    Winter(DJF)              2.700000                   233.1\n    GrStBernhard_Mitteltemperatur GrStBernhard_Niederschlagssumme\n487                     10.266667                           256.8\n488                     -4.966667                           270.0\n489                     -1.666667                           388.4\n490                      2.966667                           553.3\n491                      9.200000                           288.4\n492                     -5.333333                           228.7\n\n\n\n\n\nsummary(): Gibt eine Zusammenfassung des Data Frames aus.\n\n\nsummary(meteodaten)\n\n      Jahr         Saison          Bern_Mitteltemperatur\n Min.   :1901   Length:492         Min.   :-4.500       \n 1st Qu.:1931   Class :character   1st Qu.: 4.883       \n Median :1962   Mode  :character   Median : 8.750       \n Mean   :1962                      Mean   : 8.715       \n 3rd Qu.:1993                      3rd Qu.:12.750       \n Max.   :2023                      Max.   :21.100       \n Bern_Niederschlagssumme GrStBernhard_Mitteltemperatur\n Min.   : 47.9           Min.   :-11.2000             \n 1st Qu.:185.7           1st Qu.: -5.1000             \n Median :243.2           Median : -1.4000             \n Mean   :253.3           Mean   : -0.9232             \n 3rd Qu.:308.9           3rd Qu.:  3.2750             \n Max.   :600.1           Max.   : 10.5333             \n GrStBernhard_Niederschlagssumme\n Min.   : 125.9                 \n 1st Qu.: 383.1                 \n Median : 491.5                 \n Mean   : 513.9                 \n 3rd Qu.: 619.2                 \n Max.   :1351.6                 \n\n\n\n\n\nIndizierung: Mit der Indizierung können bestimmte Zeilen und Spalten des Data Frames ausgewählt werden.\n\n\nmeteodaten[1:10,] # Ersten 10 Zeilen\n\n   Jahr         Saison Bern_Mitteltemperatur Bern_Niederschlagssumme\n1  1901 Fruehling(MAM)              7.733333                   277.8\n2  1901    Herbst(SON)              7.400000                   244.9\n3  1901    Sommer(JJA)             16.800000                   381.1\n4  1901    Winter(DJF)             -2.733333                   112.4\n5  1902 Fruehling(MAM)              7.533333                   323.2\n6  1902    Herbst(SON)              7.466667                   231.7\n7  1902    Sommer(JJA)             16.466667                   295.9\n8  1902    Winter(DJF)             -0.800000                   193.9\n9  1903 Fruehling(MAM)              7.433333                   177.6\n10 1903    Herbst(SON)              8.766667                   267.3\n   GrStBernhard_Mitteltemperatur GrStBernhard_Niederschlagssumme\n1                     -4.0000000                           494.7\n2                     -0.8000000                           520.8\n3                      6.3000000                           285.2\n4                    -10.6000000                           356.2\n5                     -3.6333333                           448.1\n6                     -1.0000000                           335.6\n7                      5.3000000                           242.7\n8                     -7.4000000                           341.2\n9                     -4.4666667                           409.7\n10                    -0.4666667                           507.1",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen R</span>"
    ]
  },
  {
    "objectID": "grundlagen_R.html#daten-als-.csv--und-.txt-dateien-exportieren",
    "href": "grundlagen_R.html#daten-als-.csv--und-.txt-dateien-exportieren",
    "title": "2  Grundlagen R",
    "section": "3.4 Daten als .csv- und .txt-Dateien exportieren",
    "text": "3.4 Daten als .csv- und .txt-Dateien exportieren\nDaten können mit der write.csv() Funktion als CSV-Dateien und mit der write.table() Funktion als Textdateien exportiert werden.\n\n3.4.1 .csv-Dateien\n\n# CSV-Datei exportieren\nwrite.csv(meteodaten,\n          file = \"meteodaten.csv\",\n          row.names = FALSE)\n\n\n\n\n\n\n\n\nParameter\nBeschreibung\n\n\n\n\nx\nDas Data Frame, das exportiert werden soll.\n\n\nfile\nDateiname und Speicherort. Auch hier können absolute und relative Dateipfade verwendet werden.\n\n\nrow.names\nGibt an, ob die Zeilennummern in der CSV-Datei gespeichert werden sollen.\n\n\n\n\n\n3.4.2 .txt-Dateien\n\n# Textdatei exportieren\nwrite.table(meteodaten, # Das Data Frame, das exportiert werden soll\n            file = \"meteodaten.txt\", # Dateiname und Speicherort\n            sep = \"\\t\", # Tabulator als Trennzeichen\n            eol = \"\\r\", # Zeilenumbruch\n            na = \"NA\", # Wert für fehlende Daten\n            row.names = FALSE,\n            col.names = TRUE)\n\n\n\n\n\n\n\n\nParameter\nBeschreibung\n\n\n\n\nx\nDas Data Frame, das exportiert werden soll.\n\n\nfile\nDateiname und Speicherort. Auch hier können absolute und relative Dateipfade verwendet werden.\n\n\nsep\nTrennzeichen für die Spalten.\n\n\neol\nZeilenumbruch. Kann je nach Betriebssystem erforderlich sein.\n\n\nna\nWert für fehlende Daten.\n\n\nrow.names\nGibt an, ob die Zeilennummern in der Textdatei gespeichert werden sollen.\n\n\ncol.names\nGibt an, ob die Spaltennamen in der Textdatei gespeichert werden sollen.\n\n\n\nWie sonst auch, haben die meisten Parameter Standardwerte, die nicht explizit angegeben werden müssen.",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen R</span>"
    ]
  },
  {
    "objectID": "grundlagen_R.html#umgang-mit-fehlwerten",
    "href": "grundlagen_R.html#umgang-mit-fehlwerten",
    "title": "2  Grundlagen R",
    "section": "3.5 Umgang mit Fehlwerten",
    "text": "3.5 Umgang mit Fehlwerten\nFehlwerte sind in Datenanalysen ein häufiges Problem. In R werden Fehlwerte standardmässig mit NA (Not Available) dargestellt.\n\n3.5.1 Fehlwerte in Funktionsaufrufen behandeln\nErstellen wir ein Beispiel-Vektor mit Fehlwerten:\n\nvektor_mit_na &lt;- c(1, 2, NA, 4, 5)\n\nWenn wir nun z.B. die Summe des Vektors berechnen, erhalten wir:\n\nsum(vektor_mit_na)\n\n[1] NA\n\n\nDie Ausgabe ist NA, da R nicht weiss, wie es mit dem Fehlwert umgehen soll.\nWir können in diversen Funktionen definieren, wie mit Fehlwerten umgegangen werden soll. Dazu können wir den na.rm Parameter verwenden. (rm = remove) Dieser Parameter ist standardmässig auf FALSE gesetzt.\n\nsum(vektor_mit_na,\n    na.rm = TRUE)\n\n[1] 12\n\n\nDie Ausgabe ist 12, da der Fehlwert ignoriert wird.\nDies funktioniert auch bei anderen Funktionen, wie z.B. mean(), var(), sd(), etc.\n\n\n3.5.2 Fehlwerte im Dateiimport behandeln\nBeim Import von Daten können wir mit dem Parameter na.strings definieren, welche Werte als Fehlwerte interpretiert werden sollen.\n\n# CSV-Datei einlesen\nmeteodaten &lt;- read.csv('Data/meteodaten_saison.csv',\n                        sep = ',',\n                        header = TRUE,\n                        na.strings = c(\"NA\", \"N/A\", \"na\"))\n\nIn diesem Beispiel definieren wir, dass die Werte \"NA\", \"N/A\" und \"na\" als Fehlwerte interpretiert werden sollen.\n\n\n3.5.3 Fehlwerte identifizieren\nFehlwerte können mit der is.na() Funktion identifiziert und mit der na.omit() Funktion entfernt werden.\n\n# Fehlwerte identifizieren\nis.na(vektor_mit_na)\n\n[1] FALSE FALSE  TRUE FALSE FALSE\n\n# Fehlwerte entfernen\nvektor_ohne_na &lt;- na.omit(vektor_mit_na)\n\nDer Vektor ist nun: 1, 2, 4, 5.\n\n3.5.3.1 Überprüfen auf Gleichheit\nFehlwerte müssen mit is.na() überprüft werden, da sie nicht mit == verglichen werden können.3\n\n# Überprüfen auf Gleichheit\nvektor_mit_na == NA\n\n[1] NA NA NA NA NA\n\n# Überprüfen auf Gleichheit mit is.na()\nis.na(vektor_mit_na)\n\n[1] FALSE FALSE  TRUE FALSE FALSE\n\n\n\n\n\n3.5.4 Fehlwerte ersetzen\nMit der replace() Funktion können Fehlwerte am einfachsten ersetzt werden.\n\n# Vector mit falschen Fehlwerten\nvektor_mit_falschen_na &lt;- c(1, 2, -999, 4, 5)\n\n# Fehlwerte ersetzen\nvektor_mit_korrigierten_na &lt;- replace(vektor_mit_falschen_na,\n                                      vektor_mit_falschen_na == -999,\n                                      NA)\n\nDer Vektor ist nun: 1, 2, NA, 4, 5.",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen R</span>"
    ]
  },
  {
    "objectID": "grundlagen_R.html#übungen",
    "href": "grundlagen_R.html#übungen",
    "title": "2  Grundlagen R",
    "section": "3.6 Übungen",
    "text": "3.6 Übungen\nBerechne die Sommer (JJA) Temperaturanomalien zur Referenzperiode 1961 bis 1990 in Bern.\n\n# Daten einlesen\nmeteodaten &lt;- read.csv('Data/meteodaten_saison.csv', sep = ',', header = TRUE)\n\n# Daten filtern\nsaison_sommer &lt;- meteodaten[meteodaten$Saison == \"Sommer(JJA)\", ]\n\n# Referenzwert der Periode 1961 bis 1990 berechnen\nreferenzwert &lt;- mean(\n    saison_sommer$Bern_Mitteltemperatur[saison_sommer$Jahr &gt;= 1961\n    & saison_sommer$Jahr &lt;= 1990])\n\n# Sommer (JJA) Temperaturanomalien berechnen und direkt im data frame speichern\nsaison_sommer$Bern_Mitteltemperatur_anomalie &lt;-\n    saison_sommer$Bern_Mitteltemperatur - referenzwert\n\n# Plot erstellen\nplot(saison_sommer$Jahr,\n    saison_sommer$Bern_Mitteltemperatur_anomalie,\n    type = \"l\",\n    xlab = \"Jahr\",\n    ylab = \"Temperaturanomalie (°C)\",\n    main = \"Sommer (JJA) Temperaturanomalien in Bern\")\n\n# null-Linie hinzufügen\nabline(h = 0, col = \"red\")",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen R</span>"
    ]
  },
  {
    "objectID": "grundlagen_R.html#footnotes",
    "href": "grundlagen_R.html#footnotes",
    "title": "2  Grundlagen R",
    "section": "",
    "text": "Kleine Anmerkung: Hier wird der Vektor mit der c() Funktion erstellt. Diese Funktion wird verwendet, um Werte zu kombinieren (combine).↩︎\nWenn die Vektoren unterschiedliche Längen haben, wird der kürzere Vektor so oft wiederholt, bis er die Länge des längeren Vektors hat. Wenn die Länge des längeren Vektors kein Vielfaches der Länge des kürzeren Vektors ist, wird eine Warnung ausgegeben.↩︎\nDer Vergleich von Fehlwerten mit == ergibt immer NA, da R nicht weiss, ob der Fehlwert gleich einem anderen Wert ist oder nicht.↩︎",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grundlagen R</span>"
    ]
  },
  {
    "objectID": "plots_in_R.html",
    "href": "plots_in_R.html",
    "title": "3  Einfache Plots erstellen",
    "section": "",
    "text": "4 Einfache Plots erstellen\n“High-level” Plots können in R mit der plot() Funktion erstellt werden. Diese Funktion erstellt automatisch für die gegebenen Daten ein (geeignetes) Diagramm.\nWenn wir aber Beispielsweise unser ganzes meteodaten Data Frame plotten wollen, weiss die Funktion nicht, wie sie das tun soll und plottet einfach alle Spalten gegen alle anderen Zeilen. Dies ist in diesem Fall nicht sinnvoll.\nplot(meteodaten)",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Einfache Plots erstellen</span>"
    ]
  },
  {
    "objectID": "plots_in_R.html#liniendiagramme",
    "href": "plots_in_R.html#liniendiagramme",
    "title": "3  Einfache Plots erstellen",
    "section": "4.1 Liniendiagramme",
    "text": "4.1 Liniendiagramme\nUm unsere Daten sinnvoller zu plotten müssen wir die Daten zuerst filtern und dann plotten.\nWir diskutieren die verschiedenen Schritte hier später:\n\n# Subsets der Daten erstellen\nsaison_fruehling &lt;- meteodaten[meteodaten$Saison == \"Fruehling(MAM)\", ]\nsaison_sommer &lt;- meteodaten[meteodaten$Saison == \"Sommer(JJA)\", ]\nsaison_herbst &lt;- meteodaten[meteodaten$Saison == \"Herbst(SON)\", ]\nsaison_winter &lt;- meteodaten[meteodaten$Saison == \"Winter(DJF)\", ]\n\n# Plot mit den Saisontemperaturen erstellen erstellen\nplot(saison_fruehling$Jahr, saison_fruehling$Bern_Mitteltemperatur,\n    type = \"l\",\n    xlab = \"Jahr\",\n    ylab = \"Durchschnittstemperatur in °C\",\n    main = \"Saisonale Durchschnittstemperaturen in Bern\",\n    xlim = c(1900, 2020),\n    ylim = c(-5, 35))\n\n# Weitere Linien für andere Jahreszeiten auf den selben Plot hinzufügen\nlines(saison_sommer$Jahr, saison_sommer$Bern_Mitteltemperatur,\n    col = \"red\")\nlines(saison_herbst$Jahr, saison_herbst$Bern_Mitteltemperatur,\n    col = \"green\")\nlines(saison_winter$Jahr, saison_winter$Bern_Mitteltemperatur,\n    col = \"blue\")\n\n# Gestrichelte Horizontale Linie bei 0 hinzufügen\nabline(h = 0, lty = 2)\n\n# Saisonale Mittelwertlinien hinzufügen\nabline(h = mean(saison_fruehling$Bern_Mitteltemperatur),\n    col = \"black\",\n    lty = 3)\nabline(h = mean(saison_sommer$Bern_Mitteltemperatur),\n    col = \"red\",\n    lty = 3)\nabline(h = mean(saison_herbst$Bern_Mitteltemperatur),\n    col = \"green\",\n    lty = 3)\nabline(h = mean(saison_winter$Bern_Mitteltemperatur),\n    col = \"blue\",\n    lty = 3)\n\n# Legende hinzufügen\nlegend(\"topright\",\n    legend = c(\"Frühling\", \"Sommer\", \"Herbst\", \"Winter\"),\n    col = c(\"black\", \"red\", \"green\", \"blue\"),\n    lty = 1,\n    xpd = TRUE)\n\n\n\n\n\n\n\n\nSchauen wir uns nun die verschiedenen Schritte im Detail an.\n\nCSV-Datei einlesen: Zuerst lesen wir die CSV-Datei meteodaten_saison.csv ein.\n\n\n# CSV-Datei einlesen\nmeteodaten &lt;- read.csv('Data/meteodaten_saison.csv',\n    sep = ',',\n    header = TRUE)\n\nDer Parameter sep = ',' gibt an, dass die Werte in der CSV-Datei durch Kommas getrennt sind.\nDer Parameter header = TRUE gibt an, dass die erste Zeile der CSV-Datei die Spaltennamen enthält.\n\nSubsets der Daten erstellen: Da unser Data Frame meteodaten Daten aus verschiedenen Jahreszeiten enthält, erstellen wir Subsets für jede Jahreszeit. Damit können wir die Daten für jede Jahreszeit separat plotten.\n\n\n# Subsets der Daten erstellen\nsaison_fruehling &lt;- meteodaten[meteodaten$Saison == \"Fruehling(MAM)\", ]\nsaison_sommer &lt;- meteodaten[meteodaten$Saison == \"Sommer(JJA)\", ]\nsaison_herbst &lt;- meteodaten[meteodaten$Saison == \"Herbst(SON)\", ]\nsaison_winter &lt;- meteodaten[meteodaten$Saison == \"Winter(DJF)\", ]\n\nMit dem == Operator vergleichen wir die Werte auf Gleichheit.\n\nmeteodaten$Saison == \"Fruehling(MAM)\"\n\nWir überprüfen also Zeile für Zeile, ob der Wert in der Spalte Saison gleich dem String \"Fruehling(MAM)\" ist. Dies wird in einen boolschen Vektor umgewandelt, der TRUE für Zeilen enthält, die dem Kriterium entsprechen, und FALSE für Zeilen, die es nicht tun.\nBetrachten wir nun eine Klammer weiter aussen, um zu verstehen, was genau wir dem Subset zuweisen.\n\nmeteodaten[meteodaten$Saison == \"Fruehling(MAM)\", ]\n\nHier wählen wir alle Zeilen aus dem Data Frame meteodaten aus, in denen die Spalte Saison den Wert \"Fruehling(MAM)\" hat. Da wir nach dem letzten Komma nichts weiter angeben, wählen wir alle Spalten aus.\nUnsere Saisonalen Data Frames enthalten also nicht nur die Temperatur-Mittelwerte aus Bern, sondern auch die Niederschlagswerte von Bern und dem Grossen St. Bernhard. Wir greifen im erstellten Plot nur auf die Temperaturwerte zu.\n\nPlot mit den Saisontemperaturen erstellen: Wir erstellen einen Plot mit den saisonalen Durchschnittstemperaturen in Bern.\n\n\n# Plot mit den Saisontemperaturen erstellen erstellen\nplot(saison_fruehling$Jahr, saison_fruehling$Bern_Mitteltemperatur,\n    type = \"l\",\n    xlab = \"Jahr\",\n    ylab = \"Durchschnittstemperatur in °C\",\n    main = \"Saisonale Durchschnittstemperaturen in Bern\",\n    xlim = c(1900, 2020),\n    ylim = c(-5, 35))\n\nDie plot() Funktion hat viele Parameter, die wir verwenden können, um den Plot anzupassen.\n\n\n\n\n\n\n\nParameter\nBeschreibung\n\n\n\n\nplot(x, y)\nErstellt einen Plot der Werte in x gegen die Werte in y. Wir plotten hier die Spalte Jahr aus dem Subset saison_fruehling gegen die Spalte Bern_Mitteltemperatur aus dem gleichen subset.\n\n\ntype\nGibt den Typ des Plots an. Hier verwenden wir \"l\", um eine Linie zu zeichnen.\n\n\nxlab\nBeschriftung der x-Achse.\n\n\nylab\nBeschriftung der y-Achse.\n\n\nmain\nTitel des Plots.\n\n\nxlim\nBereich der x-Achse. Hier von 1900 bis 2020.\n\n\nylim\nBereich der y-Achse. Hier von -5 bis 35.\n\n\n\n\nWeitere Linien für andere Jahreszeiten auf den selben Plot hinzufügen: Wir fügen Linien für die anderen Jahreszeiten hinzu.\n\nIn R können wir mit der lines() Funktion weitere Linien zu einem bestehenden Plot hinzufügen.\n\n# Weitere Linien für andere Jahreszeiten auf den selben Plot hinzufügen\nlines(saison_sommer$Jahr, saison_sommer$Bern_Mitteltemperatur,\n    col = \"red\")\nlines(saison_herbst$Jahr, saison_herbst$Bern_Mitteltemperatur,\n    col = \"green\")\nlines(saison_winter$Jahr, saison_winter$Bern_Mitteltemperatur,\n    col = \"blue\")\n\nHier müssen wir jeweils nicht mehr ganz so viele Parameter angeben, da wir bereits die Achsenbesschriftung etc. vorgenommen haben. Was wir noch angeben müssen, ist die Farbe der Linie mit dem col Parameter.\n\nGestrichelte Horizontale Linie bei 0 hinzufügen: Wir fügen eine gestrichelte Horizontale Linie bei 0 hinzu.\n\n\n# Gestrichelte Horizontale Linie bei 0 hinzufügen\nabline(h = 0, lty = 2)\n\nMit der abline() Funktion können wir Linien zu einem Plot hinzufügen. Mit dem h Parameter geben wir die y-Position der Linie an, und mit dem lty Parameter geben wir den Linientyp an. Hier verwenden wir lty = 2, um eine gestrichelte Linie zu zeichnen.\n\nSaisonale Mittelwertlinien hinzufügen: Wir fügen Mittelwertlinien für jede Jahreszeit hinzu.\n\n\n# Saisonale Mittelwertlinien hinzufügen\nabline(h = mean(saison_fruehling$Bern_Mitteltemperatur),\n    col = \"black\",\n    lty = 3)\nabline(h = mean(saison_sommer$Bern_Mitteltemperatur),\n    col = \"red\",\n    lty = 3)\nabline(h = mean(saison_herbst$Bern_Mitteltemperatur),\n    col = \"green\",\n    lty = 3)\nabline(h = mean(saison_winter$Bern_Mitteltemperatur),\n    col = \"blue\",\n    lty = 3)\n\nHier fügen wir gestrichelte Linien für die Mittelwerte der Temperatur für jede Jahreszeit hinzu. Wir verwenden die mean() Funktion, um direkt im Aufruf den Mittelwert zu berechnen.\n\nLegende hinzufügen: Wir fügen eine Legende für die verschiedenen Linien hinzu.\n\n\n# Legende hinzufügen\nlegend(\"topright\",\n    legend = c(\"Frühling\", \"Sommer\", \"Herbst\", \"Winter\"),\n    col = c(\"black\", \"red\", \"green\", \"blue\"),\n    lty = 1,\n    xpd = TRUE)\n\nMit der legend() Funktion können wir eine Legende zu einem Plot hinzufügen. Wir geben die Position der Legende mit dem topright Parameter an. Mit dem legend Parameter geben wir die Beschriftungen für die Linien an. Mit dem col Parameter geben wir die Farben der Linien an. Mit dem lty Parameter geben wir den Linientyp an. Mit dem xpd Parameter geben wir an, ob die Legende ausserhalb des Plots sein soll.",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Einfache Plots erstellen</span>"
    ]
  },
  {
    "objectID": "plots_in_R.html#scatterplots-und-aggregate-funktion",
    "href": "plots_in_R.html#scatterplots-und-aggregate-funktion",
    "title": "3  Einfache Plots erstellen",
    "section": "4.2 Scatterplots und aggregate()-Funktion",
    "text": "4.2 Scatterplots und aggregate()-Funktion\nWenn wir von unseren nach Jahreszeiten sortierten Daten nun bspw. den Durchschnitt der Temperaturwerte pro Jahr berechnen wollen, können wir die aggregate() Funktion verwenden.\n\n# Durchschnittstemperatur pro Jahr berechnen\ndurchschnittstemperatur_pro_jahr &lt;- aggregate(Bern_Mitteltemperatur ~ Jahr,\n    data = meteodaten,\n    FUN = mean)\n\n# Plot erstellen\nplot(durchschnittstemperatur_pro_jahr$Jahr,\n    durchschnittstemperatur_pro_jahr$Bern_Mitteltemperatur,\n    type = \"p\",\n    xlab = \"Jahr\",\n    ylab = \"Durchschnittstemperatur in °C\",\n    main = \"Durchschnittstemperatur pro Jahr in Bern\")\n\n# Lineares Modell (lineare Regression) erstellen\ntrend &lt;- lm(Bern_Mitteltemperatur ~ Jahr,\n    data = durchschnittstemperatur_pro_jahr)\n\n# Trendlinie hinzufügen\nabline(trend,\n    col = \"red\",\n    lwd = 2)  # Die Farbe und Dicke der Linie anpassen\n\n\n\n\n\n\n\n\nDie aggregate() Funktion nimmt vier Parameter:\n\nDie Spalte, nach der aggregiert werden soll (Bern_Mitteltemperatur).\nDie Spalte, nach der gruppiert werden soll (Jahr).\nDie Daten, auf die die Funktion angewendet werden soll (meteodaten).\nDie Funktion, die auf die aggregierten Werte angewendet werden soll (mean).\n\nDer ~-Operator wird in R verwendet, um die linke Seite von der rechten Seite zu trennen. In diesem Fall bedeutet dies, dass wir die Spalte Bern_Mitteltemperatur nach der Spalte Jahr aggregieren wollen.\nZusätzlich haben wir hier noch eine Trendlinie hinzugefügt. Dazu haben wir ein lineares Modell mit der lm() Funktion erstellt und die Trendlinie mit der abline() Funktion hinzugefügt.",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Einfache Plots erstellen</span>"
    ]
  },
  {
    "objectID": "plots_in_R.html#boxplots-und-mehrere-plots-in-einem-diagramm",
    "href": "plots_in_R.html#boxplots-und-mehrere-plots-in-einem-diagramm",
    "title": "3  Einfache Plots erstellen",
    "section": "4.3 Boxplots und mehrere Plots in einem Diagramm",
    "text": "4.3 Boxplots und mehrere Plots in einem Diagramm\nWir wollen nun für die Temperaturen und Niederschlagswerte in Bern und auf dem Grossen St. Bernhard Boxplots erstellen und diese in einem Diagramm nebeneinander plotten. Zusätzlich wollen wir die Daten Zeitlich bis ins Jahr 1980 beschränken. Auch dieser Code enthält einige zusätzliche und neue Schritte, welche wir uns anschliessend genauer ansehen.\n\n# Definiere neue Kategorien-Namen und die gewünschte Reihenfolge\nneue_namen &lt;- c(\"Frühling\", \"Sommer\", \"Herbst\", \"Winter\")\nalte_namen &lt;- c(\"Fruehling(MAM)\", \"Sommer(JJA)\", \"Herbst(SON)\", \"Winter(DJF)\")\n\n# Konvertiere 'Saison' in einen Faktor mit den neuen Namen und der gewünschten Reihenfolge\nmeteodaten$Saison &lt;- factor(meteodaten$Saison,\n                            levels = alte_namen,\n                            labels = neue_namen)\n\n# Mehrere Plots in einem Diagramm\npar(mfrow = c(2, 2), # 2 Zeilen und 2 Spalten\n    mar = c(4, 4, 2, 1), # verkleinert die Ränder\n    oma = c(0, 0, 4, 0), # fügt Platz für den Titel hinzu\n    cex = 0.8) # verkleinert die Schriftgrösse\n\n# Boxplots erstellen\nboxplot(Bern_Mitteltemperatur ~ Saison,\n    data = meteodaten[meteodaten$Jahr &lt;= 1980, ],\n    ylim = c(-10, 20),\n    ylab = \"Durchschnittstemperatur in °C\",\n    main = \"Durchschnittstemperatur Bern\")\n\nboxplot(GrStBernhard_Mitteltemperatur ~ Saison,\n    data = meteodaten[meteodaten$Jahr &lt;= 1980, ],\n    ylim = c(-10, 20),\n    ylab = \"Durchschnittstemperatur in °C\",\n    main = \"Durchschnittstemperatur Gr. St. Bernhard\")\n\nboxplot(Bern_Niederschlagssumme ~ Saison,\n    data = meteodaten[meteodaten$Jahr &lt;= 1980, ],\n    ylim = c(0, 400),\n    ylab = \"Niederschlag in mm\",\n    main = \"Niederschlag Bern\")\n\nboxplot(GrStBernhard_Niederschlagssumme ~ Saison,\n    data = meteodaten[meteodaten$Jahr &lt;= 1980, ],\n    ylim = c(0, 400),\n    ylab = \"Niederschlag in mm\",\n    main = \"Niederschlag Gr. St. Bernhard\")\n\n# Gesamte Überschrift für alle Plots hinzufügen\ntitle(\"Klimadaten in Bern und auf dem Grossen St. Bernhard\", outer = TRUE)\n\n\n\n\n\n\n\n\nSchauen wir uns die verschiedenen Schritte im Detail an:\n\nDefiniere neue Kategorien-Namen und die gewünschte Reihenfolge: Die Kategorien-Namen haben bisher die Form Fruehling(MAM), Sommer(JJA), Herbst(SON), Winter(DJF). Um die Lesbarkeit zu verbessern und etwas kürzere Namen zu verwenden, definieren wir neue Namen. In einem nächsten Schritt konvertieren wir die Spalte Saison in einen Faktor1 mit den neuen Namen und der gewünschten Reihenfolge.\n\n\nneue_namen &lt;- c(\"Frühling\", \"Sommer\", \"Herbst\", \"Winter\")\nalte_namen &lt;- c(\"Fruehling(MAM)\",\n                \"Sommer(JJA)\",\n                \"Herbst(SON)\",\n                \"Winter(DJF)\")\n\nmeteodaten$Saison &lt;- factor(meteodaten$Saison,\n                            levels = alte_namen,\n                            labels = neue_namen)\n\nWir verwenden die factor() Funktion, um die Spalte Saison, die aktuell als Strings vorliegt, in einen Faktor zu konvertieren. Mit dem levels Parameter geben wir die Reihenfolge der vorhandenen Werte in den Daten an – hier die alten Namen, da diese in den Rohdaten stehen. Der labels Parameter definiert die neuen Namen, die im Plot oder bei Ausgaben angezeigt werden sollen.\nWichtig zu verstehen ist, dass die Umwandlung mit factor() nicht die zugrunde liegenden Daten ändert, sondern nur die Art und Weise, wie die Kategorien dargestellt werden. Die ursprünglichen Werte (also die alten Namen) bleiben im Data Frame erhalten2, aber R verwendet die neuen Labels, um diese Werte im Plot oder bei der Ausgabe anders zu präsentieren.\n\nMehrere Plots in einem Diagramm: Mit der par() Funktion können wir das Layout und die Platzierung der Plots anpassen.\n\n\nMit dem mfrow Parameter geben wir an, wie viele Zeilen und Spalten von Plots wir haben wollen. Hier haben wir 2 Zeilen und 2 Spalten.\nMit dem mar Parameter können wir die Ränder des Plots anpassen.\nMit dem oma Parameter können wir Platz für den Titel des gesamten Diagramms hinzufügen.\nMit dem cex Parameter können wir die Schriftgrösse anpassen.\n\n\npar(mfrow = c(2, 2), # 2 Zeilen und 2 Spalten\n    mar = c(4, 4, 2, 1), # verkleinert die Ränder\n    oma = c(0, 0, 4, 0), # fügt Platz für den Titel hinzu\n    cex = 0.8) # verkleinert die Schriftgrösse\n\n\nBoxplots erstellen: Wir erstellen Boxplots für die Durchschnittstemperaturen und Niederschlagssummen in Bern und auf dem Grossen St. Bernhard.\n\nZusätzlich beschränken wir die Daten auf die Jahre bis 1980.\n\nboxplot(Bern_Mitteltemperatur ~ Saison,\n    data = meteodaten[meteodaten$Jahr &lt;= 1980, ],\n    ylim = c(-10, 20),\n    ylab = \"Durchschnittstemperatur in °C\",\n    main = \"Durchschnittstemperatur Bern\")\n\nWir beachten auch hier wieder die Verwendung des ~-Operators, um die linke Seite von der rechten Seite zu trennen. In diesem Fall bedeutet dies, dass wir die Spalte Bern_Mitteltemperatur nach der Spalte Saison gruppieren wollen.\nWir verwenden die ylim Parameter, um die y-Achse auf einen bestimmten Bereich zu beschränken. Dies ist nützlich, um die Plots besser vergleichen zu können.\nDie Selelektion der Daten erflogt im data Parameter. Hier wählen wir nur die Daten bis ins Jahr 1980 aus.\n\nGesamte Überschrift für alle Plots hinzufügen: Wir fügen eine Überschrift für alle Plots hinzu.\n\n\ntitle(\"Klimadaten in Bern und auf dem Grossen St. Bernhard\", outer = TRUE)\n\nDer outer Parameter gibt an, dass die Überschrift über allen Plots platziert werden soll.",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Einfache Plots erstellen</span>"
    ]
  },
  {
    "objectID": "plots_in_R.html#grafiken-speichern",
    "href": "plots_in_R.html#grafiken-speichern",
    "title": "3  Einfache Plots erstellen",
    "section": "4.4 Grafiken speichern",
    "text": "4.4 Grafiken speichern\nGrafiken können entweder in RStudio unter dem Reiter “Export” … “Save Plot as PDF” oder “…Image” gespeichert werden.\nAlternativ können mit den Funktionen pdf(), jpeg() und png() Grafiken direkt in R gespeichert werden.\n\n# PDF-Datei erstellen\npdf(file = \"boxplots.pdf\",\n    width = 9,\n    height = 4.5) # Grösse des PDFs in Inch\n\n# Boxplot aus der vorherigen Sektion erstellen\nboxplot(Bern_Mitteltemperatur ~ Saison,\n        data = meteodaten[meteodaten$Jahr &lt;= 1980, ],\n        ylim = c(-10, 20),\n        ylab = \"Durchschnittstemperatur in °C\",\n        main = \"Durchschnittstemperatur Bern\")\n\n# PDF-Datei schliessen\ndev.off()\n\n\n\n\n\n\n\n\nParameter\nBeschreibung\n\n\n\n\nfile\nDateiname und Speicherort. Auch hier können absolute und relative Dateipfade verwendet werden. Wichtig ist die entsprechende Dateieindung (.pdf, .jpeg oder .png) anzugeben.\n\n\nwidth\nBreite des Plots in Inch.\n\n\nheight\nHöhe des Plots in Inch.\n\n\ndev.off()\nIst kein eigentlicher Parameter, aber ist am Ende jeder der Funktionen benötigt, um den Export zu beenden.",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Einfache Plots erstellen</span>"
    ]
  },
  {
    "objectID": "plots_in_R.html#übungen-3",
    "href": "plots_in_R.html#übungen-3",
    "title": "3  Einfache Plots erstellen",
    "section": "Übungen 3",
    "text": "Übungen 3\n\n3.1 Klimadiagramm\n\nLadet den Datensatz meteodaten_tag.csv nach dem Excel Export in R (ACHTUNG: NA-Werte sind sowohl mit’-’als auch mit’NA’)kodiert, deshalb: na.strings= c('-','NA'))\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# CSV-Datei einlesen\nmeteodaten_tag &lt;- read.csv('Data/meteodaten_tag.csv',\n    sep = ',',\n    header = TRUE,\n    na.strings = c('-', 'NA'))\n\n\n\n\n\nMit str() ansehen, ob Daten korrekt (z.B.als numerisch) gelesen wurden.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nstr(meteodaten_tag)\n\n'data.frame':   4627 obs. of  7 variables:\n $ Jahr                : int  2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\n $ Monat               : int  1 1 1 1 1 1 1 1 1 1 ...\n $ Tag                 : int  1 2 3 4 5 6 7 8 9 10 ...\n $ Wochentag           : chr  \"Sa\" \"So\" \"Mo\" \"Di\" ...\n $ Temperatur.C.       : num  3.6 4.8 4.6 6.2 8.1 6.9 3.4 2.4 5.5 5.1 ...\n $ Niederschlag.mm.Tag.: num  0 0 0 0 0.2 0 0 0 0.5 1.8 ...\n $ Bewoelkung.Achtel.  : int  3 7 3 3 3 3 6 6 6 7 ...\n\n\n\n\n\n\nErstellt ein Histogramm (hist()) mit den Tagestemperaturen mit feinen Abständen (breaks=40).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nhist(meteodaten_tag$Temperatur.C.,\n     breaks = 40,\n     xlab = \"Temperatur in °C\",\n     ylab = \"Anzahl Tage\",\n     main = \"Histogramm der Tagestemperaturen in Bern\")\n\n\n\n\n\n\n\n\n\n\n\n\nWie sieht die Verteilung nach Augenmass aus?\nBerechnet die Monatsmittelwerte der Temperatur und der Bewölkung über alle Jahre (also Mittel über alle Jan, alle Feb,… wie in Klimadiagrammen). Achtung: Fehlwerte vorhanden!\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmonatsmittel &lt;-\n    aggregate(cbind(Temperatur.C., Bewoelkung.Achtel.) ~ Monat,\n        data = meteodaten_tag,\n        FUN = mean,\n        na.rm = TRUE)\n\nHinweis zur Funktion cbind(): cbind() fügt die Spalten Bern_Temperatur und Bern_Bewoelkung zusammen, um sie dann nach Monat zu gruppieren. Alternativ könnten wir die beiden Mittelwerte auch seperat berechnen und anschliessend mit einem merge() zusammenfügen.\n\ntemp_mittel &lt;- aggregate(Temperatur.C. ~ Monat,\n    data = meteodaten_tag,\n    FUN = mean,\n    na.rm = TRUE)\nbewoelkung_mittel &lt;- aggregate(Bewoelkung.Achtel. ~ Monat,\n    data = meteodaten_tag,\n    FUN = mean,\n    na.rm = TRUE)\n\nmonatsmittel &lt;- merge(temp_mittel, bewoelkung_mittel,\n    by = \"Monat\")\n\n\n\n\n\nErstellt in eine Abbildung mit zwei Barplots der Ergebnisse übereinander(par(mfrow=c(2,1))). Was erwartet ihr?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# Mehrere Plots in einem Diagramm\npar(mfrow = c(2, 1))\n\n# Barplot für die Monatsmittel der Temperatur\nbarplot(temp_mittel$Temperatur.C.,\n    names.arg = temp_mittel$Monat,\n    xlab = \"Monat\",\n    ylab = \"Temp. in °C\",\n    main = \"Monatsmittel der Temperatur in Bern\")\n\n# Barplot für die Monatsmittel der Bewölkung\nbarplot(bewoelkung_mittel$Bewoelkung.Achtel.,\n    names.arg = bewoelkung_mittel$Monat,\n    xlab = \"Monat\",\n    ylab = \"Bewölkung in Achteln\",\n    main = \"Monatsmittel der Bewölkung in Bern\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2 Boxplots\n\nWählt den Zeitraum 200-2001 in den täglichen Daten.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# Data Frame filtern und in einem neuen Objekt speichern\nmeteodaten_tag_2000_2001 &lt;- meteodaten_tag[meteodaten_tag$Jahr &gt;= 2000 & meteodaten_tag$Jahr &lt;= 2001, ]\n\n\n\n\n\nStellt die Temperaturen dieses Zeitrauemes als Funktion der Bewölkung in einem boxpolt()dar (je ein Boxplot pro Bewölkungsklasse). Beschriftet die Achsen und vergebt einen Titel\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nboxplot(Temperatur.C. ~ Bewoelkung.Achtel.,\n    data = meteodaten_tag_2000_2001,\n    ylab = \"Temperatur in °C\",\n    xlab = \"Bewölkung in Achteln\",\n    main = \"Temperaturen in Bern 2000-2001 nach Bewölkung\")\n\n\n\n\n\n\n\n\n\n\n\n\nUnter welchen Bewölkungsbedingungen ist die Spannweite und Varianz der Temperatur am grössten?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# Berechnung der Spannweite und Varianz der Temperatur für jede Bewölkungsklasse\nspannweite &lt;- aggregate(Temperatur.C. ~ Bewoelkung.Achtel.,\n    data = meteodaten_tag_2000_2001,\n    FUN = function(x) diff(range(x)))\n\nvarianz &lt;- aggregate(Temperatur.C. ~ Bewoelkung.Achtel.,\n    data = meteodaten_tag_2000_2001,\n    FUN = var)\n\n# Umbenennen der Spalten, um Verwechslungen zu vermeiden\nnames(spannweite)[2] &lt;- \"Spannweite\"\nnames(varianz)[2] &lt;- \"Varianz\"\n\n# Zusammenführen der Ergebnisse\nergebnisse &lt;- merge(spannweite, varianz, by = \"Bewoelkung.Achtel.\")\n\n# Ausgabe der Ergebnisse\nergebnisse\n\n  Bewoelkung.Achtel. Spannweite  Varianz\n1                  0       24.3 52.71585\n2                  1       29.0 60.76026\n3                  2       31.0 44.37131\n4                  3       33.5 54.83717\n5                  4       28.3 36.53915\n6                  5       24.5 34.10751\n7                  6       24.2 23.78013\n8                  7       21.7 29.81474\n9                  8       15.6 14.02061\n\n\n\n\n\n\nFindet heraus welcher Monat im Mittel der bewölkungsärmste und der -reichste ist (Im Mittel über die beiden Jahre). Wie viel Bewälkung gibt es im Mittel in diesen Monaten (in Achteln)?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# Berechnung der Monatsmittel der Bewölkung\nbewoelkung_mittel &lt;- aggregate(Bewoelkung.Achtel. ~ Monat,\n    data = meteodaten_tag_2000_2001,\n    FUN = mean,\n    na.rm = TRUE)\n\n# Bewölkungsärmster Monat\nbewoelkung_min &lt;- bewoelkung_mittel[which.min(bewoelkung_mittel$Bewoelkung.Achtel.), ]\nbewoelkung_min\n\n  Monat Bewoelkung.Achtel.\n8     8           1.854839\n\n# Bewölkungsreichster Monat\nbewoelkung_max &lt;- bewoelkung_mittel[which.max(bewoelkung_mittel$Bewoelkung.Achtel.), ]\nbewoelkung_max\n\n   Monat Bewoelkung.Achtel.\n12    12           5.016129",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Einfache Plots erstellen</span>"
    ]
  },
  {
    "objectID": "plots_in_R.html#footnotes",
    "href": "plots_in_R.html#footnotes",
    "title": "3  Einfache Plots erstellen",
    "section": "",
    "text": "Ein Faktor ist ein Datentyp in R, der kategorische Daten repräsentiert. Faktoren werden verwendet, um Daten zu kategorisieren und zu ordnen.↩︎\nWenn eine Spalte mit factor() bearbeitet wird, wird sie intern in diskrete Kategorien umgewandelt, jedoch ohne die ursprünglichen Daten zu überschreiben. Der levels Parameter bezieht sich auf die originalen Datenwerte, um sicherzustellen, dass R die Daten korrekt interpretiert. Die labels hingegen ändern nur, wie diese Daten für den Benutzer angezeigt werden. Dadurch bleibt der Inhalt des Data Frames unverändert, aber die Darstellung der Werte wird angepasst. Das ist nützlich, wenn man die Rohdaten beibehalten will, jedoch für Visualisierungen oder Präsentationen eine klarere oder kürzere Bezeichnung verwenden möchte.↩︎",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Einfache Plots erstellen</span>"
    ]
  },
  {
    "objectID": "packages_and_libraries.html",
    "href": "packages_and_libraries.html",
    "title": "4  Packages und Libraries",
    "section": "",
    "text": "5 Packages und Libraries\nIn R gibt es ähnlich wie in Python und anderen Programmiersprachen die Möglichkeit, zusätzliche Funktionalitäten durch das Einbinden von Packages und Libraries zu nutzen. In R werden diese durch den Befehl library() eingebunden.\nDie Pakete müssen einmalig installiert werden und können dann immer am Anfang eines Skripts oder Notebooks geladen werden.",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Packages und Libraries</span>"
    ]
  },
  {
    "objectID": "packages_and_libraries.html#pakete-installieren",
    "href": "packages_and_libraries.html#pakete-installieren",
    "title": "4  Packages und Libraries",
    "section": "5.1 Pakete installieren",
    "text": "5.1 Pakete installieren\nPakete können mit der Funktion install.packages() installiert werden. Zum Beispiel:\n\ninstall.packages(\"ggplot2\")\n\nUm Skripte und Notebooks portabel zu halten, ist es sinnvoll, die Installation von fehlenden Paketen am Anfang des Skripts oder Notebooks zu platzieren.\n\nif (!require(\"ggplot2\")) {\n  install.packages(\"ggplot2\")\n}",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Packages und Libraries</span>"
    ]
  },
  {
    "objectID": "packages_and_libraries.html#pakete-laden",
    "href": "packages_and_libraries.html#pakete-laden",
    "title": "4  Packages und Libraries",
    "section": "5.2 Pakete laden",
    "text": "5.2 Pakete laden\nPakete können mit der Funktion library() geladen werden. Zum Beispiel:\n\nlibrary(ggplot2)\n\nDie meisten Pakete haben eine Vielzahl von Funktionen, die genutzt werden können. Es ist ratsam, die Dokumentation des Pakets zu lesen, um die verfügbaren Funktionen und deren Anwendung zu verstehen. Die Dokumentation eines Pakets kann mit dem Befehl ? aufgerufen werden. Zum Beispiel:\n\n?ggplot2",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Packages und Libraries</span>"
    ]
  },
  {
    "objectID": "packages_and_libraries.html#häufig-genutzte-pakete",
    "href": "packages_and_libraries.html#häufig-genutzte-pakete",
    "title": "4  Packages und Libraries",
    "section": "5.3 Häufig genutzte Pakete",
    "text": "5.3 Häufig genutzte Pakete\nEinige der am häufigsten genutzten Pakete in R sind:\n\nggplot2: Ein Paket zur Erstellung von ansprechenden und aussagekräftigen Grafiken.\ndplyr: Ein Paket zur Datenmanipulation und -aggregation.\ntidyr: Ein Paket zur Datenbereinigung und -umformung.\nreadr: Ein Paket zur Einlesung von Daten aus verschiedenen Dateiformaten.\nstringr: Ein Paket zur Arbeit mit Zeichenketten.\nlubridate: Ein Paket zur Arbeit mit Datum und Uhrzeit.\ncaret: Ein Paket zur Erstellung von Modellen und zur Modellauswertung.\ntidyverse: Ein Paket, das eine Sammlung von Paketen für die Datenanalyse in R bereitstellt.\n\nEs gibt viele weitere Pakete, die für spezifische Anwendungen und Analysen entwickelt wurden. Es ist ratsam, die Dokumentation der Pakete zu lesen, um die verfügbaren Funktionen und deren Anwendung zu verstehen.",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Packages und Libraries</span>"
    ]
  },
  {
    "objectID": "packages_and_libraries.html#beispiel-einbinden-des-ggplot2-pakets",
    "href": "packages_and_libraries.html#beispiel-einbinden-des-ggplot2-pakets",
    "title": "4  Packages und Libraries",
    "section": "5.4 Beispiel: Einbinden des ggplot2 Pakets",
    "text": "5.4 Beispiel: Einbinden des ggplot2 Pakets\nAn einem einfachen Beispiel sehen wir, wie mit Hilfe der Pakete ggplot2 und plotly ein interaktives Diagramm erstellt werden kann.\n\n# Bibliotheken laden\nlibrary(ggplot2)\nlibrary(plotly)\n\n# Daten für den Plot vorbereiten\n# Konvertiere die Spalte Saison in einen einfacheren Faktor für die Darstellung\nmeteodaten$Saison &lt;- factor(meteodaten$Saison,\n                            levels = c(\"Fruehling(MAM)\",\n                                       \"Sommer(JJA)\",\n                                       \"Herbst(SON)\",\n                                       \"Winter(DJF)\"),\n                            labels = c(\"Frühling\",\n                                       \"Sommer\",\n                                       \"Herbst\",\n                                       \"Winter\"))\n\n# Plot mit ggplot2 erstellen\ngg &lt;- ggplot(meteodaten, aes(x = Jahr,\n        y = Bern_Mitteltemperatur,\n        color = Saison)) +\n    geom_line(linewidth = 1.2) +  # Linienbreite anpassen\n    geom_hline(yintercept = 0,\n        linetype = \"dashed\") +  # Horizontale Linie bei 0\n    labs(title = \"Saisonale Durchschnittstemperaturen in Bern\",\n        x = \"Jahr\",\n        y = \"Durchschnittstemperatur in °C\") +\n    theme_minimal() +  # Minimalistisches Theme für einen klaren Look\n    scale_color_manual(values = c(\"Frühling\" = \"green\",\n                                  \"Sommer\" = \"red\",\n                                  \"Herbst\" = \"orange\",\n                                  \"Winter\" = \"blue\")) +  # Farben anpassen\n    theme(plot.title = element_text(hjust = 0.5,\n        size = 16))  # Zentriere Titel und passe die Schriftgröße an\n\n# Plot interaktiv machen mit plotly\ngg_interaktiv &lt;- ggplotly(gg)\n\n# Interaktiver Plot anzeigen\ngg_interaktiv\n\n\n\nInteraktives Diagramm der saisonalen Durchschnittstemperaturen in Bern",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Packages und Libraries</span>"
    ]
  },
  {
    "objectID": "packages_and_libraries.html#übungen",
    "href": "packages_and_libraries.html#übungen",
    "title": "4  Packages und Libraries",
    "section": "Übungen",
    "text": "Übungen\n\n3.4 R als GIS Ersatz\n\nInstalliert das Paket maps und ladet es in R (z.B. library(maps)) Findet die x,y-Koordinaten von Bern und dem Gr. S. Bernhard heraus.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nlibrary(maps)\n\n# Koordinaten für Bern und Grosser St. Bernhard\nbern_coords &lt;- c(7.4474, 46.9481)\ngross_bernhard_coords &lt;- c(7.1761, 45.8689)\n\n\n\n\n\nVersucht eine Europakarte herzustellen und Bern und Gr. Bernhard als Punkte auf die Karte zu plotten und die Punkte mit Stationsnamen zu versehen\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# Erstelle eine Europakarte\nmap(\"world\",\n    xlim = c(-10, 20),\n    ylim = c(35, 55),\n    fill = TRUE,\n    col = \"lightgray\")\n\n\n# Punkte auf der Karte plotten\npoints(bern_coords[1],\n       bern_coords[2],\n       col = \"red\",\n       pch = 19,\n       cex = 1.5)\npoints(gross_bernhard_coords[1],\n       gross_bernhard_coords[2],\n       col = \"blue\",\n       pch = 19,\n       cex = 1.5)\n\n# Text hinzufügen\ntext(bern_coords[1],\n     bern_coords[2],\n     labels = \"Bern\",\n     pos = 3,\n     cex = 0.8,\n     col = \"red\")\ntext(gross_bernhard_coords[1],\n     gross_bernhard_coords[2],\n     labels = \"Gr. St. Bernhard\",\n     pos = 3,\n     cex = 0.8,\n     col = \"blue\")",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Packages und Libraries</span>"
    ]
  },
  {
    "objectID": "loops_and_functions.html",
    "href": "loops_and_functions.html",
    "title": "5  Schlaufen und Funktionen",
    "section": "",
    "text": "6 Schlaufen und Funktionen",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Schlaufen und Funktionen</span>"
    ]
  },
  {
    "objectID": "loops_and_functions.html#if-und-else",
    "href": "loops_and_functions.html#if-und-else",
    "title": "5  Schlaufen und Funktionen",
    "section": "6.1 if() und else()",
    "text": "6.1 if() und else()\nMit if() und else() können Bedingungen in R überprüft und entsprechende Aktionen ausgeführt werden. Die Syntax ist wie folgt:\n\nif (Bedingung) {\n  # Aktion, wenn die Bedingung TRUE ist\n} else {\n  # Aktion, wenn die Bedingung FALSE ist\n}\n\nZum Beispiel:\n\nx &lt;- 10\nif (x &gt; 5) {\n  print(paste(x, \"ist grösser als 5\"))\n} else {\n  print(\"x ist kleiner oder gleich 5\")\n}\n\n[1] \"10 ist grösser als 5\"\n\n\nHier verwenden wir zusätzlich die Funktion paste(), um Text und Variablen zu kombinieren. Dies ist ohne nicht direkt möglich.\n\n6.1.1 ifelse() als Vektoroperation\nifelse() ist eine Funktion, die eine Bedingung auf einen Vektor anwendet und basierend auf der Bedingung Werte zurückgibt. Die Syntax ist wie folgt:\n\nifelse(Bedingung, Wert_wenn_TRUE, Wert_wenn_FALSE)\n\nZum Beispiel:\n\nvectorA &lt;- c(1, 2, 3, 4, 5)\nifelse(vectorA == 3, \"Drei\", \"Nicht Drei\")\n\n[1] \"Nicht Drei\" \"Nicht Drei\" \"Drei\"       \"Nicht Drei\" \"Nicht Drei\"",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Schlaufen und Funktionen</span>"
    ]
  },
  {
    "objectID": "loops_and_functions.html#schleifen",
    "href": "loops_and_functions.html#schleifen",
    "title": "5  Schlaufen und Funktionen",
    "section": "6.2 Schleifen",
    "text": "6.2 Schleifen\nSchleifen sind nützlich, um eine bestimmte Aktion mehrmals auszuführen. In R gibt es verschiedene Arten von Schleifen, darunter for, while und repeat.\n\n6.2.1 for Schleife\nDie for Schleife wird verwendet, um eine Aktion für jedes Element in einer Sequenz auszuführen. Die Syntax ist wie folgt:\n\nfor (Element in Sequenz) {\n  # Aktion, die für jedes Element ausgeführt wird\n}\n\nZum Beispiel:\n\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nSchleifen mit Laufindex\nLaufindexe können in R auch ausserhalb der Schleife definiert werden. Zum Beispiel:\n\noriginal_vector &lt;- c(1, 2, 3, 4, 5)\nresult_vector &lt;- vector() # Leerer Vektor für das Ergebnis\n\n# Laufindex definieren\nj &lt;- 1\n\nfor (i in original_vector) {\n  result_vector[j] &lt;- i * 2\n  j &lt;- j + 1\n}\n\nresult_vector\n\n[1]  2  4  6  8 10\n\n\nBemerkung: aus Python kennen wir j++ oder j += 1 um den Laufindex zu erhöhen. In R gibt es keinen solchen Shortcut.",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Schlaufen und Funktionen</span>"
    ]
  },
  {
    "objectID": "loops_and_functions.html#eigene-funktionen",
    "href": "loops_and_functions.html#eigene-funktionen",
    "title": "5  Schlaufen und Funktionen",
    "section": "6.3 Eigene Funktionen",
    "text": "6.3 Eigene Funktionen\nFunktionen sind nützlich, um wiederkehrende Aktionen zu kapseln und zu abstrahieren. In R können eigene Funktionen mit dem function Schlüsselwort definiert werden. Die Syntax ist wie folgt:\n\nfunktion_name &lt;- function(Parameter1, Parameter2, ...) {\n  # Aktionen, die die Funktion ausführt\n  return(Ergebnis)\n}\n\nZum Beispiel:\nWir schreiben eine Funktion, die die Summe der Quadrate von zwei Zahlen berechnet.\n\nsumme_quadrate &lt;- function(x, y) {\n  summe &lt;- x^2 + y^2\n  return(summe)\n}\n\nDie Funktion kann dann wie folgt aufgerufen werden:\n\nsumme_quadrate(3, 4)\n\n[1] 25",
    "crumbs": [
      "Einführung R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Schlaufen und Funktionen</span>"
    ]
  },
  {
    "objectID": "deskriptive-statistik.html",
    "href": "deskriptive-statistik.html",
    "title": "6  Deskriptive Statistik",
    "section": "",
    "text": "6.1 Grundgesamtheit vs. Stichprobe",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "deskriptive-statistik.html#grundgesamtheit-vs.-stichprobe",
    "href": "deskriptive-statistik.html#grundgesamtheit-vs.-stichprobe",
    "title": "6  Deskriptive Statistik",
    "section": "",
    "text": "Grundgesamtheit\nStichprobe\n\n\n\n\nBeispiele\nAlle Studierenden im Bachelorstudium\nDie 200 Studierenden, die an deiner Studie teilnehmen\n\n\n\nDie Wahlberechtigten einer Wahl\nDiejenigen, die bei einer Wahlumfrage befragt werden, um eine Prognose zu erstellen\n\n\n\nAlle Bücher in einer Bibliothek\nDie Bücher, die du aus dem Regal nimmst\n\n\nSchreibweise\n\n\n\n\nGenerell\nGriechische Buchstaben\nLateinische Buchstaben\n\n\nUmfang\n\\(N\\) (Gesamtanzahl der statistischen Einheiten in der Grundgesamtheit)\n\\(n\\) (Grösse der Stichprobe)\n\n\nMittelwert\n\\(\\mu\\)\n\\(\\bar{x}\\) oder \\(M\\)\n\n\nStandardabweichung\n\\(\\sigma\\)\n\\(s\\) oder \\(SD\\)",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "deskriptive-statistik.html#skalen",
    "href": "deskriptive-statistik.html#skalen",
    "title": "6  Deskriptive Statistik",
    "section": "6.2 Skalen",
    "text": "6.2 Skalen\n\n6.2.1 Kategoriale Variablen\n\n6.2.1.1 Nominalskala\n\n\n\n\n\n\nNominalskalen Beispiele\n\n\n\n\nGeschlecht\nAugenfarbe\nNationalität\n\n\nOperationen\n\nGleichheit: \\(x = y\\)\nUngleichheit: \\(x \\neq y\\)\nKategorien: \\(x \\in \\{A, B, C\\}\\)\n\n\n\n\nNominalskalen sind die einfachste Form der Skala und werden verwendet, um Kategorien zu unterscheiden. Die Kategorien haben keine natürliche Reihenfolge oder Rangfolge. Beispiele für Nominalskalen sind Geschlecht, Augenfarbe oder Nationalität.\n\n\n6.2.1.2 Ordinalskala\n\n\n\n\n\n\nOrdinalskalen Beispiele\n\n\n\n\nSchulnoten\nsozioökonomischer Status\nKundenzufriedenheit\n\n\nOperationen\n\nOrdnung: \\(x &lt; y\\)\nUngleichheit: \\(x \\neq y\\)\nGrösse: \\(x &gt; y\\)\nKategorien: \\(x \\in \\{A, B, C\\}\\)\n\n\n\n\nOrdinalskalen werden verwendet, um Kategorien zu unterscheiden, die eine natürliche Reihenfolge oder Rangfolge haben. Die Abstände zwischen den Kategorien sind jedoch nicht gleich. Beispiele für Ordinalskalen sind Schulnoten, sozioökonomischer Status oder Kundenzufriedenheit.\n\n\n\n6.2.2 Metrische Variablen\n\n6.2.2.1 Intervallskala\n\n\n\n\n\n\nIntervallskalen Beispiele\n\n\n\n\nTemperatur in Celsius\nIQ\nGeld\n\n\nOperationen\n\nGleichheit: \\(x = y\\)\nUngleichheit: \\(x \\neq y\\)\nGrösse: \\(x &gt; y\\)\nDifferenz: \\(x - y\\)\nKategorien: \\(x \\in \\{A, B, C\\}\\)\n\n\n\n\nIntervallskalen werden verwendet, um kontinuierliche Variablen zu messen, bei denen die Abstände zwischen den Werten gleich sind, aber kein absoluter Nullpunkt vorhanden ist. Beispiele für Intervallskalen sind Temperatur in Celsius oder IQ.\n\n\n6.2.2.2 Verhältnisskala\n\n\n\n\n\n\nVerhältnisskalen Beispiele\n\n\n\n\nGewicht\nGrösse\nEinkommen\n\n\nOperationen\n\nGleichheit: \\(x = y\\)\nUngleichheit: \\(x \\neq y\\)\nGrösse: \\(x &gt; y\\)\nDifferenz: \\(x - y\\)\nVerhältnis: \\(x / y\\)\nKategorien: \\(x \\in \\{A, B, C\\}\\)\n\n\n\n\nVerhältnisskalen werden verwendet, um kontinuierliche Variablen zu messen, bei denen die Abstände zwischen den Werten gleich sind und ein absoluter Nullpunkt vorhanden ist. Beispiele für Verhältnisskalen sind Gewicht, Grösse oder Einkommen.",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "deskriptive-statistik.html#lageparameter-masse-der-zentraltendenz",
    "href": "deskriptive-statistik.html#lageparameter-masse-der-zentraltendenz",
    "title": "6  Deskriptive Statistik",
    "section": "6.3 Lageparameter / Masse der Zentraltendenz",
    "text": "6.3 Lageparameter / Masse der Zentraltendenz\n\n6.3.1 Modus \\(x_{mod}\\)\nDer Modus ist der Wert, der am häufigsten in einer Variablen vorkommt. Es ist möglich, dass eine Variable mehrere Modi hat (unimodal, bimodal, multimodal).\n\n\n6.3.2 Median \\(x_{med}\\)\nDer Median ist der Wert, der die Daten in zwei gleich grosse Teile teilt. Der Median ist robust gegenüber Ausreissern und wird verwendet, wenn die Daten nicht normalverteilt sind.\n\\[\n\\text{Median} = \\begin{cases}\n      x_{\\frac{n+1}{2}} & \\text{für ungerade Anzahl von Werten} \\\\\n      \\frac{1}{2} (x_{\\frac{n}{2}} + x_{\\frac{n}{2}+1}) & \\text{für gerade Anzahl von Werten}\n   \\end{cases}\n\\]\n\nRobustes Mass für die Lage von NICHT-symmetrisch verteilten Daten.\n\n\n\n6.3.3 Arithmetischer Mittelwert \\(\\bar{x}\\)\nDas arithmetische Mittel ist der Durchschnittswert einer Variablen und wird berechnet, indem alle Werte addiert und durch die Anzahl der Werte geteilt werden. Die Formel lautet:\n\\[\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i = \\frac{x_1 + x_2 + \\ldots + x_n}{n}\n\\]\nWo \\(\\bar{x}\\) das arithmetische Mittel ist, \\(n\\) die Anzahl der Werte und \\(x_i\\) die einzelnen Werte.\n\nAussagekräftig bei symmetrisch verteilten Daten.",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "deskriptive-statistik.html#streuungsparameter",
    "href": "deskriptive-statistik.html#streuungsparameter",
    "title": "6  Deskriptive Statistik",
    "section": "6.4 Streuungsparameter",
    "text": "6.4 Streuungsparameter\n\n6.4.1 Quantile \\(q\\%\\)\nDas \\(q\\%\\)-Quantil ist der Wert, unter dem \\(q\\%\\) der Daten liegen.\n\n6.4.1.1 Spezielle Quantile\n\nMedian ist \\(Q_{0.5}\\)\nQuartile: \\(Q_{0.25}\\), \\(Q_{0.5}\\), \\(Q_{0.75}\\)\nWhisker im Boxplot sind uneinheitlich definiert.\n\n\n\n\n6.4.2 Spannweite\nDie Spannweite ist die Differenz zwischen dem grössten und dem kleinsten Wert einer Variablen. Die Spannweite ist anfällig gegenüber Ausreissern.\n\\[\n\\text{Spannweite} = x_{\\text{max}} - x_{\\text{min}}\n\\]\n\n\n6.4.3 Varianz \\(s^2\\)\nMittle quadratische Abweichungen vom Mittelwert.\n\\[\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\n\\]\n\nSinnvoll bei metrischen Daten und wenn der Mittelwert ein geeignetes Mass für die Lage der Daten ist.\nStarker Einfluss von Ausreissern.\n\n\n\n6.4.4 Standardabweichung \\(s\\)\nDie Standardabweichung ist die Quadratwurzel der Varianz und gibt an, wie stark die Werte einer Variablen um den Mittelwert streuen.\n\\[\ns = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2}\n\\]\n\nSinnvoll bei metrischen Daten und wenn der Mittelwert ein geeignetes Mass für die Lage der Daten ist.\nStarker Einfluss von Ausreissern.\nEinfache Interpretation: Standardabweichung = 10 bedeutet, dass die Werte im Durchschnitt 10 Einheiten um den Mittelwert streuen.\n\n\n\n6.4.5 Schiefe\nEinfaches Mass für die Asymmetrie der Verteilung.\n\\[\n\\text{Schiefe} = \\frac{\\text{arithm. Mittel} - \\text{Median}}{\\text{Standardabweichung}}\n\\]\n\nNegative Schiefe: linksschief, rechtssteil\nPositive Schiefe: rechtsschief, linkssteil\n\n\n\n\nSchiefe der Verteilung",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "deskriptive-statistik.html#kreuztabelle-kontingenztafel",
    "href": "deskriptive-statistik.html#kreuztabelle-kontingenztafel",
    "title": "6  Deskriptive Statistik",
    "section": "6.5 Kreuztabelle / Kontingenztafel",
    "text": "6.5 Kreuztabelle / Kontingenztafel\n\nFür nominale Daten\nOrdinale und metrische Daten können in nominale Daten transformiert werden (z.b. Grenzüberschreitung ja/nein)\n\nBeispiel:\nEs werden 2000 Personen darüber befragt, ob sie Produkt A oder B bevorzugen. Das Ergebnis wird nach Geschlecht des Befragten ausgewertet.\n\n\n\nProdukt / Geschlecht\nMännlich\nWeiblich\nSumme\n\n\n\n\nA\n660\n440\n1100\n\n\nB\n340\n560\n900\n\n\nSumme\n1000\n1000\n2000\n\n\n\n\n6.5.1 Freiheitsgrade\n\nAnzahl Beobachtungen abzüglich Anzahl geschätzter Parameter.\nBeispiel: Standardabweichung aus Stichprobe mit \\(n\\) Beobachtungen\n\n\\[\ns = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2}\n\\]\n\nDer Mittelwert wurde bereits aus den Beobachtungen geschätzt. Wenn man den Mittwelwert und alle Beobachtungen ausser der letzten kennt (\\(n-1\\)) dann kann man diese berechnen, es besteht also keine “Freiheit” mehr.\n\n\n# Population erstellen\npopulation &lt;- rnorm(100000, mean = 0, sd = 10)\npopulation_sd &lt;- sqrt(sum((population - mean(population))^2) / length(population))\n\n# Viele Stichproben ziehen, aber mit kleinerer Stichprobengröße\nn_samples &lt;- 1000\nsample_size &lt;- 10  # kleinere Stichprobengröße\nmean_sd_n &lt;- 0\nmean_sd_n_minus_1 &lt;- 0\n\nfor(i in 1:n_samples) {\n    sample_data &lt;- sample(population, sample_size)\n    mean_sd_n &lt;- mean_sd_n + sqrt(sum((sample_data - mean(sample_data))^2) / sample_size)\n    mean_sd_n_minus_1 &lt;- mean_sd_n_minus_1 + sqrt(sum((sample_data - mean(sample_data))^2) / (sample_size-1))\n}\n\nmean_sd_n &lt;- mean_sd_n / n_samples\nmean_sd_n_minus_1 &lt;- mean_sd_n_minus_1 / n_samples\n\n# Prozentuale Abweichungen berechnen\nbias_n &lt;- (mean_sd_n - population_sd) / population_sd * 100\nbias_n_minus_1 &lt;- (mean_sd_n_minus_1 - population_sd) / population_sd * 100\n\n\nWahre Standardabweichung der Population: 10.01\nDurchschnittliche Schätzung mit n: 9.24 (Abweichung: -7.67%)\nDurchschnittliche Schätzung mit n-1: 9.74 (Abweichung: -2.68%)\n\nDer Effekt der Freiheitsgrade ist besonders bei kleinen Stichproben bedeutsam. Bei einer Stichprobengröße von n=10 führt die Berechnung mit n zu einer systematischen Unterschätzung von etwa 7%, während die Korrektur mit n-1 die Unterschätzung auf etwa 2% reduziert. Bei größeren Stichproben wird dieser Unterschied kleiner, da ein einzelner Freiheitsgrad weniger ins Gewicht fällt (bei n=100 macht ein Freiheitsgrad nur noch 1% aus, bei n=10 sind es 10%).",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "verteilungen.html",
    "href": "verteilungen.html",
    "title": "7  Verteilungen",
    "section": "",
    "text": "7.1 Theoretische Verteilungen diskreter Zufallsvariablen",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "verteilungen.html#theoretische-verteilungen-diskreter-zufallsvariablen",
    "href": "verteilungen.html#theoretische-verteilungen-diskreter-zufallsvariablen",
    "title": "7  Verteilungen",
    "section": "",
    "text": "7.1.1 Diskrete Gleichverteilung\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(gridExtra)\n\n# Funktion zum Berechnen der Wahrscheinlichkeits- und Verteilungsfunktionen\nsimulate_dice &lt;- function(n_dice) {\n  rolls &lt;- replicate(1000000, sum(sample(1:6, n_dice, replace = TRUE)))  # Simulation von n_dice Würfeln\n  df &lt;- as.data.frame(table(rolls) / length(rolls)) %&gt;%\n    rename(x = rolls, probability = Freq) %&gt;%\n    mutate(x = as.numeric(as.character(x))) %&gt;%\n    arrange(x) %&gt;%\n    mutate(cumulative_probability = cumsum(probability))\n\n  # Zusätzliche Punkte für 0 und 1\n  df &lt;- rbind(data.frame(x = 0, probability = 0, cumulative_probability = 0),\n              df,\n              data.frame(x = max(df$x) + 1, probability = 0, cumulative_probability = 1))\n  return(df)\n}\n\n# Daten für 1 Würfel\ndf_1dice &lt;- simulate_dice(1)\n\n# Plot für die Wahrscheinlichkeitsfunktion (PDF) von 1 Würfel\nplot_pdf_1 &lt;- ggplot(df_1dice, aes(x = x, y = probability)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\", width = 0.7) +\n  labs(title = \"ein Würfel (PDF)\", x = \"x\", y = expression(f(x))) +\n  theme_minimal() +\n  ylim(0, max(df_1dice$probability, na.rm = TRUE) * 1.1) +\n  xlim(0, 7) +\n  scale_y_continuous(breaks = seq(0, 1/6, by = 1/6),\n                    labels = c(\"0\", \"1/6\"))\n\n# Plot für die kumulative Verteilungsfunktion (CDF) von 1 Würfel\nplot_cdf_1 &lt;- ggplot(df_1dice, aes(x = x, y = cumulative_probability)) +\n  geom_step(linewidth = 0.8, color = \"black\") +\n  labs(title = \"ein Würfel (CDF)\", x = \"x\", y = expression(F(x))) +\n  theme_minimal() +\n  ylim(0, 1) +\n  xlim(0, 7) +\n  scale_y_continuous(breaks = seq(0, 1, by = 1/6),\n                    labels = c(\"0\", \"1/6\", \"2/6\", \"3/6\", \"4/6\", \"5/6\", \"6/6\"))\n\n# Anordnung der beiden Plots in einem 2x1-Layout\ngrid.arrange(plot_pdf_1, plot_cdf_1, ncol = 2)\n\n\n\n\n\n\n\n\nFigure 7.1: Diskrete Wahrscheinlichkeits- und Verteilungsfunktionen für einen Würfel (Berechnet mit 1’000’000 Simulationen)\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(gridExtra)\n\n# Funktion zum Berechnen der Wahrscheinlichkeits- und Verteilungsfunktionen\nsimulate_dice &lt;- function(n_dice) {\n  rolls &lt;- replicate(10000, sum(sample(1:6, n_dice, replace = TRUE)))  # Simulation von n_dice Würfeln\n  df &lt;- as.data.frame(table(rolls) / length(rolls)) %&gt;%\n    rename(x = rolls, probability = Freq) %&gt;%\n    mutate(x = as.numeric(as.character(x))) %&gt;%\n    arrange(x) %&gt;%\n    mutate(cumulative_probability = cumsum(probability))\n  return(df)\n}\n\n# Daten für 2, 3 und 4 Würfel\ndf_2dice &lt;- simulate_dice(2)\ndf_3dice &lt;- simulate_dice(3)\ndf_4dice &lt;- simulate_dice(4)\n\n# Plots für die PDF und CDF von 2 Würfeln\nplot_pdf_2 &lt;- ggplot(df_2dice, aes(x = x, y = probability)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\", width = 0.7) +\n  labs(title = \"zwei Würfel (PDF)\", x = \"x\", y = expression(f(x))) +\n  theme_minimal() +\n  ylim(0, max(df_2dice$probability, na.rm = TRUE) * 1.1)\n\nplot_cdf_2 &lt;- ggplot(df_2dice, aes(x = x, y = cumulative_probability)) +\n  geom_step(linewidth = 0.8, color = \"black\") +\n  labs(title = \"zwei Würfel (CDF)\", x = \"x\", y = expression(F(x))) +\n  theme_minimal() +\n  ylim(0, 1)\n\n# Plots für die PDF und CDF von 3 Würfeln\nplot_pdf_3 &lt;- ggplot(df_3dice, aes(x = x, y = probability)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\", width = 0.7) +\n  labs(title = \"drei Würfel (PDF)\", x = \"x\", y = expression(f(x))) +\n  theme_minimal() +\n  ylim(0, max(df_3dice$probability, na.rm = TRUE) * 1.1)\n\nplot_cdf_3 &lt;- ggplot(df_3dice, aes(x = x, y = cumulative_probability)) +\n  geom_step(linewidth = 0.8, color = \"black\") +\n  labs(title = \"drei Würfel (CDF)\", x = \"x\", y = expression(F(x))) +\n  theme_minimal() +\n  ylim(0, 1)\n\n# Plots für die PDF und CDF von 4 Würfeln\nplot_pdf_4 &lt;- ggplot(df_4dice, aes(x = x, y = probability)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\", width = 0.7) +\n  labs(title = \"vier Würfel (PDF)\", x = \"x\", y = expression(f(x))) +\n  theme_minimal() +\n  ylim(0, max(df_4dice$probability, na.rm = TRUE) * 1.1)\n\nplot_cdf_4 &lt;- ggplot(df_4dice, aes(x = x, y = cumulative_probability)) +\n  geom_step(linewidth = 0.8, color = \"black\") +\n  labs(title = \"vier Würfel (CDF)\", x = \"x\", y = expression(F(x))) +\n  theme_minimal() +\n  ylim(0, 1)\n\n# Anordnung der Plots in einem 3x2-Layout\ngrid.arrange(plot_pdf_2, plot_pdf_3, plot_pdf_4, plot_cdf_2, plot_cdf_3, plot_cdf_4, ncol = 3, nrow = 2)\n\n\n\n\n\n\n\n\nFigure 7.2: Diskrete Wahrscheinlichkeits- und Verteilungsfunktionen für 2, 3 und 4 Würfel (Berechnet mit 100’000 Simulationen)\n\n\n\n\n\nMit mehr Würfeln kommt das immer näher an eine Normalverteilung\n\n\nCode\n# Lade benötigte Pakete\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(gridExtra)\n\n# Parameter definieren\nn_dice &lt;- 15       # Anzahl Würfel\nn_simulations &lt;- 100000  # Anzahl Simulationen\n\n# Dynamische xlim basierend auf minimaler/maximaler Würfelsumme\nx_min &lt;- n_dice * 1      # Minimale Summe (alle Würfel = 1)\nx_max &lt;- n_dice * 6      # Maximale Summe (alle Würfel = 6)\n\n# Funktion zur Simulation der Würfelsummen und Berechnung der Wahrscheinlichkeiten\nsimulate_dice &lt;- function(n_dice, n_simulations) {\n  \n  # Simulation: Summe von n_dice Würfeln pro Durchlauf\n  rolls &lt;- replicate(n_simulations, sum(sample(1:6, n_dice, replace = TRUE)))\n  \n  # Häufigkeitstabelle mit Wahrscheinlichkeiten und kumulativen Wahrscheinlichkeiten\n  df &lt;- as.data.frame(table(rolls)) %&gt;%\n    rename(x = rolls, probability = Freq) %&gt;%\n    mutate(\n      x = as.numeric(as.character(x)),         # x als numerisch\n      probability = probability / sum(probability),   # Wahrscheinlichkeiten normieren\n      cumulative_probability = cumsum(probability)     # Kumulative Verteilungsfunktion\n    ) %&gt;%\n    arrange(x)\n  \n  return(df)\n}\n\n# Simulation durchführen\ndf_results &lt;- simulate_dice(n_dice, n_simulations)\n\n# Wahrscheinlichkeitsfunktion (PDF) plotten\nplot_pdf &lt;- ggplot(df_results, aes(x = x, y = probability)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\", width = 0.7) +\n  labs(\n    title = paste(n_dice, \"Würfel (PDF)\"),\n    x = \"Summe der Würfel\",\n    y = expression(f(x))\n  ) +\n  theme_minimal() +\n  # x-Achse dynamisch setzen\n  xlim(c(x_min, x_max))\n\n# Kumulative Verteilungsfunktion (CDF) plotten\nplot_cdf &lt;- ggplot(df_results, aes(x = x, y = cumulative_probability)) +\n  geom_step(linewidth = 0.8, color = \"black\") +\n  labs(\n    title = paste(n_dice, \"Würfel (CDF)\"),\n    x = \"Summe der Würfel\",\n    y = expression(F(x))\n  ) +\n  theme_minimal() +\n  ylim(0, 1) +\n  # x-Achse dynamisch setzen\n  xlim(c(x_min, x_max))\n\n# Beide Plots nebeneinander ausgeben\ngrid.arrange(plot_pdf, plot_cdf, ncol = 2)\n\n\n\n\n\n\n\n\nFigure 7.3: Diskrete Wahrscheinlichkeits- und Verteilungsfunktionen für 15 Würfel (Berechnet mit 100’000 Simulationen)\n\n\n\n\n\n\n\n\n\n\n\nWas passiert bei extrem vielen Würfeln?\n\n\n\n\n\nSpannend ist dass die Streuung der Summen extrem klein wird.\n\n\nCode\n# Lade benötigte Pakete\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(gridExtra)\n\n# Parameter definieren\nn_dice &lt;- 1000       # Anzahl Würfel\nn_simulations &lt;- 100000  # Anzahl Simulationen\n\n# Dynamische xlim basierend auf minimaler/maximaler Würfelsumme\nx_min &lt;- n_dice * 1      # Minimale Summe (alle Würfel = 1)\nx_max &lt;- n_dice * 6      # Maximale Summe (alle Würfel = 6)\n\n# Funktion zur Simulation der Würfelsummen und Berechnung der Wahrscheinlichkeiten\nsimulate_dice &lt;- function(n_dice, n_simulations) {\n  \n  # Simulation: Summe von n_dice Würfeln pro Durchlauf\n  rolls &lt;- replicate(n_simulations, sum(sample(1:6, n_dice, replace = TRUE)))\n  \n  # Häufigkeitstabelle mit Wahrscheinlichkeiten und kumulativen Wahrscheinlichkeiten\n  df &lt;- as.data.frame(table(rolls)) %&gt;%\n    rename(x = rolls, probability = Freq) %&gt;%\n    mutate(\n      x = as.numeric(as.character(x)),         # x als numerisch\n      probability = probability / sum(probability),   # Wahrscheinlichkeiten normieren\n      cumulative_probability = cumsum(probability)     # Kumulative Verteilungsfunktion\n    ) %&gt;%\n    arrange(x)\n  \n  return(df)\n}\n\n# Simulation durchführen\ndf_results &lt;- simulate_dice(n_dice, n_simulations)\n\n# Wahrscheinlichkeitsfunktion (PDF) plotten\nplot_pdf &lt;- ggplot(df_results, aes(x = x, y = probability)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\", width = 0.7) +\n  labs(\n    title = paste(n_dice, \"Würfel (PDF)\"),\n    x = \"Summe der Würfel\",\n    y = expression(f(x))\n  ) +\n  theme_minimal() +\n  # x-Achse dynamisch setzen\n  xlim(c(x_min, x_max))\n\n# Kumulative Verteilungsfunktion (CDF) plotten\nplot_cdf &lt;- ggplot(df_results, aes(x = x, y = cumulative_probability)) +\n  geom_step(linewidth = 0.8, color = \"black\") +\n  labs(\n    title = paste(n_dice, \"Würfel (CDF)\"),\n    x = \"Summe der Würfel\",\n    y = expression(F(x))\n  ) +\n  theme_minimal() +\n  ylim(0, 1) +\n  # x-Achse dynamisch setzen\n  xlim(c(x_min, x_max))\n\n# Beide Plots nebeneinander ausgeben\ngrid.arrange(plot_pdf, plot_cdf, ncol = 2)\n\n\n\n\n\n\n\n\nFigure 7.4: Diskrete Wahrscheinlichkeits- und Verteilungsfunktionen für 1000 Würfel (Berechnet mit 100’000 Simulationen)\n\n\n\n\n\n\n\n\n\n\n7.1.2 Normalverteilung\n\n\n\n\n\n\nZentraler Grenzwertsatz\n\n\n\n\n\n\\[\n\\lim_{n \\to \\infty} \\frac{1}{n} \\sum_{i=1}^{n} X_i = \\mu\n\\]\nDer Zentrale Grenzwertsatz besagt, dass die Summe von unabhängigen, identisch verteilten Zufallsvariablen mit wachsendem \\(n\\) gegen eine Normalverteilung konvergiert.\n\n\n\n\\[\nf_{\\mu, \\sigma}(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n\\]\n\n\nCode\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n# Erzeugung der Normalverteilung\nx &lt;- seq(-4, 4, length.out = 1000)\ny_pdf &lt;- dnorm(x, mean = 0, sd = 1)\ny_cdf &lt;- pnorm(x, mean = 0, sd = 1)\n\n# Datensätze erstellen\ndf_pdf &lt;- data.frame(x = x, y = y_pdf)\ndf_cdf &lt;- data.frame(x = x, y = y_cdf)\n\n# PDF Plot\nplot_pdf &lt;- ggplot(df_pdf, aes(x = x, y = y)) +\n  geom_ribbon(data = subset(df_pdf, x &gt;= -3 & x &lt;= 3),\n             aes(ymin = 0, ymax = y, fill = \"99.73%\")) +\n  geom_ribbon(data = subset(df_pdf, x &gt;= -2 & x &lt;= 2),\n             aes(ymin = 0, ymax = y, fill = \"95.45%\")) +\n  geom_ribbon(data = subset(df_pdf, x &gt;= -1 & x &lt;= 1),\n             aes(ymin = 0, ymax = y, fill = \"68.27%\")) +\n  geom_line(linewidth = 1) +\n  geom_vline(xintercept = c(-3, -2, -1, 1, 2, 3), \n            linetype = \"dashed\", color = \"gray40\") +\n  labs(x = \"Standardabweichungen (σ)\", \n       y = \"f(x)\",\n       title = \"Dichtefunktion\") +\n  scale_x_continuous(breaks = -3:3,\n                    labels = paste0(c(\"-3\", \"-2\", \"-1\", \"0\", \"1\", \"2\", \"3\"), \"σ\")) +\n  scale_fill_manual(values = c(\n    \"68.27%\" = \"#2C7BB6\",\n    \"95.45%\" = \"#81B9D9\",\n    \"99.73%\" = \"#D1E5F0\"\n  )) +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n    legend.position = \"bottom\",\n    legend.title = element_blank()\n  )\n\n# CDF Plot\nplot_cdf &lt;- ggplot(df_cdf, aes(x = x, y = y)) +\n  geom_line(linewidth = 1) +\n  geom_vline(xintercept = c(-3, -2, -1, 1, 2, 3), \n            linetype = \"dashed\", color = \"gray40\") +\n  labs(x = \"Standardabweichungen (σ)\", \n       y = \"F(x)\",\n       title = \"Verteilungsfunktion\") +\n  scale_x_continuous(breaks = -3:3,\n                    labels = paste0(c(\"-3\", \"-2\", \"-1\", \"0\", \"1\", \"2\", \"3\"), \"σ\")) +\n  scale_y_continuous(breaks = seq(0, 1, 0.2)) +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank()\n  )\n\n# Plots nebeneinander anordnen\ngrid.arrange(plot_pdf, plot_cdf, ncol = 2)\n\n\n\n\n\n\n\n\nFigure 7.5: Links: Wahrscheinlichkeitsdichte (PDF), Rechts: Verteilungsfunktion (CDF) der Normalverteilung\n\n\n\n\n\n\nSymmetrisch zur Achse \\(x = \\mu\\)\nunimodal mit Maximum bei \\(x = \\mu\\)\nWendepunkte bei \\(x = \\mu \\pm \\sigma\\)\nasymptotisch gegen 0\n\n\n7.1.2.1 Standardnormalverteilung\nDurch eine Transformation zu \\(\\mu = 0\\) und \\(\\sigma = 1\\) erhält man die Standardnormalverteilung.\n\\[\nZ = \\frac{X - \\mu}{\\sigma}\n\\]\nWobei \\(Z\\) die standardisierte Zufallsvariable, \\(X\\) die ursprüngliche Zufallsvariable und \\(\\mu\\) und \\(\\sigma\\) der Mittelwert und die Standardabweichung der ursprünglichen Verteilung sind.",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Verteilungen</span>"
    ]
  },
  {
    "objectID": "statistische-tests.html",
    "href": "statistische-tests.html",
    "title": "8  Statistische Tests",
    "section": "",
    "text": "8.1 Standardabweichung vs. Standardfehler\nStatistische Tests sind essenziell, um Hypothesen über Daten zu überprüfen.\nDer Standardfehler ist ein Mass für die Genauigkeit eines Schätzers. Er ist definiert als die Standardabweichung der Schätzfunktion.\n\\[\ns_{\\overline{x}} = \\sqrt{\\frac{s^2}{n}}\n\\]\nWo \\(s_{\\overline{x}}\\) der Standardfehler des Mittelwerts ist, \\(s^2\\) die Varianz der Stichprobe und \\(n\\) die Anzahl der Beobachtungen.\nD.h. der Standardfehler ist gross, wenn die Varianz gross ist und/oder die Stichprobe klein ist.\nDie Standardfehler sind dank dem zentralen Grenzwertsatz normalverteilt.",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistische Tests</span>"
    ]
  },
  {
    "objectID": "statistische-tests.html#standardabweichung-vs.-standardfehler",
    "href": "statistische-tests.html#standardabweichung-vs.-standardfehler",
    "title": "8  Statistische Tests",
    "section": "",
    "text": "Beispiel\n\n\n\nBeim Start zum Engadiner Skimarathon wird ein Bus vermisst. Bei der Suche findest du einen Parkplatz einen Bus. Du schaust in den Bus und stellt fest, dass das durchschnittliche Alter der Personen vermutlich bei ca. 80 Jahren liegt.\nDie Teilnehmer am Skimarathon haben ein mittleres Alter von 40 Jahren mit einer Standardabweichung von 10 Jahren, wobei wir annehmen, dass die Alter ungefähr normalverteilt ist.\nDer Standardfehler misst nun die Genauigkeit des Schätzers, also wie genau der Mittelwert der Stichprobe den Mittelwert der Population schätzt.\nIm gefundenen Bus befinden sich 50 Personen mit einem durchschnittlichen Alter von 80 Jahren.\nDer Standardfehler des Mittelwerts beträgt:\n\\[\ns_{\\overline{x}} = \\sqrt{\\frac{s^2}{n}} = \\sqrt{\\frac{10^2}{50}} = \\sqrt{2} \\approx 1.41 \\text{ Jahre}\n\\]\nDie Differenz zwischen dem Mittelwert der Stichprobe und dem Mittelwert der Population beträgt 40 Jahre, und ist damit grösser als 28 Standardfehler.\nAus der Normalverteilung können wir also schliessen, dass der Bus mit 99.9% Wahrscheinlichkeit nicht die Teilnehmer des Skimarathons enthält.\n\n\n\n8.1.1 Hypothesen\nEine Hypothese ist eine testbare Aussage über eine Population. In der Statistik gibt es zwei Hauptarten von Hypothesen:\n\n8.1.1.1 Nullhypothese \\(H_0\\)\nDie Nullhypothese postuliert, dass es keinen Effekt oder Unterschied gibt. Zum Beispiel könnte H₀ aussagen, dass es keinen Unterschied zwischen den Mittelwerten zweier Gruppen gibt.\n\n\n8.1.1.2 Alternativhypothese \\(H_A\\) oder \\(H_1\\)\nDie Alternativhypothese widerspricht der Nullhypothese und postuliert, dass es einen Effekt oder Unterschied gibt. Alternativhypothesen können einseitig (z.B. \\(H_1: \\mu &gt; \\mu_0\\)) oder zweiseitig (z.B. \\(H_1: \\mu \\neq \\mu_0\\)) sein.",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistische Tests</span>"
    ]
  },
  {
    "objectID": "statistische-tests.html#testtheorie",
    "href": "statistische-tests.html#testtheorie",
    "title": "8  Statistische Tests",
    "section": "8.2 Testtheorie",
    "text": "8.2 Testtheorie\n\nHypothesen aufstellen\n\nFormuliere eine Nullhypothese \\(H_0\\) (z.B. „kein Unterschied zwischen Mittelwerten“) und eine Alternativhypothese \\(H_1\\) (z.B. „es gibt einen Unterschied“).\n\nSignifikanzniveau \\(\\alpha\\) festlegen\n\nHäufig \\(\\alpha = 0.05\\). Wenn dein p-Wert kleiner ist als 0.05, lehnst du \\(H_0\\) ab (auf 5%-Niveau).\n\nStichprobe erheben\n\nDaten sammeln (z.B. Zufallsstichprobe) und Kennwerte (Mittelwert, Varianz, etc.) berechnen.\n\nTeststatistik berechnen\n\nBeim t-Test rechnest du einen t-Wert (Teststatistik) aus. Dieser t-Wert sagt dir, wie viele „Standardfehler“ deine gemessene Differenz vom erwarteten Wert (unter \\(H_0\\)) entfernt ist.\n\n\\[\nt = \\frac{\\overline{x} - \\mu_0}{s_{\\overline{x}}}\n\\]\n\n\\(\\overline{x}\\): Mittelwert deiner Stichprobe\n\n\\(\\mu_0\\): unter \\(H_0\\) vermuteter Populationsmittelwert (oder z.B. Differenz von 0 zwischen zwei Gruppen)\n\n\\(s_{\\overline{x}} = \\frac{s}{\\sqrt{n}}\\): Standardfehler des Mittelwerts, basierend auf der Stichproben-Standardabweichung \\(s\\) und der Stichprobengrösse \\(n\\)\n\n\n\n\n\n\n\n\nt-Test\n\n\n\nEin t-Test ist ein statistischer Test, der oft genutzt wird, um Mittelwerte zu vergleichen oder einen Mittelwert mit einem Referenzwert zu prüfen. Beispielsweise kannst du testen, ob das Durchschnittsgewicht einer Stichprobe signifikant von 70 kg abweicht (\\(H_0: \\mu = 70\\)).\nVoraussetzung ist, dass die Daten metrisch, ohne Ausreisser und symetrisch verteilt sind.\nDer Kern des t-Tests:\n\nDu berechnest den t-Wert als \\(\\frac{\\text{Abweichung des Mittelwerts}}{\\text{Standardfehler}}\\).\n\nAus diesem t-Wert und den Freiheitsgraden (z.B. \\(n-1\\)) bestimmt man den p-Wert mithilfe der t-Verteilung.\n\nIst der p-Wert kleiner als das vorab festgelegte Signifikanzniveau \\(\\alpha\\), so lehnt man \\(H_0\\) ab.\n\nEin typisches Beispiel ist der Zweistichproben-t-Test (unabhängige Gruppen), bei dem untersucht wird, ob sich zwei Mittelwerte (z.B. Gruppe A vs. Gruppe B) signifikant unterscheiden.\n\n\n\np-Wert bestimmen und Entscheidung treffen\n\nAus dem t-Wert (und den Freiheitsgraden \\(\\text{df} = n-1\\) oder ähnlich) kannst du den p-Wert ablesen (z.B. mittels t-Verteilungstabellen oder Software). Der p-Wert gibt an, wie wahrscheinlich (oder selten) eine so grosse oder grössere Abweichung zufällig auftreten würde, wenn \\(H_0\\) wahr wäre.\n\nRichtlinie: Ist der p-Wert kleiner als \\(\\alpha\\) (z.B. &lt; 0.05), lehnen wir \\(H_0\\) ab – das Ergebnis gilt als „statistisch signifikant“.\n\n\n\n8.2.1 t-Wert vs. p-Wert\n\nDer t-Wert ist der numerische „Abstand“ deiner beobachteten Daten (Mittelwertdifferenz) vom Wert unter \\(H_0\\), gemessen in Einheiten des Standardfehlers.\n\nDer p-Wert ist die Wahrscheinlichkeit, einen t-Wert (oder Teststatistik) zu erhalten, der mindestens so extrem ist wie dein beobachteter, wenn \\(H_0\\) gilt.\n\nOder vereinfacht:\n- t-Wert: „Wir sind 2.5 Standardfehler vom erwarteten Wert entfernt.“\n- p-Wert: „Diese Abweichung kommt nur mit 1% Wahrscheinlichkeit zustande, wenn \\(H_0\\) stimmt.“\nBeide Werte gehören zusammen: Ohne t-Wert weisst du nicht, wie stark die Abweichung ist; ohne p-Wert weisst du nicht, wie (un)wahrscheinlich diese Abweichung unter der Nullhypothese wäre.\n\n\n8.2.2 Fehlerarten\n\n\n\nTestentscheidung\n\\(H_0\\) nicht ablehnen\n\\(H_0\\) ablehnen\n\n\n\n\n\\(H_0\\) wahr\nRichtige Entscheidung\nFehler 1. Art\n\n\n\\(H_0\\) falsch\nFehler 2. Art\nRichtige Entscheidung\n\n\n\n\nFehler 1. Art (Alpha-Fehler): Wir lehnen \\(H_0\\) ab, obwohl \\(H_0\\) wahr ist.\nFehler 2. Art (Beta-Fehler): Wir nehmen \\(H_0\\) an, obwohl \\(H_0\\) falsch ist.\nEs gibt keine Testverfahren, die beide Fehlerarten gleichzeitig minimieren können.\nDas Signifikanzniveau \\(\\alpha\\) ist die Wahrscheinlichkeit für einen Fehler 1. Art.\nDer Fehler 2. Art ist in der Regel weniger gravierend.\n\n\n\n8.2.3 Mittwelwerte Testen\n\nMittelwert \\(\\mu\\) und Standardabweichung \\(\\sigma\\) aus \\(X_{\\text{Mittel}}\\) und \\(s_x\\) schätzen.\nDas führt bei kleinen Stichproben zu grossen Standardfehlern.\nes ist unwahrscheinlich, dass die Stichprobe exakt das Mittel der Grundgesamtheit trifft.\nDadurch wird die Verteilung der Teststatistik \\(t\\) breiter.\n\n\n\n\n\n\n\nBeispiel\n\n\n\nHypothesen:\n\n\\(H_0\\): Erwartere Sept. bis Nov. Mitteltemperatur beträgt 9°C (\\(x = \\mu_0\\))\n\\(H_1\\): Erwartere Sept. bis Nov. Mitteltemperatur weicht signifikant von 9°C ab (\\(x \\neq \\mu_0\\))\n\nTeststatistik:\n\\[\n\\begin{aligned}\nT &= \\frac{\\overline{x} - \\mu_0}{s_{\\overline{x}}} \\\\\n  &= \\frac{\\overline{x} - \\mu_0}{\\frac{s_x}{\\sqrt{n}}} \\\\\n  &= \\frac{8.75 - 9}{\\frac{1.05}{\\sqrt{111}}} \\\\\n  &= \\frac{-0.25}{0.031} \\\\\n  &= -2.51\n\\end{aligned}\n\\]\nWobei \\(\\overline{x}\\) der Mittelwert der Stichprobe ist, \\(\\mu_0\\) der Mittelwert der Grundgesamtheit ist, \\(s_x\\) der Standardfehler ist und \\(n\\) die Anzahl der Beobachtungen ist.\n\n\n\n\n\nT-Verteilung\n\n\nDieser Test ist ein zweiseitiger Test mit \\(\\alpha = 0.05\\). Das führt dazu, dass wir die Quantile so verteilen, dass “unten” 2.5% der Fläche und “oben” 2.5% der Fläche liegen.\nBei einem einseitigen Test wäre \\(\\alpha = 0.05\\) und wir würden die Quantile so verteilen, dass “unten” 5% der Fläche und “oben” 95% der Fläche liegen.",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistische Tests</span>"
    ]
  },
  {
    "objectID": "statistische-tests.html#konfidenzintervalle",
    "href": "statistische-tests.html#konfidenzintervalle",
    "title": "8  Statistische Tests",
    "section": "8.3 Konfidenzintervalle",
    "text": "8.3 Konfidenzintervalle\n\nMasszahl für die Unsicherheit der Parameterschätzung\nKonfidenzintervalle sind Intervalle, die den wahren Wert einer Grundgesamtheit mit einer bestimmten Wahrscheinlichkeit schätzen.\nEng verknüpft mit dem Signifikanzlevel \\(\\alpha\\)\n\n\n\n\n\n\n\nBeispiel\n\n\n\n\\[\nT = \\frac{\\overline{x} - \\mu_0}{s_{\\overline{x}}} \\Rightarrow \\mu \\in \\left\\{\\overline{x} \\pm q_{T, 0.975} \\cdot s_{\\overline{x}}\\right\\}\n\\]\nWobei \\(\\overline{x}\\) der Mittelwert der Stichprobe ist, \\(\\mu_0\\) der Mittelwert der Grundgesamtheit ist, \\(s_{\\overline{x}}\\) der Standardfehler ist und \\(q_{T, 0.975}\\) das 97.5%-Quantil der t-Verteilung mit \\(n-1\\) Freiheitsgraden ist.\n\n\n\nWie repräsentativ sind unsere Stichprobenergebnisse für die Grundgesamtheit?\n\n\\[\n\\begin{aligned}\n\\mu_{\\text{Obergrenze}} &= \\overline{x} + q_{1 - \\alpha} \\cdot \\sqrt{\\frac{s^2}{n}} \\\\\n\\mu_{\\text{Untergrenze}} &= \\overline{x} - q_{1 - \\alpha} \\cdot \\sqrt{\\frac{s^2}{n}} \\\\\n\\end{aligned}\n\\]\n95%-Konfidenzintervall der erwarteten Temperatur aus dem vorherigen Beispiel:\n\\[\n\\begin{aligned}\n\\mu_{\\text{Obergrenze}} &= 8.75 \\text{°C} + 1.98 \\cdot 0.1 \\text{°C} = 8.55 \\text{°C} \\\\\n\\mu_{\\text{Untergrenze}} &= 8.75 \\text{°C} - 1.98 \\cdot 0.1 \\text{°C} = 8.8.95 \\text{°C} \\\\\n\\end{aligned}\n\\]\nWir beachten, dass \\(9 \\text{°C}\\) nicht im Konfidenzintervall liegt, was im Einvernehmen mit der Ablehnung der Nullhypothese \\(H_0\\) liegt.\nDaumenregel:\n\\[\n\\text{Konfidenzintervall} = \\text{Stichprobenergebnis} \\pm 2 \\cdot \\text{Standardfehler}\n\\]",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistische Tests</span>"
    ]
  },
  {
    "objectID": "statistische-tests.html#überprüfung-auf-normalverteilung",
    "href": "statistische-tests.html#überprüfung-auf-normalverteilung",
    "title": "8  Statistische Tests",
    "section": "8.4 Überprüfung auf Normalverteilung",
    "text": "8.4 Überprüfung auf Normalverteilung\nWir stellen auch hier entsprechende Hypothesen auf.\n\\[\n\\begin{aligned}\nH_0: &\\text{Daten sind normalverteilt} \\\\\nH_A: &\\text{Daten sind nicht normalverteilt}\n\\end{aligned}\n\\]\n\n\n\n\n\n\nAnmerkung\n\n\n\n\n\nDass wir hier mit der \\(H_0\\) die Normalverteilung testen, ist nicht intuitiv. Aber wir testen hier nicht, ob die Daten normalverteilt sind, sondern ob sie nicht normalverteilt sind. Wenn wir das Gegenteil beweisen wollen, müssen wir das Gegenteil widerlegen.\nEine Normalverteilung kann man nicht beweisen, sondern nur widerlegen.\n\n\n\n\n\n\n\n\n\n\n\nTest\nVorteile\nNachteile\n\n\n\n\n\\(\\chi^2\\)-Test\n\ngeeignet für beliebig skalierte Variablen\n\n\nGruppierung der Beobachtungen notwendig\nungeeignet für kleine Stichproben\nquadratische Testgrösse, d.h. sensibel auf Ausreisser\n\n\n\nKolmogorov-Smirnov-Test\n\ngeeignet für kleine Stichproben\nwie Chi-Quadrat auch zum Vergleich anderer Verteilungen geeignet\nnicht-parametrischer Test, d.h. nicht sensibel auf Ausreisser\n\n\ngeringe Teststärke im Vergleich zu den folgenden Tests\n\n\n\nCramér-von-Mises-Test\n\nhöhere Güte als KS-Test\n\n\nquadratische Testgrösse\n\n\n\nLilliefors-Test\n\nbessere Trennschärfe als KS-Test\nnicht-parametrischer Test\n\n\nnur zum Test auf Normalverteilung\n\n\n\nAnderson-Darling-Test\n\nsehr hohe Güte bei Test auf Normalverteilung\n\n\nkeine kategorialen Daten\nquadratische Testgrösse\n\n\n\nShapiro-Wilk-Test\n\nTest mit höchster Güte\n\n\nausschliesslich Test auf Normalverteilung\nmanuell schlecht durchführbar\nsensibel auf Ausreisser und viele identische Werte\n\n\n\n\n\n8.4.1 Überprüfung auf Normalverteilung in R\n\n# Daten generieren\nset.seed(123)\nnormal_data &lt;- rnorm(500)        # 500 normalverteilte Zufallszahlen\nnon_normal_data &lt;- normal_data^2 # quadrierte Zufallszahlen (nicht normalverteilt)\n\n# Shapiro-Wilk-Test für beide Datensätze\nshapiro_result_normal &lt;- shapiro.test(normal_data)\nshapiro_result_non_normal &lt;- shapiro.test(non_normal_data)\n\n# Shapiro-Wilk-Test für normal_data:\ncat(\"W-Teststatistik:\", round(shapiro_result_normal$statistic, 4), \"\\n\")\n\nW-Teststatistik: 0.9981 \n\ncat(\"p-Wert:\", round(shapiro_result_normal$p.value, 4), \"\\n\")\n\np-Wert: 0.8639 \n\n# Shapiro-Wilk-Test für non_normal_data:\ncat(\"W-Teststatistik:\", round(shapiro_result_non_normal$statistic, 4), \"\\n\")\n\nW-Teststatistik: 0.708 \n\ncat(\"p-Wert:\", round(shapiro_result_non_normal$p.value, 4), \"\\n\")\n\np-Wert: 0 \n\n\n\nCode\nif (shapiro_result_normal$p.value &gt; 0.05) {\n  cat(\"Die Nullhypothese der Normalverteilung kann nicht verworfen werden. \\n`normal_data` ist normalverteilt.\\n\\n\")\n} else {\n  cat(\"Die Nullhypothese der Normalverteilung wird verworfen. \\n`normal_data` ist **nicht** normalverteilt.\\n\\n\")\n}\n\nDie Nullhypothese der Normalverteilung kann nicht verworfen werden. normal_data ist normalverteilt.\n\nCode\nif (shapiro_result_non_normal$p.value &gt; 0.05) {\n  cat(\"Die Nullhypothese der Normalverteilung kann nicht verworfen werden. \\n`non_normal_data` ist normalverteilt.\\n\\n\")\n} else {\n  cat(\"Die Nullhypothese der Normalverteilung wird verworfen. \\n`non_normal_data` ist **nicht** normalverteilt.\\n\\n\")\n}\n\nDie Nullhypothese der Normalverteilung wird verworfen. non_normal_data ist nicht normalverteilt.\n\n\nCode\n# Layout für nebeneinanderstehende Plots definieren\npar(mfrow = c(2, 2), mar = c(4, 4, 2, 1))\n\n# Histogramm\nhist(normal_data, \n     main = \"Histogramm (Normalverteilung)\", \n     xlab = \"Werte\", \n     col = \"lightblue\", \n     border = \"white\")\nhist(non_normal_data, \n     main = \"Histogramm (Nicht Normalverteilt)\", \n     xlab = \"Werte\", \n     col = \"lightcoral\", \n     border = \"white\")\n\n# Dichtefunktion\nplot(density(normal_data), \n     main = \"Dichtefunktion (Normalverteilung)\", \n     xlab = \"Werte\", \n     col = \"darkblue\", \n     lwd = 2)\nplot(density(non_normal_data), \n     main = \"Dichtefunktion (Nicht Normalverteilt)\", \n     xlab = \"Werte\", \n     col = \"darkred\", \n     lwd = 2)\n\n\n\n\n\nVisualisierung der Normalverteilung\n\n\n\n\nCode\n# Boxplot\nboxplot(normal_data, \n        main = \"Boxplot (Normalverteilung)\", \n        col = \"lightgreen\", \n        horizontal = TRUE)\nboxplot(non_normal_data, \n        main = \"Boxplot (Nicht Normalverteilt)\", \n        col = \"lightpink\", \n        horizontal = TRUE)\n\n# QQ-Plot\nqqnorm(normal_data, \n       main = \"QQ-Plot (Normalverteilung)\")\nqqline(normal_data, col = \"red\", lwd = 2)\n\nqqnorm(non_normal_data, \n       main = \"QQ-Plot (Nicht Normalverteilt)\")\nqqline(non_normal_data, col = \"red\", lwd = 2)\n\n\n\n\n\nVisualisierung der Normalverteilung\n\n\n\n\nCode\n# Layout zurücksetzen\npar(mfrow = c(1, 1))\n\n\n\n\n8.4.2 \\(\\chi^2\\)-Test\n\nSumme der quadrierten Abweichungen:\n\n\\[\n\\chi^2 = \\sum_{i=1}^{k} \\frac{(N_i - n_i)^2}{n_i}\n\\]\n\n\\(N_i\\): beobachtete Häufigkeit in der Klasse \\(i\\)\n\\(n_i\\): erwartete Häufigkeit in der Klasse \\(i\\)\n\\(k\\): Anzahl der Klassen\n\n\n8.4.2.1 \\(\\chi^2\\)-Verteilung\n\nstetige Wahrscheinlichkeitsverteilung mit der Anzahl Freiheitsgrade \\(k\\) als einzigem Parameter\nVerteilung der Summe der Quadrate von \\(k\\) unabhängigen und standardnormalverteilten Zufallsvariablen.\n\n\n\nCode\n# Chi-Quadrat-Verteilung plotten\nx &lt;- seq(0, 8, length.out = 500)\ndf_values &lt;- c(1, 2, 3, 4, 6, 9)\n\n# Farben definieren\ncolors &lt;- c(\"darkgreen\", \"green\", \"blue\", \"purple\", \"orange\", \"red\")\n\n# Plot erstellen\nplot(x, dchisq(x, df = 1), type = \"l\", lwd = 2, col = colors[1], \n     ylim = c(0, 0.5), xlab = \"x\", ylab = expression(f[k](x)), \n     main = expression(chi^2~\"Verteilung\"))\n\n# Weitere Linien hinzufügen\nfor (i in 2:length(df_values)) {\n  lines(x, dchisq(x, df = df_values[i]), col = colors[i], lwd = 2)\n}\n\n# Legende hinzufügen\nlegend(\"topright\", legend = paste(\"k=\", df_values), \n       col = colors, lwd = 2, bty = \"n\")\n\n\n\n\n\nChi-Quadrat-Verteilung",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistische Tests</span>"
    ]
  },
  {
    "objectID": "statistische-tests.html#testauswahl",
    "href": "statistische-tests.html#testauswahl",
    "title": "8  Statistische Tests",
    "section": "8.5 Testauswahl",
    "text": "8.5 Testauswahl\n\n\n\nTestauswahl Quelle: Methodenberatung UZH",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistische Tests</span>"
    ]
  },
  {
    "objectID": "korrelation.html",
    "href": "korrelation.html",
    "title": "9  Korrelation",
    "section": "",
    "text": "9.0.1 Von der Kovarianz zur Korrelation",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korrelation</span>"
    ]
  },
  {
    "objectID": "korrelation.html#der-pearson-korrelationskoeffizient",
    "href": "korrelation.html#der-pearson-korrelationskoeffizient",
    "title": "9  Korrelation",
    "section": "9.1 Der Pearson-Korrelationskoeffizient",
    "text": "9.1 Der Pearson-Korrelationskoeffizient\n\\[\n\\rho_{X,Y} = \\frac{\\sum_{i=1}^N (X_i - \\mu_x)(Y_i - \\mu_y)}{\\sqrt{\\sum_{i=1}^N (X_i - \\mu_x)^2 \\sum_{i=1}^N (Y_i - \\mu_y)^2}}\n\\]\n\n\\(\\rho\\) ist der Standardbuchstabe für den Korrelationskoeffizienten der Grundgesamtheit.\n\\(r\\) ist der Standardbuchstabe für den Korrelationskoeffizienten der Stichprobe.\n\n\n\n\n\n\n\nHerleitung\n\n\n\n\n\n\nIdee: Produkt der Anomalien\n\n\\[\n\\begin{aligned}\nX_i ^d &= X_i - \\mu_x \\\\\nY_i ^d &= Y_i - \\mu_y \\\\\n\\sum_{i=1}^N (X_i - \\mu_x)(Y_i - \\mu_y) &= \\sum_{i=1}^N X_i ^d Y_i ^d\n\\end{aligned}\n\\]\nWo \\(X_i ^d\\) die Abweichung von \\(X_i\\) vom Mittelwert \\(\\mu_x\\) der Variable \\(X\\) ist und \\(Y_i ^d\\) die Abweichung von \\(Y_i\\) vom Mittelwert \\(\\mu_y\\) der Variable \\(Y\\) ist.\nProblem: Die Summe der Produkte der Abweichungen ist abhängig von der Stichprobengrösse \\(N\\).\n\nDivision durch Stichprobengrösse Kovarianz zwischen \\(X\\) und \\(Y\\)\n\n\\[\n\\sigma_{x,y} = \\frac{i=1}{N-1} (X_i - \\mu_x)(Y_i - \\mu_y)\n\\]\nProblem: Die Kovarianz ist abhängig von den Einheiten der Variablen.\n\nStandardisierung durch die Standardabweichungen der Variablen \\(X\\) und \\(Y\\)\n\n\\[\n\\rho_{X,Y} = \\frac{\\sum_{i=1}^N \\frac{(X_i - \\mu_x)}{\\sigma_x} \\frac{(Y_i - \\mu_y)}{\\sigma_y}}{N}\n\\]\nwo:\n\\[\n\\begin{aligned}\n\\sigma_x &= \\sqrt{\\frac{\\sum_{i=1}^N (X_i - \\mu_x)^2}{N}} \\text{ ,und} \\\\\n\\sigma_y &= \\sqrt{\\frac{\\sum_{i=1}^N (Y_i - \\mu_y)^2}{N}}\n\\end{aligned}\n\\]\n\nErgebnis ist der Pearson-Korrelationskoeffizient \\(\\rho_{x,y}\\)\n\n\\[\n\\rho_{X,Y} = \\frac{\\sum_{i=1}^N (X_i - \\mu_x)(Y_i - \\mu_y)}{\\sqrt{\\sum_{i=1}^N (X_i - \\mu_x)^2 \\sum_{i=1}^N (Y_i - \\mu_y)^2}}\n\\]\n\n\n\nIn R lässt sich der Pearson-Korrelationskoeffizient mit der Funktion cor() berechnen. So lassen sich schnell und einfach Korrelationen zwischen zwei Variablen berechnen.\n\na &lt;- c(1, 2, 3, 4, 5)\nb &lt;- c(2, 3, 4, 5, 6)\ncor(a, b)\n\n[1] 1\n\n\n\n\nCode\n# Set seed for reproducibility\nset.seed(123)\n\n# Hohe Korrelation (r nahe bei 1)\nx_high &lt;- rnorm(30, mean = 5, sd = 1)\ny_high &lt;- 2 * x_high + rnorm(30, mean = 0, sd = 0.5)\nr_high &lt;- cor(x_high, y_high)\n\n# Niedrige Korrelation (r nahe bei 0)\nx_low &lt;- rnorm(30, mean = 5, sd = 1)\ny_low &lt;- rnorm(30, mean = 5, sd = 1)\nr_low &lt;- cor(x_low, y_low)\n\n# Plots nebeneinander\npar(mfrow = c(1, 2), mar = c(4, 4, 2, 1))\n\n# Plot mit hoher Korrelation\nplot(x_high, y_high, \n     main = paste(\"Hohe Korrelation\\nr =\", round(r_high, 3)), \n     xlab = \"x\", ylab = \"y\", \n     pch = 19, col = rgb(0, 0, 1, 0.5))\n\n# Plot mit niedriger Korrelation\nplot(x_low, y_low, \n     main = paste(\"Niedrige Korrelation\\nr =\", round(r_low, 3)), \n     xlab = \"x\", ylab = \"y\", \n     pch = 19, col = rgb(0, 0, 1, 0.5))\n\n\n\n\n\nBeispiele für Pearson-Korrelationen\n\n\n\n\nWenn wir unseren Datensatz um einer Ausreisser ergänzen sehen wir schnell, dass der Pearson-Korrelationskoeffizient sehr stark beeinflusst wird.\n\n\nCode\n# Berechnung des Pearson-Korrelationskoeffizienten\n\n# Daten ohne Ausreißer generieren\nx &lt;- runif(30, 1, 10)\ny &lt;- runif(30, 1, 10)\n\n# Korrelationskoeffizient ohne Ausreißer\nr_no_outlier &lt;- cor(x, y)\n\n# Daten mit Ausreißer hinzufügen\nx_outlier &lt;- c(x, 20)\ny_outlier &lt;- c(y, 25)\n\n# Pearson-Korrelationskoeffizient mit Ausreißer\nr_with_outlier &lt;- cor(x_outlier, y_outlier)\n\n# Plots nebeneinander\npar(mfrow = c(1, 2), mar = c(4, 4, 2, 1))\n\n# Plot ohne Ausreißer\nplot(x, y, \n     main = paste(\"Ohne Ausreißer\\nr =\", round(r_no_outlier, 3)), \n     xlab = \"x\", ylab = \"y\", \n     pch = 19, col = rgb(0, 0, 1, 0.5), xlim = c(0, 22), ylim = c(0, 27))\n\n# Plot mit Ausreißer\nplot(x_outlier, y_outlier, \n     main = paste(\"Mit Ausreißer\\nr =\", round(r_with_outlier, 3)), \n     xlab = \"x\", ylab = \"y\", \n     pch = 19, col = c(rep(rgb(0, 0, 1, 0.5), 30), rgb(1, 0, 0, 0.5)), xlim = c(0, 22), ylim = c(0, 27))\n\n\n\n\n\nEinfluss von Ausreissern auf den Pearson-Korrelationskoeffizienten",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korrelation</span>"
    ]
  },
  {
    "objectID": "korrelation.html#der-spearman-rangkorrelationskoeffizient",
    "href": "korrelation.html#der-spearman-rangkorrelationskoeffizient",
    "title": "9  Korrelation",
    "section": "9.2 Der Spearman-Rangkorrelationskoeffizient",
    "text": "9.2 Der Spearman-Rangkorrelationskoeffizient\n\nFür ordinal skalierte Daten kann der Rang eines Objekts in zwei Variablen verwendet werden:\n\n\\[\n\\rho = 1 - \\frac{6 \\sum_{i=1}^N (r_i - s_i)^2}{n^3 - n}\n\\]\n\n\\(r_i\\) ist der Rang der \\(i\\)-ten Beobachtung in der ersten Variable.\nVereinfachte Formel, wenn jeder Rang nur einmal vorkommt\nDer Spearman-Rangkorrelationskoeffizient wird sehr oft acuh für metrische Daten verwendet, da er robust gegenüber Ausreissern ist. Im Zweifel sollte man den Spearman-Rangkorrelationskoeffizienten verwenden.\n\n\n\nCode\n# Synthetische Daten generieren\nx &lt;- rnorm(100, mean = 10, sd = 1)\ny &lt;- 0.8 * x + rnorm(100, mean = 0, sd = 0.5)\n\n# Funktion zur Berechnung von Pearson- und Spearman-Korrelation\ncorrelations &lt;- function(x, y) {\n  list(\n    pearson = round(cor(x, y, method = \"pearson\"), 2),\n    spearman = round(cor(x, y, method = \"spearman\"), 2)\n  )\n}\n\n# Layout für 2x2 Plots\npar(mfrow = c(2, 2), mar = c(4, 4, 2, 1))\n\n# 1. Plot (ohne Ausreißer)\ncor_vals &lt;- correlations(x, y)\nplot(x, y, pch = 19, col = rgb(0, 0, 1, 0.5),\n     main = paste0(\"r(Spearman) = \", cor_vals$spearman, \n                   \"\\nr(Pearson) = \", cor_vals$pearson),\n     xlab = \"x\", ylab = \"y\")\n\n# 2. Plot (Ausreißer unten rechts)\nx2 &lt;- c(x, 12)\ny2 &lt;- c(y, -3)\ncor_vals2 &lt;- correlations(x2, y2)\nplot(x2, y2, pch = c(rep(19, 100), 19), col = c(rep(rgb(0, 0, 1, 0.5), 100), rgb(1, 0, 0, 0.5)),\n     main = paste0(\"r(Spearman) = \", cor_vals2$spearman, \n                   \"\\nr(Pearson) = \", cor_vals2$pearson),\n     xlab = \"x\", ylab = \"y\")\n\n# 3. Plot (Ausreißer oben links)\nx3 &lt;- c(x, 7.5)\ny3 &lt;- c(y, 1.5)\ncor_vals3 &lt;- correlations(x3, y3)\nplot(x3, y3, pch = c(rep(19, 100), 19), col = c(rep(rgb(0, 0, 1, 0.5), 100), rgb(1, 0, 0, 0.5)),\n     main = paste0(\"r(Spearman) = \", cor_vals3$spearman, \n                   \"\\nr(Pearson) = \", cor_vals3$pearson),\n     xlab = \"x\", ylab = \"y\")\n\n# 4. Plot (zwei Ausreißer oben links und unten rechts)\nx4 &lt;- c(x, 7.5, 12)\ny4 &lt;- c(y, 1.5, -3)\ncor_vals4 &lt;- correlations(x4, y4)\nplot(x4, y4, pch = c(rep(19, 100), 19, 19), col = c(rep(rgb(0, 0, 1, 0.5), 100), rgb(1, 0, 0, 0.5), rgb(1, 0, 0, 0.5)),\n     main = paste0(\"r(Spearman) = \", cor_vals4$spearman, \n                   \"\\nr(Pearson) = \", cor_vals4$pearson),\n     xlab = \"x\", ylab = \"y\")\n\n\n\n\n\nEinfluss von Ausreissern auf beide Korrelationskoeffizienten\n\n\n\n\n\n\nCode\n# Set seed for reproducibility\nset.seed(42)\n\n# Basisdaten generieren\nx &lt;- runif(100, 7, 12)  # x-Werte im Bereich 7 bis 12\n\n# 1. Lineare Beziehung\ny_linear &lt;- 0.8 * x + rnorm(100, mean = 0, sd = 0.5)\n\n# 2. U-förmige (quadratische) Beziehung\ny_quadratic &lt;- -1 * (x - 9.5)^2 + 8 + rnorm(100, mean = 0, sd = 0.5)\n\n# 3. Logarithmische Beziehung\ny_logarithmic &lt;- log(x - 6.5) + rnorm(100, mean = 0, sd = 0.3)\n\n# 4. Exponentielle Beziehung\ny_exponential &lt;- exp((x - 10) / 3) + rnorm(100, mean = 0, sd = 0.5)\n\n# Funktion zur Berechnung von Pearson- und Spearman-Korrelation\ncorrelations &lt;- function(x, y) {\n  list(\n    pearson = round(cor(x, y, method = \"pearson\"), 2),\n    spearman = round(cor(x, y, method = \"spearman\"), 2)\n  )\n}\n\n# Layout für 2x2 Plots\npar(mfrow = c(2, 2), mar = c(4, 4, 2, 1))\n\n# Farben definieren\ncolors &lt;- rgb(0, 0, 1, 0.5)\n\n# 1. Plot (lineare Beziehung)\ncor_vals1 &lt;- correlations(x, y_linear)\nplot(x, y_linear, pch = 19, col = colors,\n     main = paste0(\"r(Spearman) = \", cor_vals1$spearman, \n                   \"\\nr(Pearson) = \", cor_vals1$pearson),\n     xlab = \"x\", ylab = \"y\")\n\n# 2. Plot (quadratische Beziehung)\ncor_vals2 &lt;- correlations(x, y_quadratic)\nplot(x, y_quadratic, pch = 19, col = colors,\n     main = paste0(\"r(Spearman) = \", cor_vals2$spearman, \n                   \"\\nr(Pearson) = \", cor_vals2$pearson),\n     xlab = \"x\", ylab = \"y\")\n\n# 3. Plot (logarithmische Beziehung)\ncor_vals3 &lt;- correlations(x, y_logarithmic)\nplot(x, y_logarithmic, pch = 19, col = colors,\n     main = paste0(\"r(Spearman) = \", cor_vals3$spearman, \n                   \"\\nr(Pearson) = \", cor_vals3$pearson),\n     xlab = \"x\", ylab = \"y\")\n\n# 4. Plot (exponentielle Beziehung)\ncor_vals4 &lt;- correlations(x, y_exponential)\nplot(x, y_exponential, pch = 19, col = colors,\n     main = paste0(\"r(Spearman) = \", cor_vals4$spearman, \n                   \"\\nr(Pearson) = \", cor_vals4$pearson),\n     xlab = \"x\", ylab = \"y\")\n\n\n\n\n\nEinfluss von Nicht-Linearitäten auf beide Korrelationskoeffizienten",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korrelation</span>"
    ]
  },
  {
    "objectID": "korrelation.html#vergleich-der-korrelationskoeffizienten",
    "href": "korrelation.html#vergleich-der-korrelationskoeffizienten",
    "title": "9  Korrelation",
    "section": "9.3 Vergleich der Korrelationskoeffizienten",
    "text": "9.3 Vergleich der Korrelationskoeffizienten\n\n\n\n\n\n\n\n\nKriterium\nPearson\nSpearman\n\n\n\n\nArt des Zusammenhangs\n\nMisst lineare Zusammenhänge\n\n\nMisst monotone Zusammenhänge (linear oder nicht-linear)\n\n\n\nAnwendung\n\nHäufig in der Statistik für metrische Variablen\n\n\nIdeal für Rangdaten oder nicht normalverteilte Daten\n\n\n\nVoraussetzungen\n\nNormalverteilung der Variablen\nLinearität\n\n\nKeine Normalverteilung erforderlich\nMonotone Beziehung erforderlich\n\n\n\nDatentypen\n\nMetrische (intervall- oder verhältnisskalierte) Daten\n\n\nOrdinal-, Intervall- und Verhältnisskalen\n\n\n\nSensitivität gegenüber Ausreissern\n\nSehr empfindlich gegenüber Ausreissern\n\n\nRobust gegenüber Ausreissern\n\n\n\nRobustheit bei nicht-linearen Zusammenhängen\n\nNicht robust bei nicht-linearen Zusammenhängen\n\n\nRobust bei nicht-linearen, aber monotonen Zusammenhängen\n\n\n\nSkalenniveau\n\nIntervall- oder verhältnisskaliert\n\n\nMindestens ordinalskaliert\n\n\n\nBerechnungsgrundlage\n\nKovarianz, normiert durch Standardabweichung\n\n\nBerechnet auf Basis von Rangdifferenzen\n\n\n\nVorteile\n\nEinfach zu interpretieren\nWeit verbreitet\n\n\nRobust gegenüber Ausreissern\nGeeignet für nicht-lineare monotone Beziehungen\n\n\n\nNachteile\n\nNicht robust gegenüber Ausreissern\nNicht geeignet für nicht-lineare Zusammenhänge\n\n\nWeniger empfindlich bei linearen Zusammenhängen\nInformationsverlust durch Rangkodierung",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korrelation</span>"
    ]
  },
  {
    "objectID": "korrelation.html#hypothesentests-für-korrelationen",
    "href": "korrelation.html#hypothesentests-für-korrelationen",
    "title": "9  Korrelation",
    "section": "9.4 Hypothesentests für Korrelationen",
    "text": "9.4 Hypothesentests für Korrelationen\n\n9.4.1 Null- und Alternativhypothese\n\nH0: Kein Zusammenhang (r = 0)\nHA: Es besteht ein Zusammenhang (r ≠ 0)\n\n\n\n9.4.2 t-Test für den Korrelationskoeffizienten\n\nTeststatistik und Berechnung\nSignifikanzbewertung\n\n\n\n9.4.3 Beispiel in R\n\n# Test auf Signifikanz der Korrelation\ncor.test(x, y, method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  x and y\nt = -0.79113, df = 98, p-value = 0.4308\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.2718274  0.1186115\nsample estimates:\n        cor \n-0.07966258",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korrelation</span>"
    ]
  },
  {
    "objectID": "korrelation.html#besondere-themen",
    "href": "korrelation.html#besondere-themen",
    "title": "9  Korrelation",
    "section": "9.5 Besondere Themen",
    "text": "9.5 Besondere Themen\n\n9.5.1 Korrelation von Zeitreihen\n\nDefinition von Autokorrelation\nEinfluss von Trends und Saisonalität\n\n\n\n9.5.2 Varianz-Kovarianz-Matrix\n\nDefinition\nBedeutung in der Statistik\n\n\n# Varianz-Kovarianz-Matrix in R\nA &lt;- matrix(c(2,3,1,-1,1,1,0,4,2,-1,0,0), nrow=4, byrow=TRUE)\ncor(A)\n\n          [,1]      [,2]      [,3]\n[1,] 1.0000000 0.6454972 0.2886751\n[2,] 0.6454972 1.0000000 0.8944272\n[3,] 0.2886751 0.8944272 1.0000000",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Korrelation</span>"
    ]
  },
  {
    "objectID": "regression.html",
    "href": "regression.html",
    "title": "10  Regression",
    "section": "",
    "text": "10.1 Lineare Regression\nZiel: Vorhersage einer metrischen abhängigen Variable (Kriterium) durch eine oder mehrere unabhängige Variablen (Prädiktoren).\nVoraussetzungen:\nBei einer Regressionsanalyse gibt es eine abhängige Varaible (\\(y\\)) welche erklärt werden soll und eine oder mehrere unabhängige Variablen (\\(x_1, x_2, \\ldots, x_k\\)), die mit der zu erklärenden Variable in Verbindung stehen.\n\\[\ny = a + b_1 x_1 + b_2 x_2 + \\ldots + b_k x_k\n\\]\n\\(a\\) ist eine Regressionskonstante und \\(b_1, b_2, \\ldots, b_k\\) sind die Regressionskoeffizienten.\nFür jede zunahme von \\(x_i\\) um eine Einheit, nimmt \\(y\\) um \\(b_i\\) Einheiten zu.",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#lineare-regression",
    "href": "regression.html#lineare-regression",
    "title": "10  Regression",
    "section": "",
    "text": "kausaler Zusammenhang zwischen Prädiktoren und Kriterium\nein Modell, das die Zusammenhänge zwischen Prädiktoren und Kriterium beschreibt\n\n\n\n\n\n\n10.1.1 Grundidee\nWir wollen eine Gerade der Form:\n\\[\n\\hat{y} = \\beta_0 + \\beta_1 \\cdot x\n\\]\n\n\\(\\hat{y}\\) = vorhergesagter Wert von \\(y\\)\n\n\\(\\beta_0\\) = Achsenabschnitt (Intercept)\n\n\\(\\beta_1\\) = Steigung der Regressionsgerade\n\nDie Parameter \\(\\beta_0\\) und \\(\\beta_1\\) bestimmen die Lage und Neigung der Regressionsgerade.\n\n\n10.1.2 Das Problem der Abweichungen (Residuen)\nKein Modell beschreibt die Realität perfekt. Daher gibt es für jeden Datenpunkt eine Abweichung (Residuum):\n\\[\ne_i = y_i - \\hat{y}_i\n\\]\n\n\\(e_i\\) = Residuum des \\(i\\)-ten Datenpunkts\n\n\\(y_i\\) = tatsächlicher Wert\n\n\\(\\hat{y}_i\\) = vorhergesagter Wert durch die Regressionsgerade\n\nDas Ziel der linearen Regression ist es, diese Abweichungen so klein wie möglich zu halten.\n\n10.1.2.1 Erste (zufällige) Anpassung\nIm ersten Schritt betrachten wir eine zufällige Regressionsgerade, die nicht gut zu den Daten passt. Die Residuen (grüne Linien) zeigen die Abstände zwischen den Datenpunkten und der Linie.\n\n\nCode\n# Setzen des Seeds für reproduzierbare Ergebnisse\nset.seed(42)\n\n# Definieren der Farbe mit Opacity\ndot_color &lt;- rgb(0, 0, 1, alpha = 0.6)\nline_color &lt;- rgb(0, 0, 1, alpha = 0.8)\nresidual_color &lt;- rgb(0.87, 0.72, 0.53, alpha = 0.5)\n\nx &lt;- rnorm(30, mean = 10, sd = 2)\ny &lt;- 2 * x + rnorm(30, mean = 0, sd = 4)\n\nplot(x, y, pch = 19, col = dot_color, xlab = \"x\", ylab = \"y\")\nabline(a = 20, b = -0.5, col = line_color, lwd = 2)\nfor (i in 1:length(x)) {\n  segments(x[i], y[i], x[i], -0.5 * x[i] + 20, col = residual_color, lwd = 1.5)\n}\n\n# Gesamtlänge der Residuen berechnen und anzeigen\nresidual_sum_random &lt;- sum(abs(y - (-0.5 * x + 20)))\ntext(min(x), max(y), labels = paste(\"Residuen:\", round(residual_sum_random, 2)), pos = 4, col = \"blue2\")\n\n\n\n\n\nErster Ansatz: wir zeichnen eine beliebige Gerade und visualisieren die Residuen\n\n\n\n\n\n\n10.1.2.2 Logischer Verbesserungsschritt: Linie durch den Schwerpunkt\nStatt zufällig eine bessere Linie zu raten, machen wir den logischen ersten Schritt: Wir zeichnen eine horizontale Linie durch den Schwerpunkt der Daten, d.h. die Mittelwerte von \\(x\\) und \\(y\\).\nWichtige Erkenntnis: Jede Regressionsgerade verläuft durch den Punkt \\((\\bar{x}, \\bar{y})\\).\n\n\nCode\nlibrary(latex2exp)\n\nmean_x &lt;- mean(x)\nmean_y &lt;- mean(y)\n\nplot(x, y, pch = 19, col = dot_color, xlab = \"x\", ylab = \"y\")\nabline(h = mean_y, col = line_color, lwd = 2)\npoints(mean_x, mean_y, pch = 19, col = \"red\", cex = 1.5)\ntext(mean_x, mean_y, labels = TeX(\"$(\\\\bar{x}, \\\\bar{y})$\"), pos = 4, col = \"red\")\nfor (i in 1:length(x)) {\n  segments(x[i], y[i], x[i], mean_y, col = residual_color, lwd = 1.5)\n}\n\n# Gesamtlänge der Residuen berechnen und anzeigen\nresidual_sum_mean &lt;- sum(abs(y - mean_y))\ntext(min(x), max(y), labels = paste(\"Residuen:\", round(residual_sum_mean, 2)), pos = 4, col = \"blue2\")\n\n\n\n\n\nZweiter Schritt: Wir zeichnen eine horizontale Linie durch den Schwerpunkt der Daten\n\n\n\n\n\n\n10.1.2.3 Optimale Regressionsgerade (Least Squares)\nIm letzten Schritt berechnen wir die optimale Regressionsgerade mithilfe der Methode der kleinsten Quadrate. Diese minimiert die Summe der quadrierten Abweichungen (Residuen).\n\n\n\n\n\n\nSchrittweise Herleitung\n\n\n\n\n\n\nModellgleichung:\n\nDas lineare Regressionsmodell lautet:\n\\[\n\\hat{y} = \\widehat{\\beta_0} + \\widehat{\\beta_1} \\cdot x\n\\]\n\nDas Dach \\(\\widehat{\\beta_0}\\) und \\(\\widehat{\\beta_1}\\) bedeutet, dass es sich um Schätzwerte handelt.\n\n\nDefinition der Fehler (Residuen):\n\nFür jeden Datenpunkt ergibt sich das Residuum als Differenz zwischen dem beobachteten Wert \\(y_i\\) und dem vorhergesagten Wert \\(\\hat{y}_i\\):\n\\[\ne_i = y_i - (\\widehat{\\beta_0} + \\widehat{\\beta_1} x_i)\n\\]\n\nZielfunktion – Summe der quadrierten Residuen (RSS):\n\nWir wollen die Summe der quadrierten Residuen minimieren:\n\\[\nRSS = \\sum_{i=1}^{n} (y_i - (\\widehat{\\beta_0} + \\widehat{\\beta_1} x_i))^2\n\\]\n\nOptimierung durch partielle Ableitung:\n\nWir minimieren \\(RSS\\), indem wir die partiellen Ableitungen nach \\(\\beta_0\\) und \\(\\beta_1\\) berechnen und gleich null setzen:\n\nAbleitung nach \\(\\beta_0\\):\n\n\\[\n\\frac{\\partial RSS}{\\partial \\widehat{\\beta_0}} = -2 \\sum (y_i - \\widehat{\\beta_0} - \\widehat{\\beta_1} x_i) = 0\n\\]\n\nAbleitung nach \\(\\beta_1\\):\n\n\\[\n\\frac{\\partial RSS}{\\partial \\widehat{\\beta_1}} = -2 \\sum x_i (y_i - \\widehat{\\beta_0} - \\widehat{\\beta_1} x_i) = 0\n\\]\n\nLösen des Gleichungssystems:\n\nDurch Umformen der beiden Gleichungen erhalten wir die sogenannten Normalgleichungen:\n\\[\n\\begin{aligned}\n\\sum y_i &= n \\widehat{\\beta_0} + \\widehat{\\beta_1} \\sum x_i \\\\\n\\sum x_i y_i &= \\widehat{\\beta_0} \\sum x_i + \\widehat{\\beta_1} \\sum x_i^2\n\\end{aligned}\n\\]\n\nEndformeln für die Regressionskoeffizienten:\n\nNach weiteren Umformungen ergeben sich die optimalen Schätzwerte für \\(\\widehat{\\beta_1}\\) und \\(\\widehat{\\beta_0}\\):\n\nSteigung:\n\n\\[\n\\widehat{\\beta_1} = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}\n\\]\n\nAchsenabschnitt:\n\n\\[\n\\widehat{\\beta_0} = \\bar{y} - \\widehat{\\beta_1} \\cdot \\bar{x}\n\\]\n\n\n\n\n\nCode\nmodel &lt;- lm(y ~ x)\n\nplot(x, y, pch = 19, col = dot_color, xlab = \"x\", ylab = \"y\")\nabline(model, col = line_color, lwd = 2)\nfor (i in 1:length(x)) {\n  segments(x[i], y[i], x[i], predict(model)[i], col = residual_color, lwd = 1.5)\n}\n\n# Gesamtlänge der Residuen berechnen und anzeigen\nresidual_sum_optimal &lt;- sum(abs(y - predict(model)))\ntext(min(x), max(y), labels = paste(\"Residuen:\", round(residual_sum_optimal, 2)), pos = 4, col = \"blue2\")\n\n\n\n\n\nDritter Schritt: Optimale Regressionsgerade (Methode der kleinsten Quadrate)\n\n\n\n\n\n\n\n10.1.3 Bestimmung der Güte der Anpassung\nDie Güte der Anpassung wird durch den Bestimmtheitsmass \\(R^2\\) beurteilt.\n\\[\nR^2 = \\frac{\\text{erklärte Variation}}{\\text{Gesamtvariation}} = \\frac{\\sum_{i=1}^{n} (\\hat{Y}_i - \\bar{Y})^2}{\\sum_{i=1}^{n} (Y_i - \\bar{Y})^2} = 1 - \\frac{\\text{Residualsumme}}{\\text{Gesamtvariation}}\n\\tag{10.1}\\]\n\n\\(\\hat{Y}_i\\) = vorhergesagter Wert\n\\(\\bar{Y}\\) = Mittelwert der abhängigen Variablen\n\\(Y_i\\) = beobachteter Wert\n\n\\(R^2\\) liegt immer zwischen 0 und 1. Je höher \\(R^2\\), desto besser passt das Modell zu den Daten.\n\n\n10.1.4 Testen der Signifikanz der Regressionskoeffizienten\nHypothesen:\n\n\\(H_0\\): \\(\\beta_1 = 0\\) (KEINE lineare Abhängigkeit zwischen \\(x\\) und \\(y\\))\n\\(H_1\\): \\(\\beta_1 \\neq 0\\) (lineare Abhängigkeit zwischen \\(x\\) und \\(y\\))\n\\(\\beta_1\\) der Stichprobe variiert um den wahren Wert \\(\\beta_1\\) der Grundgesamtheit mit bestimmter Wahrscheinlichkeit:\n\neiner Normalverteilung mit der Standardabweichung \\(\\sigma_{\\beta_1}\\)\n\\(\\sigma_{\\beta_1}\\) wird aus \\(s_{\\beta_1}\\) (Standardfehler von \\(\\beta_1\\)) geschätzt\num die Schätzunsicherheiten bei kleinen Stichproben zu berücksichtigen, wird die t-Verteilung verwendet\n\n\n\\[\nT = \\frac{\\widehat{\\beta}}{s_{\\beta_1}}, \\quad \\text{mit} \\quad s_{\\beta_1} = \\sqrt{\\frac{\\sum_{i=1}^{n} (Y_i - \\hat{Y}_i)^2 / (n-2)}{\\sum_{i=1}^{n} (X_i - \\bar{X})^2}}\n\\]\n\n\\(T\\) ist t-verteilt mit \\(n-2\\) Freiheitsgraden, da wir den Regressionskoeffizienten \\(\\beta_1\\) und die Streuung \\(\\sigma_{\\beta_1}\\) aus der Stichprobe schätzen\n\\(\\beta_1\\) ist die Steigung der Regressionsgerade\n\\(s_{\\beta_1}\\) ist der Standardfehler der Steigung\n\\(\\widehat{\\beta}\\) ist der geschätzte Regressionskoeffizient der Stichprobe\n\\(Y_i\\) ist der beobachtete Wert der abhängigen Variablen\n\\(\\hat{Y}_i\\) ist der vorhergesagte Wert der abhängigen Variablen\n\\(X_i\\) ist der beobachtete Wert der unabhängigen Variablen\n\\(\\bar{X}\\) ist der Mittelwert der unabhängigen Variablen\n\\(n\\) ist die Anzahl der Beobachtungen\n\n\n10.1.4.1 Konfidenzintervall der Regressionskoeffizienten\n\\[\n\\beta_1 = \\widehat{\\beta_1} \\pm q_t \\cdot s_{\\beta_1} \\quad \\text{mit} \\quad q_t \\text{ aus der T-Tabelle}\n\\]\n\n\\(t_{n-2}\\) ist der kritische Wert der t-Verteilung mit \\(n-2\\) Freiheitsgraden\n\\(s_{\\beta_1}\\) ist der Standardfehler der Steigung\n\\(\\widehat{\\beta_1}\\) ist der geschätzte Regressionskoeffizient der Stichprobe\n\n\n\n\n10.1.5 Berechnung der linearen Regression in R\n\n# Daten erstellen\nx &lt;- rnorm(30, mean = 10, sd = 2)\ny &lt;- 2 * x + rnorm(30, mean = 0, sd = 4)\n\n# Lineare Regression durchführen\nmodel &lt;- lm(y ~ x)\nmodel\n\n\nCall:\nlm(formula = y ~ x)\n\nCoefficients:\n(Intercept)            x  \n      4.131        1.595  \n\n\nDie Ausgabe der Funktion lm() zeigt uns:\n\nCall: Die verwendete Formel für die Regression\n\ny ~ x bedeutet: y wird durch x vorhergesagt\n\nCoefficients: Die geschätzten Regressionskoeffizienten\n\n(Intercept): \\(\\widehat{\\beta_0}\\) = 4.131\n\nDies ist der y-Achsenabschnitt\nDer vorhergesagte y-Wert, wenn x = 0\n\nx: \\(\\widehat{\\beta_1}\\) = 1.595\n\nDies ist die Steigung der Geraden\nFür jede Einheit, die x zunimmt, steigt y um 1.595 Einheiten\n\n\n\nFür eine detailliertere Analyse können wir die Funktion summary() verwenden:\n\nsummary(model)\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.6915 -2.4266 -0.3433  2.5292 10.5802 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   4.1311     5.1598   0.801  0.43009   \nx             1.5948     0.4916   3.244  0.00305 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.147 on 28 degrees of freedom\nMultiple R-squared:  0.2732,    Adjusted R-squared:  0.2472 \nF-statistic: 10.52 on 1 and 28 DF,  p-value: 0.003047\n\n\nDie summary() zeigt uns zusätzlich:\n\nResiduals: Verteilung der Abweichungen zwischen vorhergesagten und tatsächlichen Werten\n\nMinimum: -7.691\nMaximum: 10.58\nDie Quartile zeigen, wie die Residuen verteilt sind\nIdealerweise symmetrisch um 0\n\nCoefficients-Tabelle:\n\nIntercept (\\(\\widehat{\\beta_0}\\) = 4.131):\n\nStandardfehler: 5.16\nt-Wert: 0.801\np-Wert: 0.43\nSignifikant auf dem nicht signifikant Niveau\n\nSteigung (\\(\\widehat{\\beta_1}\\) = 1.595):\n\nStandardfehler: 0.492\nt-Wert: 3.244\np-Wert: 0.003\nSignifikant auf dem 1% Niveau\n\n\nModellgüte:\n\n\\(R^2\\) = 0.273\n\n27.3% der Varianz in y wird durch x erklärt\n\nAdjustiertes \\(R^2\\) = 0.247\n\nBerücksichtigt die Anzahl der Prädiktoren\n\n\nF-Test:\n\nF-Wert: 10.523\nFreiheitsgrade: 1 und 28\np-Wert: 0.00305\nDas Modell ist statistisch signifikant",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#multiple-regression",
    "href": "regression.html#multiple-regression",
    "title": "10  Regression",
    "section": "10.2 Multiple Regression",
    "text": "10.2 Multiple Regression",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "regression.html#multiple-regression-1",
    "href": "regression.html#multiple-regression-1",
    "title": "10  Regression",
    "section": "10.3 Multiple Regression",
    "text": "10.3 Multiple Regression\nIn der einfachen linearen Regression versuchen wir, den Zusammenhang zwischen einer abhängigen Variable \\(Y\\) und einem Prädiktor \\(X_1\\) zu modellieren. Doch was passiert, wenn \\(Y\\) nicht vollständig durch \\(X_1\\) alleine erklärt werden kann?\nStellen wir uns vor, wir haben Daten, bei denen wir vermuten, dass \\(X_1\\) einen Einfluss auf \\(Y\\) hat. Wir beginnen mit einer einfachen linearen Regression:\n\n\nCode\nset.seed(42)\n# Daten simulieren\nn &lt;- 100\nX1 &lt;- rnorm(n, mean = 10, sd = 2)\nX2 &lt;- rnorm(n, mean = 5, sd = 1.5)\nY &lt;- 3 * X1 + 2 * X2 + rnorm(n, sd = 3)\n\n# Einfache lineare Regression Y ~ X1\nmodel_X1 &lt;- lm(Y ~ X1)\n\n# Plot\nplot(X1, Y, pch = 19, col = rgb(105/255, 89/255, 205/255, alpha = 0.5), \n     xlab = \"X1\", ylab = \"Y\")\nabline(model_X1, col = \"red\", lwd = 2)\n\n\n\n\n\nErste Regression: Y in Abhängigkeit von X1\n\n\n\n\nWir erkennen, dass \\(X_1\\) einen deutlichen Einfluss auf \\(Y\\) hat. Doch die Vorhersagen des Modells sind nicht perfekt – es bleiben Residuen übrig, also Abweichungen zwischen den tatsächlichen Werten von \\(Y\\) und den durch das Modell prognostizierten Werten.\nDiese Residuen sind nicht einfach nur zufälliges Rauschen. Sie könnten Hinweise darauf liefern, dass noch weitere Faktoren im Spiel sind, die wir bisher nicht berücksichtigt haben.\nUm das zu überprüfen, untersuchen wir, ob ein weiterer Prädiktor \\(X_2\\) möglicherweise einen Teil dieser unerklärten Varianz in \\(Y\\) aufklären kann. Dazu betrachten wir die Residuen der ersten Regression und analysieren, ob sie mit \\(X_2\\) zusammenhängen:\n\n\nCode\n# Berechne die Residuen der ersten Regression\nresiduals_X1 &lt;- resid(model_X1)\n\n# Regression der Residuen auf X2\nmodel_resid_X2 &lt;- lm(residuals_X1 ~ X2)\n\n# Plot\nplot(X2, residuals_X1, pch = 19, col = rgb(105/255, 89/255, 205/255, alpha = 0.5), \n     xlab = \"X2\", ylab = \"Residuen von Y ~ X1\")\nabline(model_resid_X2, col = \"orange\", lwd = 2)\n\n\n\n\n\nZweite Regression: Residuen von Y ~ X1 in Abhängigkeit von X2\n\n\n\n\nWir sehen, dass die Residuen tatsächlich einen Zusammenhang mit \\(X_2\\) aufweisen. Das bedeutet, dass \\(X_2\\) Varianz in \\(Y\\) erklärt, die nicht durch \\(X_1\\) erfasst wurde.\nMan könnte diesen Prozess theoretisch weiterführen: Nachdem wir den Einfluss von \\(X_2\\) modelliert haben, könnten wir die neuen Residuen betrachten und versuchen, diese durch einen weiteren Prädiktor \\(X_3\\) zu erklären. Und so weiter.\nDieses schrittweise Vorgehen wirft jedoch ein Problem auf: Was passiert, wenn \\(X_1\\), \\(X_2\\), …, \\(X_k\\) miteinander korrelieren?\n\nIn diesem Fall ist es schwierig, die individuellen Effekte der einzelnen Prädiktoren zu isolieren.\nDer Einfluss von \\(X_2\\) könnte bereits teilweise in der ersten Regression durch \\(X_1\\) berücksichtigt worden sein – und umgekehrt.\nDurch das schrittweise Vorgehen riskieren wir, Doppelerklärungen oder verzerrte Effekte zu erhalten.\n\nWir brauchen einen Ansatz, der es uns ermöglicht, den Einfluss mehrerer Prädiktoren gleichzeitig zu berücksichtigen.\n\n\n\n\n\n\nBeispiel\n\n\n\n\n\nWir versuchen, den Abfluss eines Gebirgsbachs zu modellieren.\n\n\\(Y\\): Abfluss\n\\(X_1\\): Schneeschmelze\n\\(X_2\\): Niederschlag\n\nWenn wir den Abfluss \\(Y\\) zunächst in Abhängigkeit von der Schneeschmelze \\(X_1\\) modellieren, stellen wir fest, dass ein Teil der Varianz von \\(Y\\) nicht erklärt wird. Wir vermuten, dass der Niederschlag \\(X_2\\) einen zusätzlichen Einfluss haben könnte. Also modellieren wir die Residuen aus der ersten Regression in Abhängigkeit von \\(X_2\\).\nDoch hier entsteht ein Problem: Schneeschmelze und Niederschlag sind oft korreliert. Nach starken Niederschlägen folgt häufig eine beschleunigte Schneeschmelze. Wenn wir \\(X_2\\) nur auf die Residuen von \\(X_1\\) anwenden, übersehen wir möglicherweise den gemeinsamen Einfluss beider Faktoren.\nDas führt zu verzerrten Ergebnissen, da der Niederschlag sowohl einen direkten Einfluss auf den Abfluss hat als auch indirekt über die Schneeschmelze wirkt.\n\n\n\nBemerkung: Wenn die Prädiktoren nicht korrelieren, ist die Regression der Residuen mit weiteren Variablen möglich.\n\n10.3.1 Ansatz\n\nMinimierung der Summe der quadrierten Residuen:\n\n\\[\n\\sum_{i=1}^{n} (Y_i - \\widehat{\\beta_0} - \\widehat{\\beta_1} X_{1i} - \\widehat{\\beta_2} X_{2i} - \\ldots - \\widehat{\\beta_k} X_{ki})^2 \\quad \\rightarrow \\quad \\text{minimal}\n\\]\n\nDafür müssen die partiellen Ableitungen nach allen \\(\\beta_j\\) gleich null gesetzt werden\nKoeffizienten der multiplen Regression werden auch “partielle Regressionskoeffizienten” genannt\n\n\\[\n\\widehat{Y_i} = \\widehat{\\beta_0} + \\widehat{\\beta_1} X_{1i} + \\widehat{\\beta_2} X_{2i} + \\ldots + \\widehat{\\beta_k} X_{ki}\n\\]\noder in Matrixnotation:\n\\[\n\\widehat{Y} = X \\widehat{\\beta} \\quad \\text{mit} \\quad \\widehat{Y} = \\begin{bmatrix} \\widehat{Y_1} \\\\ \\widehat{Y_2} \\\\ \\vdots \\\\ \\widehat{Y_n} \\end{bmatrix}, \\quad \\widehat{\\beta} = \\begin{bmatrix} \\widehat{\\beta_0} \\\\ \\widehat{\\beta_1} \\\\ \\vdots \\\\ \\widehat{\\beta_k} \\end{bmatrix} \\quad \\text{und} \\quad X = \\begin{bmatrix} 1 & X_{11} & X_{21} & \\ldots & X_{k1} \\\\ 1 & X_{12} & X_{22} & \\ldots & X_{k2} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & X_{1n} & X_{2n} & \\ldots & X_{kn} \\end{bmatrix}\n\\]\n\n\n10.3.2 Beispiel: Anzahl der Kinder in Abhängigkeit von Ausbildung und Einkommen\nWir haben Daten über 20 Personen, bei denen wir die Anzahl der Kinder, die Ausbildung und das Einkommen erfasst haben. Wir gehen davon aus, dass die Anzahl der Kinder abhängig ist von der Ausbildung und dem Einkommen. Ebenfalls gehen wir davon aus, dass die Ausbildung und das Einkommen miteinander korrelieren.\n\n\nCode\nlibrary(knitr)\n# Daten definieren\nPerson &lt;- 1:20\nKinder &lt;- c(2, 5, 1, 9, 6, 3, 0, 3, 7, 7, 2, 5, 1, 9, 6, 3, 0, 3, 7, 14)\nAusbildung &lt;- c(12, 16, 20, 12, 9, 18, 16, 14, 9, 12, 12, 10, 20, 11, 9, 18, 16, 14, 9, 8)\nEinkommen &lt;- c(30, 40, 90, 50, 40, 120, 100, 10, 40, 30, 100, 40, 90, 40, 40, 120, 100, 60, 40, 10)\n\n# DataFrame erstellen\nanzahlKinderDaten &lt;- data.frame(Person, Kinder, Ausbildung, Einkommen)\n\n# DataFrame anzeigen\nkable(anzahlKinderDaten)\n\n\n\nDaten für das Beispiel\n\n\nPerson\nKinder\nAusbildung\nEinkommen\n\n\n\n\n1\n2\n12\n30\n\n\n2\n5\n16\n40\n\n\n3\n1\n20\n90\n\n\n4\n9\n12\n50\n\n\n5\n6\n9\n40\n\n\n6\n3\n18\n120\n\n\n7\n0\n16\n100\n\n\n8\n3\n14\n10\n\n\n9\n7\n9\n40\n\n\n10\n7\n12\n30\n\n\n11\n2\n12\n100\n\n\n12\n5\n10\n40\n\n\n13\n1\n20\n90\n\n\n14\n9\n11\n40\n\n\n15\n6\n9\n40\n\n\n16\n3\n18\n120\n\n\n17\n0\n16\n100\n\n\n18\n3\n14\n60\n\n\n19\n7\n9\n40\n\n\n20\n14\n8\n10\n\n\n\n\n\nWir formulieren:\n\\[\n\\widehat{Y_i} = \\widehat{\\beta_0} + \\widehat{\\beta_1} X_{1} + \\widehat{\\beta_2} X_{2}\n\\]\n\n\\(\\widehat{Y_i}\\): Vorhergesagte Anzahl der Kinder\n\\(\\widehat{\\beta_0}\\): Achsenabschnitt\n\\(\\widehat{\\beta_1}\\): Regressionskoeffizient für Ausbildung\n\\(\\widehat{\\beta_2}\\): Regressionskoeffizient für Einkommen\n\nWir führen eine multiple Regression durch:\n\nregressionsmodell &lt;- lm(Kinder ~ Ausbildung + Einkommen, data = anzahlKinderDaten)\n\nund erhalten:\n\n\\(\\widehat{\\beta_0}\\) = 12.519\n\\(\\widehat{\\beta_1}\\) = -0.457\n\\(\\widehat{\\beta_2}\\) = -0.031\n\nDaraus ergibt sich die Regressionsgleichung:\n\nCode\ncat(\"$$\",\n    \"Y = \", round(coef(regressionsmodell)[1], 3), \" + \", round(coef(regressionsmodell)[2], 3), \" \\\\cdot X_1 + \", round(coef(regressionsmodell)[3], 3), \" \\\\cdot X_2\",\n    \"$$\")\n\n\\[ Y =  12.519  +  -0.457  \\cdot X_1 +  -0.031  \\cdot X_2 \\]\nDaraus ergibt sich:\n\n\n\n\n\n\n\n\nAusbildung\nEinkommen\nAnzahl der Kinder\n\n\n\n\n\\(0\\)\n\\(0\\)\n\\(\\approx 12.52\\)\n\n\n\\(10\\)\n\\(0\\)\n\\(\\approx 7.95\\)\n\n\n\\(10\\)\n\\(100\\)\n\\(\\approx 4.9\\)\n\n\n\\(20\\)\n\\(200\\)\n\\(\\approx -2.72\\)\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\n\n\nUm die Güte der Schätzung zu beurteilen, rufen wir die summary() Funktion auf:\n\nsummary(regressionsmodell)\n\n\nCall:\nlm(formula = Kinder ~ Ausbildung + Einkommen, data = anzahlKinderDaten)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.1217 -1.7934 -0.1865  1.3497  5.4407 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 12.51855    2.17100   5.766 2.28e-05 ***\nAusbildung  -0.45674    0.21658  -2.109   0.0501 .  \nEinkommen   -0.03053    0.02372  -1.287   0.2152    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.523 on 17 degrees of freedom\nMultiple R-squared:  0.5502,    Adjusted R-squared:  0.4973 \nF-statistic:  10.4 on 2 and 17 DF,  p-value: 0.001124\n\n\n\n\n\n\n\n10.3.3 Multiples Bestimmtheitsmass\nDas multiple Bestimmtheitsmass \\(R^2\\) (Gleichung 10.1) ist ein Mass für die Güte der Anpassung des Regressionsmodells. Es gibt an, wie viel Varianz der abhängigen Variablen durch die unabhängigen Variablen erklärt wird.\n\\[\nR^2 = 1 - \\frac{\\text{Residualsumme}}{\\text{Gesamtvariation}}\n\\]\n\n\\(R^2 = 1\\), wenn alle Punkte auf der Regressions-Hyperebene liegen\n\\(R^2 = 0\\), wenn das Modell keinerlei Erklärung für die Variation von Y liefert.\nBei multipler Regression nimmt \\(R^2\\) mit der Anzahl der unabhängigen Variablen zu. Deshalb nutzt man das angepasste Bestimmtheitsmass \\(R^2_{adj}\\)\n\n\\[\nR^2_{adj} = \\left(R^2 - \\frac{m}{n-1}\\right) \\cdot \\left(\\frac{n-1}{n-m-1}\\right) = 1 - (1 - R^2) \\cdot \\left(\\frac{n-1}{n-m-1}\\right)\n\\]\n\n\\(m\\) ist die Anzahl der unabhängigen Variablen\n\\(n\\) ist die Anzahl der Beobachtungen\nDas angepasste Bestimmtheitsmass \\(R^2_{adj}\\) ist immer kleiner als \\(R^2\\) und nimmt mit zunehmender Anzahl Variablen ab, falls diese nichts zur Erklärung der Varianz beitragen.\n\n\n\n10.3.4 F-Test\nDer F-Test ist ein Hypothesentest, der die Güte des Regressionsmodells als Ganzes überprüft.\n\\[\nF = \\frac{\\frac{R^2}{k}}{\\frac{1-R^2}{n-(k+1)}} = \\frac{\\text{erklärte Varianz}}{\\text{unerklärte Varianz}}\n\\]\n\n\\(R^2\\) ist das multiple Bestimmtheitsmass\n\\(k\\) ist die Anzahl der unabhängigen Variablen\n\\(n\\) ist die Anzahl der Beobachtungen\n\nDer F-Wert sagt, ob das Modell besser ist als einfach die Annahme des Mittelwerts von \\(Y\\) zu nehmen. D.h. ob\n\\[\nH_0 : R^2 = 0\n\\]\nabgelehnt werden kann.\n\n\n10.3.5 Anwendungsbedingungen\n\nLinearität\nNormalverteilung der Residuen\nVarianzhomogenität\nKeine oder wenige Ausreisser\n\n\n# Perfekte synthetische Daten generieren\nset.seed(42)\nn &lt;- 100\nX1 &lt;- rnorm(n, mean = 10, sd = 2)\nX2 &lt;- rnorm(n, mean = 5, sd = 1.5)\n\n# Perfekte lineare Beziehung mit normalverteiltem Fehlerterm\nY &lt;- 3 * X1 + 2 * X2 + rnorm(n, mean = 0, sd = 3)\n\n# Lineares Regressionsmodell\nperfektes_modell &lt;- lm(Y ~ X1 + X2)\n\n# Diagnostische Plots\npar(mfrow = c(2, 2), mar = c(4, 4, 2, 1))  # Layout für 4 Plots\nplot(perfektes_modell)\n\n\n\n\nLinearität",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "glossar.html",
    "href": "glossar.html",
    "title": "11  Glossar",
    "section": "",
    "text": "11.1 Mittelwert \\(\\bar{x}\\) oder \\(\\mu\\)",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Glossar</span>"
    ]
  },
  {
    "objectID": "glossar.html#mittelwert-barx-oder-mu",
    "href": "glossar.html#mittelwert-barx-oder-mu",
    "title": "11  Glossar",
    "section": "",
    "text": "Symbol: \\(\\bar{x}\\) (Stichprobe) oder \\(\\mu\\) (Population)\n\nBeschreibung: Der Mittelwert ist der Durchschnitt aller Werte in einer Stichprobe oder Population. Er gibt an, wo das Zentrum der Daten liegt.\nFormel:\n\\[\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n\\]\nAnwendung: Wird verwendet, um den typischen Wert in Datensätzen zu beschreiben, z.B. den durchschnittlichen Lohn in einer Population.\nR-Code:\n\n\nmean(x)",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Glossar</span>"
    ]
  },
  {
    "objectID": "glossar.html#median-x_0.5",
    "href": "glossar.html#median-x_0.5",
    "title": "11  Glossar",
    "section": "11.2 Median \\(x_{0.5}\\)",
    "text": "11.2 Median \\(x_{0.5}\\)\n\nSymbol: \\(x_{0.5}\\)\n\nBeschreibung: Der Median ist der Wert, der die Daten in zwei gleiche Hälften teilt. Er ist robust gegen Ausreißer und gibt einen durchschnittlichen Wert an, der nicht durch Extremwerte beeinflusst wird.\nFormel:\n\\[\nx_{0.5} = \\begin{cases}\nx_{(n+1)/2} & \\text{falls } n \\text{ ungerade} \\\\\n\\frac{x_{n/2} + x_{n/2+1}}{2} & \\text{falls } n \\text{ gerade}\n\\end{cases}\n\\]\nAnwendung: Wird verwendet, um den typischen Wert in Datensätzen zu beschreiben, z.B. den durchschnittlichen Lohn in einer Population.\nR-Code:\n\n\nmedian(x)",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Glossar</span>"
    ]
  },
  {
    "objectID": "glossar.html#varianz-s2-sigma2",
    "href": "glossar.html#varianz-s2-sigma2",
    "title": "11  Glossar",
    "section": "11.3 Varianz \\(s^2\\), \\(\\sigma^2\\)",
    "text": "11.3 Varianz \\(s^2\\), \\(\\sigma^2\\)\n\nSymbol: \\(s^2\\) (Stichprobe), \\(\\sigma^2\\) (Population)\n\nBeschreibung: Die Varianz misst die durchschnittliche quadratische Abweichung der Werte vom Mittelwert und beschreibt die Streuung der Daten.\nFormel (Stichprobe):\n\\[\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\n\\]\nFormel (Population):\n\\[\n\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2\n\\]\nAnwendung: Wichtig zur Berechnung der Standardabweichung und zur Analyse der Datenstreuung.\nR-Code:\n\n\nvar(x)\n# Für Population: var(x) * (n-1)/n",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Glossar</span>"
    ]
  },
  {
    "objectID": "glossar.html#standardabweichung-s-sigma",
    "href": "glossar.html#standardabweichung-s-sigma",
    "title": "11  Glossar",
    "section": "11.4 Standardabweichung \\(s\\), \\(\\sigma\\)",
    "text": "11.4 Standardabweichung \\(s\\), \\(\\sigma\\)\n\nSymbol: \\(s\\) (Stichprobe), \\(\\sigma\\) (Population)\n\nBeschreibung: Die Standardabweichung ist die Wurzel der Varianz und beschreibt die durchschnittliche Abweichung der Werte vom Mittelwert.\nFormel:\n\\[\ns = \\sqrt{s^2}, \\quad \\sigma = \\sqrt{\\sigma^2}\n\\]\nAnwendung: Zeigt, wie weit die Daten im Durchschnitt um den Mittelwert streuen. Häufig verwendet in der deskriptiven Statistik.\nR-Code:\n\n\nsd(x)",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Glossar</span>"
    ]
  },
  {
    "objectID": "glossar.html#standardfehler-se",
    "href": "glossar.html#standardfehler-se",
    "title": "11  Glossar",
    "section": "11.5 Standardfehler \\(SE\\)",
    "text": "11.5 Standardfehler \\(SE\\)\n\nSymbol: \\(SE\\)\n\nBeschreibung: Der Standardfehler des Mittelwerts misst, wie genau der Mittelwert einer Stichprobe den wahren Mittelwert der Population schätzt.\nFormel:\n\\[\nSE = \\frac{s}{\\sqrt{n}}\n\\]\nAnwendung: Grundlage für Konfidenzintervalle und Hypothesentests.\nR-Code:\n\n\nsd(x) / sqrt(length(x))",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Glossar</span>"
    ]
  },
  {
    "objectID": "glossar.html#t-wert-t",
    "href": "glossar.html#t-wert-t",
    "title": "11  Glossar",
    "section": "11.6 t-Wert \\(t\\)",
    "text": "11.6 t-Wert \\(t\\)\n\nSymbol: \\(t\\)\n\nBeschreibung: Der t-Wert misst, wie stark ein beobachteter Wert vom erwarteten Wert (unter der Nullhypothese) abweicht, gemessen in Standardfehlern.\nFormel (für Mittelwert-Test):\n\\[\nt = \\frac{\\bar{x} - \\mu_0}{SE}\n\\]\nAnwendung: Verwendung in t-Tests, um Hypothesen über Mittelwerte zu überprüfen.\nR-Code:\n\n\nt.test(x, mu = 50)$statistic",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Glossar</span>"
    ]
  },
  {
    "objectID": "glossar.html#p-wert-p",
    "href": "glossar.html#p-wert-p",
    "title": "11  Glossar",
    "section": "11.7 p-Wert \\(p\\)",
    "text": "11.7 p-Wert \\(p\\)\n\nSymbol: \\(p\\)\n\nBeschreibung: Der p-Wert gibt die Wahrscheinlichkeit an, ein Ergebnis zu beobachten, das mindestens so extrem ist wie das tatsächliche Ergebnis, wenn die Nullhypothese wahr ist.\nFormel (zweiseitig):\n\\[\np = 2 \\cdot P(T &gt; |t|)\n\\]\nAnwendung: Dient zur Entscheidungsfindung in Hypothesentests. Ein kleiner p-Wert deutet darauf hin, dass das Ergebnis signifikant ist.\nR-Code:\n\n\nt.test(x, mu = 50)$p.value",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Glossar</span>"
    ]
  },
  {
    "objectID": "glossar.html#freiheitsgrade-df",
    "href": "glossar.html#freiheitsgrade-df",
    "title": "11  Glossar",
    "section": "11.8 Freiheitsgrade \\(df\\)",
    "text": "11.8 Freiheitsgrade \\(df\\)\n\nSymbol: \\(df\\)\n\nBeschreibung: Freiheitsgrade geben an, wie viele Werte in einer Berechnung frei variieren können, ohne dass eine Bedingung verletzt wird.\nFormel (für einfache Stichprobe):\n\\[\ndf = n - 1\n\\]\nAnwendung: Wichtig bei der Bestimmung der kritischen Werte für t- und F-Tests.\nR-Code:\n\n\nlength(x) - 1",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Glossar</span>"
    ]
  },
  {
    "objectID": "glossar.html#regressionskoeffizient-hatbeta",
    "href": "glossar.html#regressionskoeffizient-hatbeta",
    "title": "11  Glossar",
    "section": "11.9 Regressionskoeffizient \\(\\hat{\\beta}\\)",
    "text": "11.9 Regressionskoeffizient \\(\\hat{\\beta}\\)\n\nSymbol: \\(\\hat{\\beta}\\)\n\nBeschreibung: Der Regressionskoeffizient misst den Einfluss eines Prädiktors auf die abhängige Variable in einem linearen Regressionsmodell.\nFormel (lineare Regression):\n\\[\nY = \\beta_0 + \\beta_1 X + \\varepsilon\n\\]\nAnwendung: Analyse von Zusammenhängen zwischen Variablen in Regressionsmodellen.\nR-Code:\n\n\nlm(Y ~ X)$coefficients",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Glossar</span>"
    ]
  },
  {
    "objectID": "glossar.html#standardisiertes-residuum-r_i",
    "href": "glossar.html#standardisiertes-residuum-r_i",
    "title": "11  Glossar",
    "section": "11.10 Standardisiertes Residuum \\(r_i\\)",
    "text": "11.10 Standardisiertes Residuum \\(r_i\\)\n\nSymbol: \\(r_i\\)\n\nBeschreibung: Das standardisierte Residuum misst die Abweichung eines beobachteten Werts vom vorhergesagten Wert in Standardabweichungseinheiten.\nFormel:\n\\[\nr_i = \\frac{e_i}{SE(e_i)}\n\\]\nAnwendung: Identifikation von Ausreißern in Regressionsmodellen.\nR-Code:\n\n\nrstandard(lm(Y ~ X))",
    "crumbs": [
      "Statistische Datenanalyse",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Glossar</span>"
    ]
  },
  {
    "objectID": "excercises/ex01.html",
    "href": "excercises/ex01.html",
    "title": "Appendix A — Übung 1: Grundlagen R",
    "section": "",
    "text": "B Übung 1: Grundlagen R",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Übung 1: Grundlagen R</span>"
    ]
  },
  {
    "objectID": "excercises/ex01.html#vektoren",
    "href": "excercises/ex01.html#vektoren",
    "title": "Appendix A — Übung 1: Grundlagen R",
    "section": "B.1 Vektoren",
    "text": "B.1 Vektoren\nÜberlegt euch die erwarteten Lösungen vor dem Eintippen\n\nx &lt;- c(5, 2, 1, 4)\nxx &lt;- c(1, 10, 15, 18)\ny &lt;- rep(1, 5)\nz &lt;- c(TRUE, FALSE, TRUE, TRUE)\n\n\nB.1.1 Aufgabe a)\n\nsum(x)\nrange(x)\nlength(x)\nmax(x)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsum(x)\n\n[1] 12\n\nrange(x)\n\n[1] 1 5\n\nlength(x)\n\n[1] 4\n\nmax(x)\n\n[1] 5\n\n\n\n\n\n\n\nB.1.2 Aufgabe b)\n\nc(x, y, 13)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nc(x, y, 13)\n\n [1]  5  2  1  4  1  1  1  1  1 13\n\n\n\n\n\n\n\nB.1.3 Aufgabe c)\n\nx[4] * y[2]\nxx[2:4] + x[1:3]\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nx[4] * y[2]\n\n[1] 4\n\nxx[2:4] + x[1:3]\n\n[1] 15 17 19\n\n\n\n\n\n\n\nB.1.4 Aufgabe d)\n\nxx &lt;= 12\nxx[xx &lt;= 12]\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nxx &lt;= 12\n\n[1]  TRUE  TRUE FALSE FALSE\n\nxx[xx &lt;= 12]\n\n[1]  1 10\n\n\n\n\n\n\n\nB.1.5 Aufgabe e)\n\nplot(x, xx)\nplot(x[z], xx[z])\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nplot(x, xx)\n\n\n\n\n\n\n\nplot(x[z], xx[z])",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Übung 1: Grundlagen R</span>"
    ]
  },
  {
    "objectID": "excercises/ex01.html#zahlenfolgen",
    "href": "excercises/ex01.html#zahlenfolgen",
    "title": "Appendix A — Übung 1: Grundlagen R",
    "section": "B.2 Zahlenfolgen",
    "text": "B.2 Zahlenfolgen\nErzeugt mit den rep()und seq() Funktionen die folgenden Zahlenfolgen:\n\nB.2.1 Aufgabe a)\n1 2 3 4 5 6 7 8 9\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nseq(1, 9)\n\n[1] 1 2 3 4 5 6 7 8 9\n\n\noder gleichwertig:\n\n1:9\n\n[1] 1 2 3 4 5 6 7 8 9\n\n\n\n\n\n\n\nB.2.2 Aufgabe b)\n\"m\" \"w\" \"m\" \"w\" \"m\" \"w\"\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nrep(c(\"m\", \"w\"), 3)\n\n[1] \"m\" \"w\" \"m\" \"w\" \"m\" \"w\"\n\n\noder gleichwertig:\n\nrep(c(\"m\", \"w\"), length = 6)\n\n[1] \"m\" \"w\" \"m\" \"w\" \"m\" \"w\"\n\n\n\n\n\n\n\nB.2.3 Aufgabe c)\n1 2 3 4 1 2 3 4 1 2 3 4\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nrep(1:4, 3)\n\n [1] 1 2 3 4 1 2 3 4 1 2 3 4\n\n\n\n\n\n\n\nB.2.4 Aufgabe d)\n1 2 2 3 3 3 4 4 4 4\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nrep(1:4, 1:4)\n\n [1] 1 2 2 3 3 3 4 4 4 4",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Übung 1: Grundlagen R</span>"
    ]
  },
  {
    "objectID": "excercises/ex01.html#datei-einlesen",
    "href": "excercises/ex01.html#datei-einlesen",
    "title": "Appendix A — Übung 1: Grundlagen R",
    "section": "B.3 Datei einlesen",
    "text": "B.3 Datei einlesen\nLest die Datei meteodaten_saison.csv in R ein:\n\n1saison &lt;- read.table(\"Pfad/zur/Datei.csv\",\n2                     sep = \",\",\n                     header = TRUE)\n\n\n1\n\nSetzt den korrekten Pfad zur Datei ein.\n\n2\n\nWeitere Argumente für den Funktionsaufruf: sep (separator) gibt an welches Trennzeichen in der Datei verwendet wird und header ob die erste Zeile als Spaltennamen verwendet werden soll.\n\n\n\n\nÜberprüft, ob der Import korrekt verlief.\n\n\n\n\n\n\nTip\n\n\n\nDer Pfad zur Datei kann relativ oder absolut sein. In aller Regel ist es einfacher, Daten in einem Unterordner (z.B. Data) zu speichern und dann nur den Dateinamen anzugeben.\nWichtig ist das korrekte Setzten des Arbeitsverzeichnisses in RStudio:\nSession -&gt; Set Working Directory -&gt; To Source File Location\nDanach können Dateien relativ zum aktuellen Skriptpfad geladen werden.\nBeispiel für einen relativen Pfad:\n\nsaison &lt;- read.table(\"Data/meteodaten_saison.csv\",\n                     sep = \",\",\n                     header = TRUE)\n\n\n\nAnschliessend könnt ihr die Daten mit str(), head(), summary(), tail(), class(), etc. überprüfen.\n\nstr(saison)\n\n'data.frame':   492 obs. of  6 variables:\n $ Jahr                           : int  1901 1901 1901 1901 1902 1902 1902 1902 1903 1903 ...\n $ Saison                         : chr  \"Fruehling(MAM)\" \"Herbst(SON)\" \"Sommer(JJA)\" \"Winter(DJF)\" ...\n $ Bern_Mitteltemperatur          : num  7.73 7.4 16.8 -2.73 7.53 ...\n $ Bern_Niederschlagssumme        : num  278 245 381 112 323 ...\n $ GrStBernhard_Mitteltemperatur  : num  -4 -0.8 6.3 -10.6 -3.63 ...\n $ GrStBernhard_Niederschlagssumme: num  495 521 285 356 448 ...",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Übung 1: Grundlagen R</span>"
    ]
  },
  {
    "objectID": "excercises/ex02.html",
    "href": "excercises/ex02.html",
    "title": "Appendix B — R-Übungen 2",
    "section": "",
    "text": "B.1 Grafik erstellen",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R-Übungen 2</span>"
    ]
  },
  {
    "objectID": "excercises/ex02.html#grafik-erstellen",
    "href": "excercises/ex02.html#grafik-erstellen",
    "title": "Appendix B — R-Übungen 2",
    "section": "",
    "text": "B.1.1 Aufgabe\n\nExtrahiert aus den saisonalen Daten:\n\ndie Frühlingsdaten,\ndie Sommerdaten,\ndie Herbstdaten.\n\n\nBeispiel:\n\nfruehling &lt;- saison[saison[,2] == \"Fruehling(MAM)\", ]\n\n\nErstellt einen Plot, mit:\n\nden Jahren auf der x-Achse und\nder Temperatur in Genf auf der y-Achse.\n\nStellt dabei die Frühlings-, Sommer- und Herbsttemperaturen als Linien mit unterschiedlichen Farben dar.\n\n\nB.1.1.1 Schritte:\n\nZuerst:\n\n\nplot(x, y, col = \" \", xlab = \" \", ...)\n\n\nDann mit:\n\n\nlines(x, y, col = ...)\n\nweitere Saisons hinzufügen.\n\nÜberschrift und Achsen beschriften.\nLinien der beiden Mittelwerte hinzufügen:\n\n\nabline(h = ...)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nJahreszeitentabelle &lt;- read.table(\"Data/meteodaten_saison.csv\",\n                     header = TRUE,\n                     sep = \",\")\n\nsaison_fruehling &lt;- Jahreszeitentabelle[Jahreszeitentabelle[, 2] == \"Fruehling(MAM)\", ]\nsaison_sommer &lt;- Jahreszeitentabelle[Jahreszeitentabelle$Saison == \"Sommer(JJA)\", ]\nsaison_herbst &lt;- Jahreszeitentabelle[Jahreszeitentabelle$Saison == \"Herbst(SON)\", ]\nsaison_winter &lt;- Jahreszeitentabelle[Jahreszeitentabelle$Saison == \"Winter(DJF)\", ]\n\nsaison_helper &lt;- data.frame(\n    saison_name = c(\"Fruehling\", \"Sommer\", \"Herbst\", \"Winter\"),\n    saison_farbe = c(\"green\", \"red\", \"orange\", \"blue\"))\n\nplot(saison_fruehling$Jahr,\n     saison_fruehling$Bern_Mitteltemperatur,\n     type = \"line\",\n\n     xlab = \"Jahr\",\n     ylab = \"Mitteltemperatur\",\n     main = \"Mitteltemperatur in Bern nach Jahreszeiten\",\n     ylim = c(-5, 25))\n\nWarning in plot.xy(xy, type, ...): plot type 'line' will be truncated to first\ncharacter\n\nlines(saison_sommer$Jahr,\n      saison_sommer$Bern_Mitteltemperatur,\n      col = saison_helper$saison_farbe[2]\n)\n\nlines(saison_herbst$Jahr,\n      saison_herbst$Bern_Mitteltemperatur,\n      col = saison_helper$saison_farbe[3]\n)\n\nlines(saison_winter$Jahr,\n      saison_winter$Bern_Mitteltemperatur,\n      col = saison_helper$saison_farbe[4]\n)\n\n\n\n\n\n\nlegend(\"topright\",\n       legend = saison_helper$saison_name,\n       col = saison_helper$saison_farbe,\n       lty = 1,\n       cex = 0.8\n       )\n\nabline(mean(saison_fruehling$Bern_Mitteltemperatur),\n       0,\n       col = \"green\")\n\n\n\n\n\n\n\n\n\nSchnittpunkt mit der y-Achse\nSteigung der Linie",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R-Übungen 2</span>"
    ]
  },
  {
    "objectID": "excercises/ex02.html#jahresmittelwerte",
    "href": "excercises/ex02.html#jahresmittelwerte",
    "title": "Appendix B — R-Übungen 2",
    "section": "B.2 Jahresmittelwerte",
    "text": "B.2 Jahresmittelwerte\n\nB.2.1 Aufgabe\n\nErstellt mittels aggregate() die Jahresmittelwerte der Temperatur für Genf.\nStellt diese in einem Scatterplot mit Punkten dar:\n\n\nplot(x, y)\n\n\nBeschriftet die Achsen und vergebt einen Titel.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nJahreswerte &lt;- aggregate(Jahreszeitentabelle$Bern_Mitteltemperatur,\n                         by = list(Jahreszeitentabelle$Jahr),\n                         FUN = mean)\n\n# Für bessere Lesbarkeit: umbenennen der generierten Spaltennamen\ncolnames(Jahreswerte) &lt;- c(\"Jahr\", \"Mitteltemperatur\")\n\nplot(Jahreswerte$Jahr,\n     Jahreswerte$Mitteltemperatur,\n     col = \"black\",\n     xlab = \"Jahr\",\n     ylab = \"Mitteltemperatur\",\n     ylim = c(7, 12),\n     main = \"Mitteltemperatur in Bern nach Jahren\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R-Übungen 2</span>"
    ]
  },
  {
    "objectID": "excercises/ex02.html#boxplot",
    "href": "excercises/ex02.html#boxplot",
    "title": "Appendix B — R-Übungen 2",
    "section": "B.3 Boxplot",
    "text": "B.3 Boxplot\n\nWählt den Zeitraum 1981-2010, z.B.:\n\n\nzeit &lt;- saison[saison[,1] &gt;= 1981 & saison[,1] &lt;= 2010, ]\n\n\nStellt die Temperatur- und Niederschlagsverteilungen der Saisons in Genf und Gr. S. Bernhard für diesen Zeitraum in vier boxplot()-Plots dar.\n\n\nB.3.1 Hinweise:\n\nDas Grafikausgabefenster kann mit:\n\n\npar(mfrow = c(2, 2))\n\nin 2 Zeilen und 2 Spalten geteilt werden.\n\nBeschriftet die Achsen und vergebt Titel. Achtet darauf, für beide Stationen gleiche y-Achsen zu wählen, sodass die Plots visuell vergleichbar sind. Z.B. bei Niederschlag:\n\n\nylim = c(0, 1300)\n\n\nSetzt das Grafikausgabefenster zurück auf 1 Zeile und 1 Spalte:\n\n\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nzeitraum &lt;- 1981:2010\n\n# Ausgabefenster in 2x2 aufteilen\npar(mfrow = c(2, 2))\n\nboxplot(Jahreszeitentabelle$Bern_Mitteltemperatur ~ Jahreszeitentabelle$Saison,\n        data = Jahreszeitentabelle[Jahreszeitentabelle$Jahr %in% zeitraum, ],\n        col = saison_helper$saison_farbe,\n        xlab = \"Jahreszeiten\",\n        ylab = \"Mitteltemperatur\",\n        main = \"Mitteltemperatur in Bern nach Saison (1981-2010)\",\n        ylim = c(-12, 22))\n\nboxplot(Jahreszeitentabelle$GrStBernhard_Mitteltemperatur ~ Jahreszeitentabelle$Saison,\n        data = Jahreszeitentabelle[Jahreszeitentabelle$Jahr %in% zeitraum, ],\n        col = saison_helper$saison_farbe,\n        xlab = \"Jahreszeiten\",\n        ylab = \"Mitteltemperatur\",\n        main = \"Mitteltemperatur auf dem GSB nach Saison (1981-2010)\",\n        ylim = c(-12, 22))\n\nboxplot(Jahreszeitentabelle$Bern_Niederschlagssumme ~ Jahreszeitentabelle$Saison,\n        data = Jahreszeitentabelle[Jahreszeitentabelle$Jahr %in% zeitraum, ],\n        col = saison_helper$saison_farbe,\n        xlab = \"Jahreszeiten\",\n        ylab = \"Niederschlagssumme\",\n        main = \"Niederschlagssumme in Bern nach Saison (1981-2010)\",\n        ylim = c(0, 1400))\n\nboxplot(Jahreszeitentabelle$GrStBernhard_Niederschlagssumme ~ Jahreszeitentabelle$Saison,\n        data = Jahreszeitentabelle[Jahreszeitentabelle$Jahr %in% zeitraum, ],\n        col = saison_helper$saison_farbe,\n        xlab = \"Jahreszeiten\",\n        ylab = \"Niederschlagssumme\",\n        main = \"Niederschlagssumme auf dem GSB nach Saison (1981-2010)\",\n        ylim = c(0, 1400))\n\n\n\n\n\n\n\n# Ausgabefenster zurücksetzen\npar(mfrow = c(1, 1))",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R-Übungen 2</span>"
    ]
  },
  {
    "objectID": "excercises/ex03.html",
    "href": "excercises/ex03.html",
    "title": "Appendix C — R-Übungen 3",
    "section": "",
    "text": "C.1 Sommer (JJA) Temperaturanomalien",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>R-Übungen 3</span>"
    ]
  },
  {
    "objectID": "excercises/ex03.html#sommer-jja-temperaturanomalien",
    "href": "excercises/ex03.html#sommer-jja-temperaturanomalien",
    "title": "Appendix C — R-Übungen 3",
    "section": "",
    "text": "C.1.1 Aufgabe\n\nBerechnet die Sommer (JJA) Temperaturanomalien zur Referenzperiode 1961 bis 1990 in Bern mit Excel.\nSchreibt R-Code, um die gleiche Berechnung durchzuführen.\nHinweis: Chatbots können neuerdings Datenanalysen ohne Programmierkenntnisse durchführen. Siehe: Data Analysis with ChatGPT\nAufgabe: Überprüft den generierten Code und diskutiert die Vorteile, Nachteile und Risiken der drei Methoden.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>R-Übungen 3</span>"
    ]
  },
  {
    "objectID": "excercises/ex03.html#klimadiagramm",
    "href": "excercises/ex03.html#klimadiagramm",
    "title": "Appendix C — R-Übungen 3",
    "section": "C.2 Klimadiagramm",
    "text": "C.2 Klimadiagramm\n\nC.2.1 Schritte\n\nDatensatz laden:\n\nmeteodaten_tag.csv (nach Excel-Export in R):\n\n\n\ndata &lt;- read.csv(\"meteodaten_tag.csv\", na.strings = c(\"-\", \"NA\"))\n\n\nDatenstruktur überprüfen:\n\nstr(data)\n\nPrüfen, ob die Daten korrekt (z. B. numerisch) gelesen wurden.\nHistogramm erstellen:\n\nMit den Tagestemperaturen (z. B. mit feinen Abständen):\n\n\nhist(data$temp, breaks = 40)\n\nMonatsmittelwerte berechnen:\n\nTemperatur und Bewölkung über alle Jahre (z. B. Mittelwerte für jeden Monat).\nAchtung: Fehlwerte berücksichtigen.\n\nPlot erstellen:\n\nZwei Barplots (Temperatur und Bewölkung) übereinander:\n\n\npar(mfrow = c(2, 1))\nbarplot(temperature_means, main = \"Monatsmittelwerte Temperatur\")\nbarplot(cloud_cover_means, main = \"Monatsmittelwerte Bewölkung\")\n\n\nErwartet: Welche Trends zeigen die Ergebnisse?\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nComming soon!",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>R-Übungen 3</span>"
    ]
  },
  {
    "objectID": "excercises/ex03.html#boxplots",
    "href": "excercises/ex03.html#boxplots",
    "title": "Appendix C — R-Übungen 3",
    "section": "C.3 Boxplots",
    "text": "C.3 Boxplots\n\nC.3.1 Aufgabe\n\nWählt den Zeitraum 2000-2001 in den täglichen Daten, z. B.:\n\nzeit &lt;- meteodaten_tag[meteodaten_tag[, 1] &gt;= 2000 & meteodaten_tag[, 1] &lt;= 2001, ]\n\nBoxplot erstellen:\n\nTemperaturen als Funktion der Bewölkung:\n\nboxplot(temp ~ cloud_cover, data = zeit)\n\nAchsen beschriften und Titel vergeben.\n\nAnalyse:\n\nUnter welchen Bewölkungsbedingungen ist die Spannweite/Varianz der Temperatur am größten?\nFindet den bewölkungsärmsten und bewölkungsreichsten Monat (im Mittel der zwei Jahre). Wie hoch ist die mittlere Bewölkung (in Oktas)?\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nComming soon!",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>R-Übungen 3</span>"
    ]
  },
  {
    "objectID": "excercises/ex03.html#r-als-gis-ersatz",
    "href": "excercises/ex03.html#r-als-gis-ersatz",
    "title": "Appendix C — R-Übungen 3",
    "section": "C.4 R als GIS-Ersatz",
    "text": "C.4 R als GIS-Ersatz\n\nC.4.1 Schritte\n\nPaket installieren und laden:\n\n\ninstall.packages(\"maps\")\nlibrary(maps)\n\n\nKoordinaten herausfinden:\n\nFür Genf und Gr. S. Bernhard (ca.).\n\nEuropakarte erstellen:\n\nLeeren Plot erstellen:\n\n\n\nplot(x = c(-5, 30), y = c(35, 60), type = \"n\", xlab = \"lon\", ylab = \"lat\")\n\n\nWeltkarte hinzufügen:\n\n\nmap(\"world\", add = TRUE)\n\n\nStationen hinzufügen:\n\nStationen als Punkte plotten (mit unterschiedlichen Farben/Symbolen):\n\n\n\npoints(x_coord, y_coord, col = \"red\", pch = 19)\ntext(x_coord, y_coord, labels = station_names, pos = 4)\n\n\nHinweis: Für genaue Koordinaten verwendet Google!\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nComming soon!",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>R-Übungen 3</span>"
    ]
  },
  {
    "objectID": "excercises/deskriptive-statistik.html",
    "href": "excercises/deskriptive-statistik.html",
    "title": "Appendix D — Übung 4: Deskriptive Statistik und Visualisierung",
    "section": "",
    "text": "D.1 Histogramm und Kennzahlen\nArbeite mit den saisonalen Meteodaten, die wir im R-Kurs eingelesen haben\nIhr möchtet die mittlere Jahresniederschlagssumme und die mittlere Jahrestemperatur sowie deren Varianz von Jahr zu Jahr bestimmen, um die Klimabedingungen in Bern zu beschreiben.\nUm die richtigen Kennzahlen (Mittelwert, Median, Modus, etc.) zu wählen, müssen wir die Verteilung der Daten kennen. Erstellt ein Histogramm der Jahresmitteltemperaturen und -niederschlag:\n# Jahresdaten erstellen\n# Berechne Jahresmittelwerte und -summen\njahresmitteltemp_bern &lt;- aggregate(meteodaten$Bern_Mitteltemperatur ~ meteodaten$Jahr,\n                                   FUN = mean,\n                                   na.rm = TRUE)\njahresmitteltemp_grstbernhard &lt;- aggregate(meteodaten$GrStBernhard_Mitteltemperatur ~ meteodaten$Jahr,\n                                           FUN = mean,\n                                           na.rm = TRUE)\njahresniederschlag_bern &lt;- aggregate(meteodaten$Bern_Niederschlagssumme ~ meteodaten$Jahr,\n                                     FUN = sum,\n                                     na.rm = TRUE)\njahresniederschlag_grstbernhard &lt;- aggregate(meteodaten$GrStBernhard_Niederschlagssumme ~ meteodaten$Jahr,\n                                             FUN = sum,\n                                             na.rm = TRUE)\n\n# Kombiniere die Ergebnisse in eine neue Tabelle\njahresdaten &lt;- data.frame(\n  Jahr = jahresmitteltemp_bern$`meteodaten$Jahr`,\n  Bern_Mitteltemperatur = jahresmitteltemp_bern$`meteodaten$Bern_Mitteltemperatur`,\n  GrStBernhard_Mitteltemperatur = jahresmitteltemp_grstbernhard$`meteodaten$GrStBernhard_Mitteltemperatur`,\n  Bern_Niederschlagssumme = jahresniederschlag_bern$`meteodaten$Bern_Niederschlagssumme`,\n  GrStBernhard_Niederschlagssumme = jahresniederschlag_grstbernhard$`meteodaten$GrStBernhard_Niederschlagssumme`\n)\n\n\nhist(jahresdaten$Bern_Mitteltemperatur,\n     main = 'Histogramm der Mitteltemperatur in Bern',\n     xlab = 'Mitteltemperatur (°C)',\n     ylab = 'Anzahl der Jahre',\n     xlim = c(6, 12),\n     ylim = c(0, 15),\n     breaks = 30)\n\n\n\n\n\n\n\nhist(jahresdaten$Bern_Niederschlagssumme,\n     main = 'Histogramm der Niederschlagssumme in Bern',\n     xlab = 'Niederschlagssumme (mm)',\n     ylab = 'Anzahl der Jahre',\n     xlim = c(500, 1500),\n     ylim = c(0, 10),\n     breaks = 30)\nBeide Verteilungen sind ungefähr symmetrisch, da die Daten in der Mitte des Bereichs konzentriert sind und die Verteilung nach links und rechts ungefähr gleich ist. Dies ist aber mit so “wenigen” Daten nicht wirklich aussagekräftig. Das macht aber bei der Art der Daten Sinn, da die Temperatur und Niederschlagssumme in der Regel normalverteilt sind.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Übung 4: Deskriptive Statistik und Visualisierung</span>"
    ]
  },
  {
    "objectID": "excercises/deskriptive-statistik.html#histogramm-und-kennzahlen",
    "href": "excercises/deskriptive-statistik.html#histogramm-und-kennzahlen",
    "title": "Appendix D — Übung 4: Deskriptive Statistik und Visualisierung",
    "section": "",
    "text": "D.1.1 Kennzahlen\nWelche Kennzahlen zur Beschreibung des Mittels und der Streuung kommen aufgrund den Verteilung und Skala der Daten in Frage?\nDa die Daten normalverteilt sind, können wir den Mittelwert und die Standardabweichung verwenden, um die zentrale Tendenz und die Streuung der Daten zu beschreiben. Der Median ist auch eine gute Kennzahl, um die zentrale Tendenz zu beschreiben, da er robust gegenüber Ausreissern ist.\n\nBerechne Mittelwert, Median, Spannweite und Standardabweichung des jährlichen Temperaturen in Bern und schaue dir zusätzlich die Ausgabe der summary() Funktion von R an.\n\n\nmean_temp_bern &lt;- mean(jahresdaten$Bern_Mitteltemperatur)\nprint(mean_temp_bern)\n\n[1] 8.715176\n\nmedian_temp_bern &lt;- median(jahresdaten$Bern_Mitteltemperatur)\nprint(median_temp_bern)\n\n[1] 8.666667\n\nrange_temp_bern &lt;- diff(range(jahresdaten$Bern_Mitteltemperatur))\nrange(jahresdaten$Bern_Mitteltemperatur)\n\n[1]  7.091667 11.050000\n\nprint(range_temp_bern)\n\n[1] 3.958333\n\nsd_temp_bern &lt;- sd(jahresdaten$Bern_Mitteltemperatur)\nprint(sd_temp_bern)\n\n[1] 0.8185026\n\nsummary(jahresdaten$Bern_Mitteltemperatur)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  7.092   8.104   8.667   8.715   9.221  11.050 \n\n\nDer Unterschied zwischen Mittelwert und Median (0.05°C) ist sehr klein, was darauf hindeutet, dass die Verteilung der Daten symmetrisch ist. Die Spannweite der Daten beträgt 3.96 °C, was darauf hindeutet, dass die Daten relativ eng um den Mittelwert verteilt sind. Die Standardabweichung beträgt 0.82°C, was darauf hindeutet, dass die Daten relativ homogen um den Mittelwert verteilt sind.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Übung 4: Deskriptive Statistik und Visualisierung</span>"
    ]
  },
  {
    "objectID": "excercises/deskriptive-statistik.html#kontingenztabelle",
    "href": "excercises/deskriptive-statistik.html#kontingenztabelle",
    "title": "Appendix D — Übung 4: Deskriptive Statistik und Visualisierung",
    "section": "D.2 Kontingenztabelle",
    "text": "D.2 Kontingenztabelle\n\nKonvertiere die Spalte mit den Niederschlagssummen in Bern in Klassen, die jeweils 100 mm umfassen (Tipp: z.B. mit round() Funktion für Klassen: &lt;50mm, 50-150mm, 150-250mm, …) Erstelle die Kontingenztabelle für die Anzahl der Regensummen in den 100 mm Klassen in den vier Jahreszeiten (table() Funktion)\n\n                  0 100 200 300 400 500 600\nFruehling(MAM)  ?  ?   ?   ?   ?   ?   ?\nHerbst(SON)     ?  ?   ?   ?   ?   ?   ?\nSommer(JJA)     ?  ?   ?   ?   ?   ?   ?\nWinter(DJF)     ?  ?   ?   ?   ?   ?   ?\nKontingenztabelle mit R erstellen\n\n# 1. Erstelle Klassen für Niederschlagssummen in Bern in 100-mm-Schritten\n# Die Spalte 'Saison' enthält die Jahreszeiten (z.B. 'Fruehling(MAM)', 'Sommer(JJA)')\n# Die Spalte 'Bern_Niederschlagssumme' enthält die Niederschlagssummen\n\n# Klassen für Niederschlagssummen in 100-mm-Schritten erstellen\nmeteodaten$Niederschlag_klassen &lt;- cut(\n  meteodaten$Bern_Niederschlagssumme,\n  breaks = seq(0, max(meteodaten$Bern_Niederschlagssumme, na.rm = TRUE), by = 100),\n  include.lowest = TRUE,\n  right = FALSE\n)\n\nDie Einteilung liesse sich auch einfacher machen, aber etwas weniger hübsch…\n\n# Klassen für Niederschlagssummen in 100-mm-Schritten erstellen\nmeteodaten$Niederschlag_klassen &lt;-\n            round(meteodaten$Bern_Niederschlagssumme/100)*100\n\nWir arbeiten weiter mit der ersten Lösung.\n\n# 2. Erstelle eine Kontingenztabelle\nkontingenz_tabelle &lt;- table(\n  meteodaten$Saison,\n  meteodaten$Niederschlag_klassen\n)\n\n# 3. Zeige die Kontingenztabelle an\nprint(kontingenz_tabelle)\n\n                \n                 [0,100) [100,200) [200,300) [300,400) [400,500) [500,600]\n  Fruehling(MAM)       0        36        60        25         1         1\n  Herbst(SON)          2        38        53        24         6         0\n  Sommer(JJA)          0         7        40        41        31         3\n  Winter(DJF)         14        59        45         5         0         0",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Übung 4: Deskriptive Statistik und Visualisierung</span>"
    ]
  },
  {
    "objectID": "excercises/deskriptive-statistik.html#visualisierung-des-erwärmungstrends",
    "href": "excercises/deskriptive-statistik.html#visualisierung-des-erwärmungstrends",
    "title": "Appendix D — Übung 4: Deskriptive Statistik und Visualisierung",
    "section": "D.3 Visualisierung des Erwärmungstrends",
    "text": "D.3 Visualisierung des Erwärmungstrends\n\nVisualisiert die Erwärmungstrend der Station Bern mit einem Liniendiagramm, indem du die Jahresmitteltemperatur darstellst und die 31-jährige Gleitende Mittel (auch “running mean” genannt z.B. mit der Funktion runmean() aus der Bibliothek “caTools”) hinzufügst.\n\n\nD.3.1 Liniendiagramm mit Gleitendem Mittel\n\n# Bibliothek caTools laden\nlibrary(caTools)\n\n# Berechnung des 31-jährigen gleitenden Mittels (Running Mean)\n# Die Spalte für die Mitteltemperatur in Bern heisst 'Bern_Mitteltemperatur'\ngleitendes_mittel &lt;- runmean(jahresdaten$Bern_Mitteltemperatur, 31, align = \"center\", endrule = \"mean\")\n\n# Liniendiagramm erstellen\nplot(jahresdaten$Jahr, jahresdaten$Bern_Mitteltemperatur, type = \"l\", col = \"blue\",\n     xlab = \"Jahr\", ylab = \"Mitteltemperatur in Bern (°C)\",\n     main = \"Erwärmungstrend der Station Bern mit 31-jährigem Gleitendem Mittel\")\n\n# Hinzufügen der Gleitenden Mittel-Linie (31-jähriges Running Mean)\nlines(jahresdaten$Jahr, gleitendes_mittel, col = \"red\", lwd = 2)\n\n# Legende hinzufügen\nlegend(\"topright\", legend = c(\"Jahresmitteltemperatur\", \"31-jähriges Gleitendes Mittel\"),\n       col = c(\"blue\", \"red\"), lty = 1, lwd = 2)\n\n\n\n\n\n\n\n\nErstelle zusätzlich zwei Abbildungen der Temperaturanomalien wie hier und hier:\n\n\nD.3.2 Warming Stripes\n\n# Bibliothek\n# Bibliothek\nlibrary(ggplot2)\n\n# Berechnung der Abweichung der Mitteltemperatur von der Referenzperiode 1961-1990\njahresdaten$Abweichung &lt;- jahresdaten$Bern_Mitteltemperatur - mean(jahresdaten$Bern_Mitteltemperatur[jahresdaten$Jahr &gt;= 1961 & jahresdaten$Jahr &lt;= 1990])\n\n# Erstelle die \"Warming Stripes\" mit Legende\nggplot(jahresdaten, aes(x = Jahr, y = 1, fill = Abweichung)) +\n  geom_tile() +\n  scale_fill_gradientn(\n    colours = c(\"blue\", \"lightblue\", \"white\", \"orange\", \"red\", \"darkred\"),\n    name = \"Temperaturabweichung (°C)\"\n  ) +\n  theme_void() +  # Entfernt Achsen, Titel etc.\n  theme(legend.position = \"bottom\", legend.title = element_text(size = 10)) +\n  labs(title = \"Schweizer Temperatur seit 1864\")\n\n\n\n\nWarming Stripes im vergleich zur Referenzperiode 1961-1990. Nach R-Bloggers\n\n\n\n\n\n\nD.3.3 Barplot der Temperaturanomalien\n\n# Bibliotheken\nlibrary(ggplot2)\n\n# Erstelle einen Barplot, der die Abweichungen darstellt\nggplot(jahresdaten, aes(x = Jahr, y = Abweichung, fill = Abweichung &gt; 0)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  scale_fill_manual(values = c(\"blue\", \"red\")) +  # Farben: Blau für kälter, Rot für wärmer\n  theme_minimal() +\n  labs(title = \"Jahres-Temperatur Abweichungen – Bern\",\n       x = \"Jahr\",\n       y = \"Abweichung in °C\") +\n  theme(plot.title = element_text(hjust = 0.5))  # Zentriere den Titel\n\n\n\n\nBarplot der Temperaturanomalien zur Vergleichsperiode 1961–1990.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Übung 4: Deskriptive Statistik und Visualisierung</span>"
    ]
  },
  {
    "objectID": "excercises/verteilungen-und-tests.html",
    "href": "excercises/verteilungen-und-tests.html",
    "title": "Appendix E — Übung 5 & 6: Verteilungen und Tests",
    "section": "",
    "text": "E.1 Statistische Tests mit Psychologieexperiment\nErstellt mit R das Histogramm und die Verteilungsfunktion des Sommer-Niederschlags am Grossen St. Bernhard (Datei mit Saison-Mittelwerten). Tipp: In R kann die empirische Verteilungsfunktion mit der Funktion ecdf() erzeugt werden.\nLies aus dem Plot der Verteilungsfunktion ungefähr ab, welcher Niederschlag in 20% der Jahre überschritten wird?\nANTWORT: Die Niederschlagssumme, die in 20% der Jahre überschritten wird, beträgt 647.2 mm.\nDaten einlesen\npsychologieExperiment &lt;- read.table('Data/Psycho_Exp_Ergebnisse2_2024-10-28.csv',\n                                    sep = ',',\n                                    header = TRUE,\n                                    na.strings = '999')\n\n# Spalten im DataFrame umbenennen (kürzere und schönere Namen)\ncolnames(psychologieExperiment) &lt;- c(\n  \"Gefuehl_Vor_SelberGutesTun\",\n  \"Gefuehl_Nach_SelberGutesTun\",\n  \"Gefuehl_Vor_AnderenGutesTun\",\n  \"Gefuehl_Nach_AnderenGutesTun\")\nGehen wir mal davon aus, dass die Mittelwerte interpretierbar seien. (Nächste Woche lernen wir weitere Test für Verteilungen kennen und Test, wenn die Normalverteilung nicht gegeben ist.) Dann könnten wir untersuchen, wie stark sich die Mittelwerte vor und nach dem Experiment unterscheiden und ob die Unterschiede statistisch signifikant sind.\nStellt nun zunächst die Null- und Alternativhypothesen für beide Experimente (1. sich selber und 2. anderen etwas gutes tun) auf, ob etwas Gutes tun sich auf das Wohlbefinden auswirkt.\nH0: Die beiden Mittelwerte sind gleich\nHA: Jemandem oder uns selbst etwas Gutes zu tun, hat einen (positiven) Einfluss auf das Wohlbefinden\nErstelle einen Boxplot, um die Verteilung der Daten anzusehen und einen ersten Eindruck zu erhalten\nboxplot(psychologieExperiment,\n        main = \"Boxplot der Gefühle vor und nach dem Experiment\",\n        ylab = \"Gefühle\",\n        col = c(\"lightblue\", \"lightgreen\"),\n        names = c(\"Gefühl, vor dem man sich selbst etwas Gutes tut\",\n                  \"Gefühl, nach dem man sich selbst etwas Gutes tut\",\n                  \"Gefühl, vor dem man jemand anderem etwas Gutes tut\",\n                  \"Gefühl, nach dem man jemand anderem etwas Gutes tut\"),\n        las = 2)\nBerechne wie gross die Unterschiede der Mittelwerte sind?\nDiffSelberGutesTun &lt;- mean(psychologieExperiment$Gefuehl_Nach_SelberGutesTun,\n                           na.rm = TRUE) -\n                      mean(psychologieExperiment$Gefuehl_Vor_SelberGutesTun,\n                           na.rm = TRUE)\nprint(DiffSelberGutesTun)\n\n[1] 2.027027\n\nDiffAnderenGutesTun &lt;- mean(psychologieExperiment$Gefuehl_Nach_AnderenGutesTun,\n                            na.rm = TRUE) -\n                       mean(psychologieExperiment$Gefuehl_Vor_AnderenGutesTun,\n                            na.rm = TRUE)\nprint(DiffAnderenGutesTun)\n\n[1] 1.918919\nInterpretiere die Unterschiede!\nANTWORT: Beide Effekte sind positiv. Fast identisch grosse Effekte.\nFühre nun einen 2-Stichproben T-Test mit R durch. Schau dir mit der Hilfe unter ?t.test die Parameter der t.test Funktion in R an. Wähle entsprechend einen ein- oder zweiseitigen Test, das Konfidenzlevel mit 99% und gehe davon aus, dass die Varianzen beider Stichproben gleich sind. Recherchiere, ob es sich um abhängige oder unabhängige Stichproben handelt. Gibt den entsprechenden Parameter bei der Nutzung der t.test Funktion an.\nt.test(psychologieExperiment$Gefuehl_Nach_SelberGutesTun,\n       psychologieExperiment$Gefuehl_Vor_SelberGutesTun,\n       alternative = \"greater\",\n       paired = TRUE,\n       equal.var = TRUE,\n       conf.level = 0.99)\n\n\n    Paired t-test\n\ndata:  psychologieExperiment$Gefuehl_Nach_SelberGutesTun and psychologieExperiment$Gefuehl_Vor_SelberGutesTun\nt = 9.8012, df = 36, p-value = 5.298e-12\nalternative hypothesis: true mean difference is greater than 0\n99 percent confidence interval:\n 1.523537      Inf\nsample estimates:\nmean difference \n       2.027027 \n\nt.test(psychologieExperiment$Gefuehl_Nach_AnderenGutesTun,\n       psychologieExperiment$Gefuehl_Vor_AnderenGutesTun,\n       alternative = \"greater\",\n       paired = TRUE,\n       equal.var = TRUE,\n       conf.level = 0.99)\n\n\n    Paired t-test\n\ndata:  psychologieExperiment$Gefuehl_Nach_AnderenGutesTun and psychologieExperiment$Gefuehl_Vor_AnderenGutesTun\nt = 8.5716, df = 36, p-value = 1.61e-10\nalternative hypothesis: true mean difference is greater than 0\n99 percent confidence interval:\n 1.373909      Inf\nsample estimates:\nmean difference \n       1.918919\nInterpretiere die Ausgabe des Tests (Konfidenzintervalle besprechen wir nächste Woche).\nANTWORT:\nIhr könntest mit einem gleichen t-Test auch testen, ob der Effekt beider Experimente gleich gross ist, d.h. wirkt es sich gleich oder unterschiedlich auf das Befinden aus, ob man sich selbst oder anderen etwas Gutes tut. Wie würdet ihr hierfür vorgehen?\nH0: Ob ich anderen oder mir selber tue underscheidet sich nicht in der Auswirkung auf mein Wohlbefinden.\nHA: Ob ich anderen oder mir selber tue unterscheidet sich in der Auswirkung auf mein Wohlbefinden.\nDiffAuswirkung &lt;- DiffSelberGutesTun - DiffAnderenGutesTun\nprint(DiffAuswirkung)\n\n[1] 0.1081081\nt.test(psychologieExperiment$Gefuehl_Nach_SelberGutesTun -\n         psychologieExperiment$Gefuehl_Vor_SelberGutesTun,\n       psychologieExperiment$Gefuehl_Nach_AnderenGutesTun -\n         psychologieExperiment$Gefuehl_Vor_AnderenGutesTun,\n       alternative = \"greater\",\n       paired = TRUE,\n       equal.var = TRUE,\n       conf.level = 0.99)\n\n\n    Paired t-test\n\ndata:  psychologieExperiment$Gefuehl_Nach_SelberGutesTun - psychologieExperiment$Gefuehl_Vor_SelberGutesTun and psychologieExperiment$Gefuehl_Nach_AnderenGutesTun - psychologieExperiment$Gefuehl_Vor_AnderenGutesTun\nt = 0.48727, df = 36, p-value = 0.3145\nalternative hypothesis: true mean difference is greater than 0\n99 percent confidence interval:\n -0.4320254        Inf\nsample estimates:\nmean difference \n      0.1081081\nANTWORT:\nMit dem t-Wert von ca. 0.5 und einem p-Wert von ca. 0.3 können wir die Nullhypothese nicht ablehnen. Es gibt keinen statistisch signifikanten Unterschied zwischen den beiden Experimenten.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Übung 5 & 6: Verteilungen und Tests</span>"
    ]
  },
  {
    "objectID": "excercises/verteilungen-und-tests.html#statistische-tests-mit-psychologieexperiment",
    "href": "excercises/verteilungen-und-tests.html#statistische-tests-mit-psychologieexperiment",
    "title": "Appendix E — Übung 5 & 6: Verteilungen und Tests",
    "section": "",
    "text": "Hypothesen aufstellen\n\n\n\n\nBerechnungen\n\n\n\nt-Test\n\n\n\nInterpretation aller ausgegebenen Ergebnisse der R t-test() Funktion.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Übung 5 & 6: Verteilungen und Tests</span>"
    ]
  },
  {
    "objectID": "excercises/verteilungen-und-tests.html#chi2-verteilungstest-zu-würfelexperiment",
    "href": "excercises/verteilungen-und-tests.html#chi2-verteilungstest-zu-würfelexperiment",
    "title": "Appendix E — Übung 5 & 6: Verteilungen und Tests",
    "section": "E.2 Chi^2 Verteilungstest zu Würfelexperiment",
    "text": "E.2 Chi^2 Verteilungstest zu Würfelexperiment\n\n# Daten einlesen\nwuerfel_daten &lt;- read.table(\n  \"Data/alle_wuerfel.csv\",\n  sep = \",\",\n  header = TRUE\n)\n\n# Initialisierung eines Vektors für p-Werte\np_werte &lt;- rep(NA, 4)\n\n# Schleife durch die relevanten Spalten (Spalten 5 bis 32)\nfor (spalte in 5:32) {\n  # Durchführung des Chi-Quadrat-Tests\n  chi_quadrat_test &lt;- chisq.test(x = wuerfel_daten[, spalte],\n                                 p = wuerfel_daten[, 3])  # Erwartete Wahrscheinlichkeiten in Spalte 3\n\n  # p-Wert speichern\n  p_werte &lt;- c(p_werte, chi_quadrat_test$p.value)\n\n  # Barplot für absolute Häufigkeiten\n  barplot(\n    wuerfel_daten[, 4],\n    names.arg = wuerfel_daten[, 1],\n    col = \"grey\",\n    ylim = c(0, 15),\n    main = colnames(wuerfel_daten)[spalte]\n  )\n\n  # Neuen Plot für die Vergleichsdaten auf derselben Grafik\n  par(new = TRUE)\n  barplot(\n    wuerfel_daten[, spalte],\n    col = rgb(1, 0, 0, 0.5, maxColorValue = 1),\n    ylim = c(0, 15)\n  )\n\n  # Legende hinzufügen, die den p-Wert anzeigt\n  legend(\n    \"topleft\",\n    paste(\"p-Wert:\", round(chi_quadrat_test$p.value, 2),\n          ifelse(chi_quadrat_test$p.value &lt; 0.05, \"erfunden\",\n                 ifelse(\n                   chi_quadrat_test$p.value &gt; 0.9,\n                      \"wahrscheinlich erfunden\",\n                      \"gewürfelt\")\n                 )\n          )\n  )\n\n  # Anhalten für visuelle Überprüfung\n  # cat(\"Drücke Enter, um fortzufahren...\")\n  # readline()\n}\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n\nWarning in chisq.test(x = wuerfel_daten[, spalte], p = wuerfel_daten[, 3]):\nChi-squared approximation may be incorrect\n\n\n\n\n\n\n\n\n# Ergebniszeilen für die Interpretation der p-Werte hinzufügen\ninterpretation &lt;- ifelse(\n  p_werte &lt; 0.05 | p_werte &gt; 0.9,\n  \"erfunden\", \"gewürfelt\"\n)\n\n# p-Werte und die neue Interpretation an den DataFrame anhängen\nwuerfel_daten &lt;- rbind(\n  wuerfel_daten,\n  p_werte,\n  interpretation\n)\n\n# Überarbeiteter DataFrame mit neuen Zeilen für p-Werte und ihre Interpretation",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Übung 5 & 6: Verteilungen und Tests</span>"
    ]
  },
  {
    "objectID": "excercises/verteilungen-und-tests.html#psychologie-experiment",
    "href": "excercises/verteilungen-und-tests.html#psychologie-experiment",
    "title": "Appendix E — Übung 5 & 6: Verteilungen und Tests",
    "section": "E.3 Psychologie Experiment",
    "text": "E.3 Psychologie Experiment\nDaten einlesen\n\npsychologieExperiment &lt;- read.table(\n  'Data/Psycho_Exp_Ergebnisse2_2024-10-28.csv',\n  sep = ',',\n  header = TRUE,\n  na.strings = '999'\n)\n\n# Spalten im DataFrame umbenennen\ncolnames(psychologieExperiment) &lt;- c(\n  \"Gefuehl_Vor_SelberGutesTun\",\n  \"Gefuehl_Nach_SelberGutesTun\",\n  \"Gefuehl_Vor_AnderenGutesTun\",\n  \"Gefuehl_Nach_AnderenGutesTun\"\n)\n\nErstelle sogenannte QQ Plots und führe den Shapiro Test auf Normalverteilung durch\n\n# QQ-Plots für die vier Spalten erstellen\n\nqqnorm(psychologieExperiment$Gefuehl_Vor_SelberGutesTun)\nqqline(psychologieExperiment$Gefuehl_Vor_SelberGutesTun)\n\n\n\n\n\n\n\nqqnorm(psychologieExperiment$Gefuehl_Nach_SelberGutesTun)\nqqline(psychologieExperiment$Gefuehl_Nach_SelberGutesTun)\n\n\n\n\n\n\n\nqqnorm(psychologieExperiment$Gefuehl_Vor_AnderenGutesTun)\nqqline(psychologieExperiment$Gefuehl_Vor_AnderenGutesTun)\n\n\n\n\n\n\n\nqqnorm(psychologieExperiment$Gefuehl_Nach_AnderenGutesTun)\nqqline(psychologieExperiment$Gefuehl_Nach_AnderenGutesTun)\n\n\n\n\n\n\n\n# Shapiro-Wilk-Test für die Normalverteilung durchführen\nshapiro_test_vor_selber &lt;- shapiro.test(psychologieExperiment$Gefuehl_Vor_SelberGutesTun)\nshapiro_test_nach_selber &lt;- shapiro.test(psychologieExperiment$Gefuehl_Nach_SelberGutesTun)\nshapiro_test_vor_anderen &lt;- shapiro.test(psychologieExperiment$Gefuehl_Vor_AnderenGutesTun)\nshapiro_test_nach_anderen &lt;- shapiro.test(psychologieExperiment$Gefuehl_Nach_AnderenGutesTun)\n\n# Shapiro-Wilk-Testergebnisse ausgeben\nshapiro_test_vor_selber\n\n\n    Shapiro-Wilk normality test\n\ndata:  psychologieExperiment$Gefuehl_Vor_SelberGutesTun\nW = 0.94075, p-value = 0.04874\n\nshapiro_test_nach_selber\n\n\n    Shapiro-Wilk normality test\n\ndata:  psychologieExperiment$Gefuehl_Nach_SelberGutesTun\nW = 0.88499, p-value = 0.001157\n\nshapiro_test_vor_anderen\n\n\n    Shapiro-Wilk normality test\n\ndata:  psychologieExperiment$Gefuehl_Vor_AnderenGutesTun\nW = 0.93818, p-value = 0.0404\n\nshapiro_test_nach_anderen\n\n\n    Shapiro-Wilk normality test\n\ndata:  psychologieExperiment$Gefuehl_Nach_AnderenGutesTun\nW = 0.8824, p-value = 0.0009906\n\n\nSind alle Daten normalverteilt?\nDie Ergebnisse des Shapiro-Wilk-Tests zeigen, dass der p-Wert für alle vier Variablen unter 0.05 liegt:\n\nGefühl Vor Selber Gutes Tun: p-Wert = 0.0487385\nGefühl Nach Selber Gutes Tun: p-Wert = 0.0011574\nGefühl Vor Anderen Gutes Tun: p-Wert = 0.0404011\nGefühl Nach Anderen Gutes Tun: p-Wert = 9.9057037^{-4}\n\nDa alle p-Werte unter 0.05 liegen, können wir die Nullhypothese der Normalverteilung für alle Variablen ablehnen.\nAntwort: Nein, die Daten sind nicht normalverteilt.\nBeim t-Test hatten wir Gleichheit der Varianzen angenommen. Testet hier, ob diese Annahme korrekt war?\n\nlibrary(car)  # Für den Levene-Test\n\nLoading required package: carData\n\n# Levene-Test für Gleichheit der Varianzen\nlevene_test_result &lt;- leveneTest(\n  c(psychologieExperiment$Gefuehl_Nach_SelberGutesTun, psychologieExperiment$Gefuehl_Vor_SelberGutesTun),\n  group = rep(c(\"Nach\", \"Vor\"), each = nrow(psychologieExperiment))\n)\n\nWarning in\nleveneTest.default(c(psychologieExperiment$Gefuehl_Nach_SelberGutesTun, :\nrep(c(\"Nach\", \"Vor\"), each = nrow(psychologieExperiment)) coerced to factor.\n\n# Ausgabe des Testergebnisses\n\nprint(levene_test_result)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  1  0.0147 0.9039\n      72               \n\npWertLevene &lt;- levene_test_result$`Pr(&gt;F)`[1]\n\nANTWORT:\nDie Ausgabe des Levene-Tests zeigt Folgendes:\n\np-Wert des Levene-Tests: 0.9039338\n\nInterpretation:\nDer p-Wert ist deutlich grösser als 0.05, was darauf hindeutet, dass die Nullhypothese der Gleichheit der Varianzen nicht abgelehnt wird. Das bedeutet, dass es keinen statistisch signifikanten Unterschied in den Varianzen der Gruppen gibt.\nAntwort: Ja, die Annahme der Gleichheit der Varianzen beim t-Test war korrekt.\nWie stark verändert sich der Median in den beiden Experimenten von Bevor zu Danach?\n\n# Berechnung der Mediane für die Bedingungen\nmedian_vor_selber &lt;- median(psychologieExperiment$Gefuehl_Vor_SelberGutesTun, na.rm = TRUE)\nmedian_nach_selber &lt;- median(psychologieExperiment$Gefuehl_Nach_SelberGutesTun, na.rm = TRUE)\nmedian_vor_anderen &lt;- median(psychologieExperiment$Gefuehl_Vor_AnderenGutesTun, na.rm = TRUE)\nmedian_nach_anderen &lt;- median(psychologieExperiment$Gefuehl_Nach_AnderenGutesTun, na.rm = TRUE)\n\n# Berechnung der Veränderungen der Mediane\ndiff_median_selber &lt;- median_nach_selber - median_vor_selber\ndiff_median_anderen &lt;- median_nach_anderen - median_vor_anderen\n\n# Ausgabe der Ergebnisse\ncat(\"Veränderung des Medians für Selber Gutes Tun:\", diff_median_selber, \"\\n\")\n\nVeränderung des Medians für Selber Gutes Tun: 2 \n\ncat(\"Veränderung des Medians für Anderen Gutes Tun:\", diff_median_anderen, \"\\n\")\n\nVeränderung des Medians für Anderen Gutes Tun: 2 \n\n\nANTWORT:\nSuche mit Entscheidungsbäumen, Chatbots, Internetsuche, etc. welcher statistische Test sich zum Vergleich der zentralen Tendenz dieser Daten eignet? ANTWORT: Wilcoxon-Vorzeichen-Rang-Test. Dieser vergleicht die Mediane von zwei abhängigen Stichproben.\nParameterfreier Tests, d.h. unabhängig von Verteilung der Daten\n\n# Wilcoxon-Vorzeichen-Rang-Tests für beide Experimente\nwilcox_test_selber &lt;- wilcox.test(\n  psychologieExperiment$Gefuehl_Vor_SelberGutesTun,\n  psychologieExperiment$Gefuehl_Nach_SelberGutesTun,\n  paired = TRUE\n)\n\nWarning in\nwilcox.test.default(psychologieExperiment$Gefuehl_Vor_SelberGutesTun, : cannot\ncompute exact p-value with ties\n\n\nWarning in\nwilcox.test.default(psychologieExperiment$Gefuehl_Vor_SelberGutesTun, : cannot\ncompute exact p-value with zeroes\n\nwilcox_test_anderen &lt;- wilcox.test(\n  psychologieExperiment$Gefuehl_Vor_AnderenGutesTun,\n  psychologieExperiment$Gefuehl_Nach_AnderenGutesTun,\n  paired = TRUE\n)\n\nWarning in\nwilcox.test.default(psychologieExperiment$Gefuehl_Vor_AnderenGutesTun, : cannot\ncompute exact p-value with ties\n\n\nWarning in\nwilcox.test.default(psychologieExperiment$Gefuehl_Vor_AnderenGutesTun, : cannot\ncompute exact p-value with zeroes\n\n# Ausgabe der Testergebnisse\nwilcox_test_selber\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  psychologieExperiment$Gefuehl_Vor_SelberGutesTun and psychologieExperiment$Gefuehl_Nach_SelberGutesTun\nV = 0, p-value = 2.768e-07\nalternative hypothesis: true location shift is not equal to 0\n\nwilcox_test_anderen\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  psychologieExperiment$Gefuehl_Vor_AnderenGutesTun and psychologieExperiment$Gefuehl_Nach_AnderenGutesTun\nV = 28, p-value = 2.051e-06\nalternative hypothesis: true location shift is not equal to 0\n\n\nWie interpretierst du die Tests?\n\nE.3.1 Interpretation der Warnungen und Testergebnisse:\n\nE.3.1.1 Testergebnisse:\n\nWilcoxon-Test für Selber Gutes Tun:\n\nV-Wert: 0\np-Wert: 2.7683169^{-7}\n\n\nDer p-Wert ist viel kleiner als 0.05, was bedeutet, dass die Veränderung der Mediane statistisch signifikant ist. Die Nullhypothese (kein Unterschied der zentralen Tendenz) kann abgelehnt werden, was darauf hinweist, dass das Experiment „Selber Gutes Tun“ eine signifikante Veränderung im Median bewirkt hat.\n\nWilcoxon-Test für Anderen Gutes Tun:\n\nV-Wert: 28\np-Wert: 2.0506755^{-6}\n\n\nAuch hier ist der p-Wert viel kleiner als 0.05. Die Nullhypothese kann abgelehnt werden, was zeigt, dass auch das Experiment „Anderen Gutes Tun“ eine signifikante Veränderung im Median bewirkt hat.\n\n\n\nE.3.2 Gesamtfazit:\nBeide Experimente zeigen eine signifikante Veränderung der Mediane von „Bevor“ zu „Danach“. Die zentralen Tendenzen sind in beiden Fällen signifikant unterschiedlich. Dies unterstützt die Schlussfolgerung, dass die Handlung, sich selbst oder anderen etwas Gutes zu tun, eine positive Wirkung auf die Bewertung des Gefühls hat.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Übung 5 & 6: Verteilungen und Tests</span>"
    ]
  }
]